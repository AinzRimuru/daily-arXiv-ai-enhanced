{"id": "2512.16814", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16814", "abs": "https://arxiv.org/abs/2512.16814", "authors": ["William English", "Dominic Simon", "Sumit Kumar Jha", "Rickard Ewetz"], "title": "Grammar-Forced Translation of Natural Language to Temporal Logic using LLMs", "comment": null, "summary": "Translating natural language (NL) into a formal language such as temporal logic (TL) is integral for human communication with robots and autonomous systems. State-of-the-art approaches decompose the task into a lifting of atomic propositions (APs) phase and a translation phase. However, existing methods struggle with accurate lifting, the existence of co-references, and learning from limited data. In this paper, we propose a framework for NL to TL translation called Grammar Forced Translation (GraFT). The framework is based on the observation that previous work solves both the lifting and translation steps by letting a language model iteratively predict tokens from its full vocabulary. In contrast, GraFT reduces the complexity of both tasks by restricting the set of valid output tokens from the full vocabulary to only a handful in each step. The solution space reduction is obtained by exploiting the unique properties of each problem. We also provide a theoretical justification for why the solution space reduction leads to more efficient learning. We evaluate the effectiveness of GraFT using the CW, GLTL, and Navi benchmarks. Compared with state-of-the-art translation approaches, it can be observed that GraFT the end-to-end translation accuracy by 5.49% and out-of-domain translation accuracy by 14.06% on average.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa GraFT \u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u8bed\u6cd5\u7ea6\u675f\u51cf\u5c11\u8bed\u8a00\u6a21\u578b\u7684\u8f93\u51fa\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ece\u81ea\u7136\u8bed\u8a00\u5230\u65f6\u5e8f\u903b\u8f91\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u7136\u8bed\u8a00\uff08NL\uff09\u8f6c\u65f6\u5e8f\u903b\u8f91\uff08TL\uff09\u65b9\u6cd5\u5728\u539f\u5b50\u547d\u9898\uff08AP\uff09\u63d0\u53d6\u3001\u6307\u4ee3\u89e3\u6790\u4ee5\u53ca\u5c0f\u6837\u672c\u5b66\u4e60\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u641c\u7d22\u7a7a\u95f4\u8fc7\u5927\u3002", "method": "\u63d0\u51fa GraFT \u6846\u67b6\uff0c\u5229\u7528\u8bed\u6cd5\u7ea6\u675f\uff08Grammar Forced Translation\uff09\u5728\u7ffb\u8bd1\u7684\u6bcf\u4e00\u6b65\u9650\u5236 LLM \u7684\u53ef\u9009 Token \u8303\u56f4\uff0c\u5c06\u5168\u8bcd\u8868\u9884\u6d4b\u7f29\u51cf\u4e3a\u6781\u5c0f\u96c6\u5408\u7684\u9884\u6d4b\u3002", "result": "\u5728 CW\u3001GLTL \u548c Navi \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGraFT \u7684\u7aef\u5230\u7aef\u7ffb\u8bd1\u51c6\u786e\u7387\u5e73\u5747\u63d0\u5347\u4e86 5.49%\uff0c\u800c\u5176\u5728\u57df\u5916\uff08Out-of-domain\uff09\u7ffb\u8bd1\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\u4e86 14.06%\u3002", "conclusion": "GraFT \u901a\u8fc7\u51cf\u5c11\u641c\u7d22\u7a7a\u95f4\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u4e0b\u7684\u5b66\u4e60\u6548\u7387\uff0c\u662f\u89e3\u51b3 NL \u5230 TL \u7ffb\u8bd1\u4efb\u52a1\u4e2d\u590d\u6742\u6027\u548c\u8de8\u9886\u57df\u6cdb\u5316\u95ee\u9898\u7684\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.16832", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16832", "abs": "https://arxiv.org/abs/2512.16832", "authors": ["Aditya Yadavalli", "Tiago Pimentel", "Tamar I Regev", "Ethan Wilcox", "Alex Warstadt"], "title": "What Do Prosody and Text Convey? Characterizing How Meaningful Information is Distributed Across Multiple Channels", "comment": null, "summary": "Prosody -- the melody of speech -- conveys critical information often not captured by the words or text of a message. In this paper, we propose an information-theoretic approach to quantify how much information is expressed by prosody alone and not by text, and crucially, what that information is about. Our approach applies large speech and language models to estimate the mutual information between a particular dimension of an utterance's meaning (e.g., its emotion) and any of its communication channels (e.g., audio or text). We then use this approach to quantify how much information is conveyed by audio and text about sarcasm, emotion, and questionhood, using speech from television and podcasts. We find that for sarcasm and emotion the audio channel -- and by implication the prosodic channel -- transmits over an order of magnitude more information about these features than the text channel alone, at least when long-term context beyond the current sentence is unavailable. For questionhood, prosody provides comparatively less additional information. We conclude by outlining a program applying our approach to more dimensions of meaning, communication channels, and languages.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u65b9\u6cd5\u91cf\u5316\u4e86\u8bed\u97f3\u97f5\u5f8b\u4e0e\u6587\u672c\u5728\u4f20\u9012\u8bed\u4e49\u4fe1\u606f\u4e0a\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u97f5\u5f8b\u5728\u4f20\u8fbe\u8bbd\u523a\u548c\u60c5\u611f\u65b9\u9762\u8fdc\u6bd4\u6587\u672c\u91cd\u8981\u3002", "motivation": "\u65e8\u5728\u91cf\u5316\u97f5\u5f8b\uff08\u8bed\u97f3\u7684\u65cb\u5f8b\uff09\u4e2d\u8574\u542b\u7684\u3001\u672a\u88ab\u6587\u672c\u6355\u6349\u7684\u5173\u952e\u4fe1\u606f\uff0c\u5e76\u660e\u786e\u8fd9\u4e9b\u4fe1\u606f\u7684\u5177\u4f53\u6307\u5411\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u89c4\u6a21\u8bed\u97f3\u548c\u8bed\u8a00\u6a21\u578b\u6765\u4f30\u8ba1\u8bed\u97f3\u542b\u4e49\u7684\u7279\u5b9a\u7ef4\u5ea6\uff08\u5982\u60c5\u611f\uff09\u4e0e\u4e0d\u540c\u901a\u4fe1\u6e20\u9053\uff08\u97f3\u9891\u6216\u6587\u672c\uff09\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u3002", "result": "\u5728\u8bbd\u523a\u548c\u60c5\u611f\u8868\u8fbe\u65b9\u9762\uff0c\u97f3\u9891\u6e20\u9053\uff08\u97f5\u5f8b\uff09\u4f20\u9012\u7684\u4fe1\u606f\u91cf\u6bd4\u7eaf\u6587\u672c\u9ad8\u51fa\u4e00\u4e2a\u6570\u91cf\u7ea7\uff08\u5728\u7f3a\u4e4f\u957f\u671f\u4e0a\u4e0b\u6587\u65f6\uff09\uff1b\u4f46\u5728\u5224\u65ad\u662f\u5426\u4e3a\u7591\u95ee\u53e5\u65f6\uff0c\u97f5\u5f8b\u63d0\u4f9b\u7684\u989d\u5916\u4fe1\u606f\u76f8\u5bf9\u8f83\u5c11\u3002", "conclusion": "\u8be5\u4fe1\u606f\u8bba\u65b9\u6cd5\u53ef\u4ee5\u63a8\u5e7f\u5230\u66f4\u591a\u8bed\u4e49\u7ef4\u5ea6\u3001\u901a\u4fe1\u6e20\u9053\u548c\u8bed\u8a00\u7684\u7814\u7a76\u4e2d\uff0c\u4e3a\u91cf\u5316\u5206\u6790\u8bed\u97f3\u7684\u591a\u6a21\u6001\u4fe1\u606f\u8d21\u732e\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
{"id": "2512.16843", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16843", "abs": "https://arxiv.org/abs/2512.16843", "authors": ["Harsh Vardhan Bansal"], "title": "LLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference", "comment": "Accepted and presented at 13th IEEE International Conference on Intelligent Systems and Embedded Design (ISED-2025)", "summary": "Transformer-based language models have achieved remarkable performance across a wide range of tasks, yet their high inference latency poses a significant challenge for real-timeand large-scale deployment. While existing caching mechanisms,such as token-level key-value caches, offer speedups in autore-gressive decoding, they are limited in scope and applicability. In this paper, we present LLMCache, a novel layer-wise caching framework that accelerates transformer inference by reusing intermediate activations based on semantic similarity of input sequences. Unlike prior work, LLMCache is model-agnostic,operates across both encoder and decoder architectures, and supports caching at arbitrary transformer layers. We introduce a lightweight fingerprinting mechanism for matching seman-tically similar inputs and propose adaptive eviction strategies to manage cache staleness. Experiments on BERT and GPT-2 across SQuAD, WikiText-103, and OpenBookQA show up to 3.1 X speedup in inference time with <0.5% accuracy degradation. Our results highlight LLMCache as a practical and general-purpose solution for optimizing transformer inference in real-world applications", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa LLMCache\uff0c\u4e00\u79cd\u8de8\u6a21\u578b\u3001\u8de8\u67b6\u6784\u7684\u5c42\u7ea7\u5316\u7f13\u5b58\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u6027\u91cd\u7528\u4e2d\u95f4\u6fc0\u6d3b\u503c\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u5c06\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u8fbe 3.1 \u500d\u3002", "motivation": "Transformer \u6a21\u578b\u7684\u9ad8\u63a8\u7406\u5ef6\u8fdf\u5236\u7ea6\u4e86\u5176\u5b9e\u65f6\u548c\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u4e14\u73b0\u6709\u7684 Token \u7ea7 KV \u7f13\u5b58\u673a\u5236\u5728\u9002\u7528\u8303\u56f4\u548c\u63d0\u901f\u6548\u679c\u4e0a\u5b58\u5728\u5c40\u9650\u3002", "method": "\u63d0\u51fa LLMCache \u6846\u67b6\uff0c\u91c7\u7528\u5c42\u7ea7\u5316\u7f13\u5b58\uff08layer-wise caching\uff09\u91cd\u7528\u4e2d\u95f4\u6fc0\u6d3b\u503c\u3002\u6838\u5fc3\u6280\u672f\u5305\u62ec\uff1a\u7528\u4e8e\u5339\u914d\u8bed\u4e49\u76f8\u4f3c\u8f93\u5165\u7684\u8f7b\u91cf\u7ea7\u6307\u7eb9\u673a\u5236\uff0c\u4ee5\u53ca\u7ba1\u7406\u7f13\u5b58\u8fc7\u65f6\u6027\u7684\u81ea\u9002\u5e94\u6dd8\u6c70\u7b56\u7565\u3002", "result": "\u5728 BERT \u548c GPT-2 \u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLLMCache \u5728 SQuAD \u7b49\u6570\u636e\u96c6\u4e0a\u53ef\u5b9e\u73b0\u9ad8\u8fbe 3.1 \u500d\u7684\u63a8\u7406\u52a0\u901f\uff0c\u800c\u51c6\u786e\u7387\u4e0b\u964d\u4e0d\u5230 0.5%\u3002", "conclusion": "LLMCache \u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u4f18\u5316 Transformer \u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2512.16899", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.16899", "abs": "https://arxiv.org/abs/2512.16899", "authors": ["Yushi Hu", "Reyhane Askari-Hemmat", "Melissa Hall", "Emily Dinan", "Luke Zettlemoyer", "Marjan Ghazvininejad"], "title": "Multimodal RewardBench 2: Evaluating Omni Reward Models for Interleaved Text and Image", "comment": "Code and data available at https://github.com/facebookresearch/MMRB2", "summary": "Reward models (RMs) are essential for training large language models (LLMs), but remain underexplored for omni models that handle interleaved image and text sequences. We introduce Multimodal RewardBench 2 (MMRB2), the first comprehensive benchmark for reward models on multimodal understanding and (interleaved) generation. MMRB2 spans four tasks: text-to-image, image editing, interleaved generation, and multimodal reasoning (\"thinking-with-images\"), providing 1,000 expert-annotated preference pairs per task from 23 models and agents across 21 source tasks. MMRB2 is designed with: (1) practical but challenging prompts; (2) responses from state-of-the-art models and agents; and (3) preference pairs with strong human-expert consensus, curated via an ensemble filtering strategy. Using MMRB2, we study existing judges for each subtask, including multimodal LLM-as-a-judge and models trained with human preferences. The latest Gemini 3 Pro attains 75-80% accuracy. GPT-5 and Gemini 2.5 Pro reach 66-75% accuracy, compared to >90% for humans, yet surpass the widely used GPT-4o (59%). The best performing open-source model Qwen3-VL-32B achieves similar accuracies as Gemini 2.5 Flash (64%). We also show that MMRB2 performance strongly correlates with downstream task success using Best-of-N sampling and conduct an in-depth analysis that shows key areas to improve the reward models going forward.", "AI": {"tldr": "\u672c\u6587\u63a8\u51fa MMRB2\uff0c\u9996\u4e2a\u9488\u5bf9\u591a\u6a21\u6001\uff08\u56fe\u6587\u4ea4\u7ec7\uff09\u7406\u89e3\u4e0e\u751f\u6210\u7684\u5956\u52b1\u6a21\u578b\u7efc\u5408\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d AI \u88c1\u5224\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5728\u504f\u597d\u5224\u65ad\u4e0a\u7684\u5dee\u8ddd\u3002", "motivation": "\u5c3d\u7ba1\u5956\u52b1\u6a21\u578b\u5728 LLM \u8bad\u7ec3\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9488\u5bf9\u80fd\u5904\u7406\u56fe\u6587\u4ea4\u7ec7\u5e8f\u5217\u7684\u5168\u80fd\u6a21\u578b\uff08Omni models\uff09\u7684\u5956\u52b1\u6a21\u578b\u7814\u7a76\u8fd8\u5f88\u5c11\uff0c\u7f3a\u4e4f\u5168\u9762\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u8bc4\u4f30\u57fa\u51c6 MM-RewardBench 2 (MMRB2)\uff0c\u6db5\u76d6\u6587\u672c\u5230\u56fe\u50cf\u3001\u56fe\u50cf\u7f16\u8f91\u3001\u4ea4\u7ec7\u751f\u6210\u548c\u591a\u6a21\u6001\u63a8\u7406\u56db\u4e2a\u4efb\u52a1\uff0c\u5305\u542b 4000 \u5bf9\u4e13\u5bb6\u6807\u6ce8\u7684\u504f\u597d\u6570\u636e\u3002\u91c7\u7528\u96c6\u6210\u8fc7\u6ee4\u7b56\u7565\u786e\u4fdd\u6570\u636e\u8d28\u91cf\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u79cd LLM-as-a-judge \u53ca\u8bad\u7ec3\u540e\u7684\u5956\u52b1\u6a21\u578b\u3002", "result": "Gemini 1.5 Pro \u8868\u73b0\u6700\u4f73\uff0875-80% \u51c6\u786e\u7387\uff09\uff1bGPT-4o \u548c Gemini 1.5 Flash \u8868\u73b0\u6b21\u4e4b\uff1b\u5f00\u6e90\u6a21\u578b Qwen2-VL-72B \u4e0e Gemini 1.5 Flash \u76f8\u5f53\uff0864%\uff09\u3002\u7814\u7a76\u8fd8\u8bc1\u660e MMRB2 \u7684\u8868\u73b0\u4e0e Best-of-N \u91c7\u6837\u4e0b\u7684\u6a21\u578b\u4e0b\u6e38\u4efb\u52a1\u8d28\u91cf\u9ad8\u5ea6\u6b63\u76f8\u5173\u3002", "conclusion": "MMRB2 \u4e3a\u591a\u6a21\u6001\u5956\u52b1\u6a21\u578b\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u57fa\u51c6\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u6700\u5148\u8fdb\u7684\u95ed\u6e90\u6a21\u578b\uff08\u5982 Gemini 1.5 Pro\uff09\u5728\u8bc4\u4f30\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u6bd4\u4ecd\u6709\u7ea6 15-20% \u7684\u51c6\u786e\u7387\u5dee\u8ddd\uff0c\u5f00\u6e90\u6a21\u578b\uff08\u5982 Qwen2-VL\uff09\u4e5f\u6709\u5de8\u5927\u8fdb\u6b65\u7a7a\u95f4\u3002"}}
{"id": "2512.16902", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16902", "abs": "https://arxiv.org/abs/2512.16902", "authors": ["Eric Todd", "Jannik Brinkmann", "Rohit Gandikota", "David Bau"], "title": "In-Context Algebra", "comment": "28 pages, 18 figures. Code and data at https://algebra.baulab.info", "summary": "We investigate the mechanisms that arise when transformers are trained to solve arithmetic on sequences where tokens are variables whose meaning is determined only through their interactions. While prior work has found that transformers develop geometric embeddings that mirror algebraic structure, those previous findings emerge from settings where arithmetic-valued tokens have fixed meanings. We devise a new task in which the assignment of symbols to specific algebraic group elements varies from one sequence to another. Despite this challenging setup, transformers achieve near-perfect accuracy on the task and even generalize to unseen algebraic groups. We develop targeted data distributions to create causal tests of a set of hypothesized mechanisms, and we isolate three mechanisms models consistently learn: commutative copying where a dedicated head copies answers, identity element recognition that distinguishes identity-containing facts, and closure-based cancellation that tracks group membership to constrain valid answers. Complementary to the geometric representations found in fixed-symbol settings, our findings show that models develop symbolic reasoning mechanisms when trained to reason in-context with variables whose meanings are not fixed.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0 Transformer \u5728\u5904\u7406\u53d8\u91cf\u5316\u7b97\u672f\u4efb\u52a1\u65f6\uff0c\u80fd\u901a\u8fc7\u5b66\u4e60\u201c\u4ea4\u6362\u590d\u5236\u201d\u548c\u201c\u5355\u4f4d\u5143\u8bc6\u522b\u201d\u7b49\u7b26\u53f7\u63a8\u7406\u673a\u5236\uff0c\u5b9e\u73b0\u5bf9\u52a8\u6001\u542b\u4e49\u7b26\u53f7\u7684\u9ad8\u6548\u4ee3\u6570\u8fd0\u7b97\u4e0e\u6cdb\u5316\u3002", "motivation": "\u63a2\u7a76\u5f53 Transformer \u9762\u5bf9\u542b\u4e49\u4e0d\u56fa\u5b9a\uff08\u53d8\u91cf\u5316\uff09\u7684\u7b97\u672f\u5e8f\u5217\u65f6\uff0c\u5176\u5185\u90e8\u7684\u5b66\u4e60\u673a\u5236\u53ca\u4ee3\u6570\u63a8\u7406\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u9879\u65b0\u4efb\u52a1\uff0c\u5176\u4e2d\u7b26\u53f7\u4e0e\u4ee3\u6570\u7fa4\u5143\u7d20\u7684\u6620\u5c04\u968f\u5e8f\u5217\u53d8\u5316\uff08In-context\uff09\uff1b\u901a\u8fc7\u63a7\u5236\u6570\u636e\u5206\u5e03\u8fdb\u884c\u56e0\u679c\u6d4b\u8bd5\uff0c\u9694\u79bb\u5e76\u8bc6\u522b\u7279\u5b9a\u7684\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u6a21\u578b\u5728\u6b64\u7c7b\u9ad8\u96be\u5ea6\u4efb\u52a1\u4e0a\u8fbe\u5230\u8fd1\u4e4e\u5b8c\u5584\u7684\u51c6\u786e\u7387\uff0c\u5e76\u80fd\u6cdb\u5316\u81f3\u672a\u89c1\u8fc7\u7684\u4ee3\u6570\u7fa4\u3002\u8bc6\u522b\u51fa\u4e09\u79cd\u6838\u5fc3\u673a\u5236\uff1a\u4ea4\u6362\u590d\u5236\uff08Commutative Copying\uff09\u3001\u5355\u4f4d\u5143\u8bc6\u522b\uff08Identity Recognition\uff09\u548c\u57fa\u4e8e\u95ed\u5305\u7684\u62b5\u6d88\uff08Closure-based Cancellation\uff09\u3002", "conclusion": "\u5728\u52a8\u6001\u53d8\u91cf\u6620\u5c04\u7684\u73af\u5883\u4e0b\uff0cTransformer \u4e0d\u4ec5\u4f9d\u8d56\u51e0\u4f55\u5d4c\u5165\uff0c\u66f4\u503e\u5411\u4e8e\u5f00\u53d1\u5177\u5907\u6cdb\u5316\u80fd\u529b\u7684\u7b26\u53f7\u5316\u63a8\u7406\u673a\u5236\u6765\u89e3\u51b3\u4ee3\u6570\u95ee\u9898\u3002"}}
{"id": "2512.16917", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16917", "abs": "https://arxiv.org/abs/2512.16917", "authors": ["Qihao Liu", "Luoxin Ye", "Wufei Ma", "Yu-Cheng Chou", "Alan Yuille"], "title": "Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs) with explicit reasoning capabilities excel at mathematical reasoning yet still commit process errors, such as incorrect calculations, brittle logic, and superficially plausible but invalid steps. In this paper, we introduce Generative Adversarial Reasoner, an on-policy joint training framework designed to enhance reasoning by co-evolving an LLM reasoner and an LLM-based discriminator through adversarial reinforcement learning. A compute-efficient review schedule partitions each reasoning chain into logically complete slices of comparable length, and the discriminator evaluates each slice's soundness with concise, structured justifications. Learning couples complementary signals: the LLM reasoner is rewarded for logically consistent steps that yield correct answers, while the discriminator earns rewards for correctly detecting errors or distinguishing traces in the reasoning process. This produces dense, well-calibrated, on-policy step-level rewards that supplement sparse exact-match signals, improving credit assignment, increasing sample efficiency, and enhancing overall reasoning quality of LLMs. Across various mathematical benchmarks, the method delivers consistent gains over strong baselines with standard RL post-training. Specifically, on AIME24, we improve DeepSeek-R1-Distill-Qwen-7B from 54.0 to 61.3 (+7.3) and DeepSeek-R1-Distill-Llama-8B from 43.7 to 53.7 (+10.0). The modular discriminator also enables flexible reward shaping for objectives such as teacher distillation, preference alignment, and mathematical proof-based reasoning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5bf9\u6297\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u8bad\u7ec3\u63a8\u7406\u5668\u548c\u5224\u522b\u5668\uff0c\u5229\u7528\u5bc6\u96c6\u7684\u6b65\u9aa4\u7ea7\u5956\u52b1\u89e3\u51b3\u4e86 LLM \u6570\u5b66\u63a8\u7406\u4e2d\u7684\u8fc7\u7a0b\u9519\u8bef\u95ee\u9898\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u5728 AIME \u7b49\u7ade\u8d5b\u7ea7\u6570\u5b66\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u4ecd\u5b58\u5728\u8fc7\u7a0b\u9519\u8bef\uff08\u5982\u8ba1\u7b97\u9519\u8bef\u3001\u903b\u8f91\u8106\u5f31\u7b49\uff09\uff0c\u4e14\u4f20\u7edf\u7684\u7a00\u758f\u5956\u52b1\u4fe1\u53f7\uff08\u4ec5\u770b\u7b54\u6848\u6b63\u786e\u4e0e\u5426\uff09\u96be\u4ee5\u5b9e\u73b0\u7cbe\u51c6\u7684\u4fe1\u7528\u5206\u914d\u3002", "method": "\u63d0\u51fa GAR\uff08Generative Adversarial Reasoner\uff09\u6846\u67b6\u3002\u901a\u8fc7\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u590d\u6838\u673a\u5236\u5c06\u63a8\u7406\u94fe\u5207\u7247\uff0c\u5229\u7528\u5224\u522b\u5668\u5bf9\u6bcf\u4e2a\u5207\u7247\u7684\u5408\u7406\u6027\u7ed9\u51fa\u7ed3\u6784\u5316\u8bc4\u4ef7\u3002\u63a8\u7406\u5668\u56e0\u903b\u8f91\u4e25\u5bc6\u4e14\u7b54\u6848\u6b63\u786e\u83b7\u5f97\u5956\u52b1\uff0c\u5224\u522b\u5668\u56e0\u51c6\u786e\u68c0\u6d4b\u9519\u8bef\u83b7\u5f97\u5956\u52b1\uff0c\u5b9e\u73b0\u6a21\u578b\u95f4\u7684\u5bf9\u6297\u5f0f\u5171\u540c\u8fdb\u5316\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u8bc4\u6d4b\u96c6\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002\u5728 AIME24 \u4e0a\uff0cDeepSeek-R1-Distill-Qwen-7B \u51c6\u786e\u7387\u63d0\u9ad8 7.3%\uff0cLlama-8B \u63d0\u9ad8 10.0%\u3002\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u548c\u63a8\u7406\u8d28\u91cf\u3002", "conclusion": "GAR \u6846\u67b6\u8bc1\u660e\u4e86\u751f\u6210\u6a21\u578b\u4e0e\u5224\u522b\u6a21\u578b\u901a\u8fc7\u5bf9\u6297\u5f3a\u5316\u5b66\u4e60\u5171\u540c\u8fdb\u5316\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u590d\u6742\u63a8\u7406\u4e2d\u7684\u8fc7\u7a0b\u9519\u8bef\u3002"}}
{"id": "2512.16855", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.16855", "abs": "https://arxiv.org/abs/2512.16855", "authors": ["Khurram Khalil", "Khaza Anuarul Hoque"], "title": "TOGGLE: Temporal Logic-Guided Large Language Model Compression for Edge", "comment": "Published in the IEEE ICCAD 2025 conference", "summary": "Large Language Models (LLMs) deliver exceptional performance across natural language tasks but demand substantial computational resources, limiting their deployment on resource-constrained edge devices. Existing compression techniques, such as quantization and pruning, often degrade critical linguistic properties and lack formal guarantees for preserving model behavior. We propose Temporal Logic-Guided Large Language Model Compression (TOGGLE), a novel framework that leverages Signal Temporal Logic (STL) to formally specify and enforce linguistic properties during compression. TOGGLE employs an STL robustness-guided Bayesian optimization to systematically explore layer-wise quantization and pruning configurations, generating compressed models that formally satisfy specified linguistic constraints without retraining or fine-tuning. Evaluating TOGGLE on four LLM architectures (GPT-2, DeepSeek-V2 7B, LLaMA 3 8B, and Mistral 7B), we achieve up to 3.3x reduction in computational costs (FLOPs) and up to a 68.8% reduction in model size while satisfying all linguistic properties. TOGGLE represents the first integration of formal methods into LLM compression, enabling efficient, verifiable deployment of LLMs on edge hardware.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTOGGLE\uff0c\u901a\u8fc7\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u5f15\u5bfc\u538b\u7f29\u8fc7\u7a0b\uff0c\u5728\u5927\u5e45\u964d\u4f4eLLM\u8ba1\u7b97\u5f00\u9500\u548c\u4f53\u79ef\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u6a21\u578b\u884c\u4e3a\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4fdd\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684LLM\u538b\u7f29\u6280\u672f\uff08\u5982\u91cf\u5316\u3001\u526a\u679d\uff09\u8ba1\u7b97\u9700\u6c42\u5927\uff0c\u4e14\u5f80\u5f80\u4f1a\u635f\u574f\u5173\u952e\u7684\u8bed\u8a00\u5c5e\u6027\uff0c\u7531\u4e8e\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u96be\u4ee5\u786e\u4fdd\u538b\u7f29\u540e\u6a21\u578b\u7684\u884c\u4e3a\u3002", "method": "\u63d0\u51faTOGGLE\u6846\u67b6\uff0c\u5229\u7528\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u5f62\u5f0f\u5316\u5b9a\u4e49\u8bed\u8a00\u5c5e\u6027\uff0c\u5e76\u7ed3\u5408STL\u9c81\u68d2\u6027\u5f15\u5bfc\u7684\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u5728\u4e0d\u8fdb\u884c\u91cd\u8bad\u7ec3\u548c\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\uff0c\u81ea\u52a8\u63a2\u7d22\u5c42\u7ea7\u91cf\u5316\u548c\u526a\u679d\u7684\u6700\u4f18\u914d\u7f6e\u3002", "result": "\u5728\u56db\u79cd\u4e3b\u6d41\u6a21\u578b\uff08GPT-2, DeepSeek-V2, LLaMA 3, Mistral\uff09\u4e0a\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe3.3\u500d\u7684FLOPs\u51cf\u5c11\u548c68.8%\u7684\u6a21\u578b\u5c3a\u5bf8\u7f29\u51cf\uff0c\u540c\u65f6\u786e\u4fdd\u6240\u6709\u6307\u5b9a\u7684\u8bed\u8a00\u5f62\u5f0f\u5316\u7ea6\u675f\u5f97\u5230\u6ee1\u8db3\u3002", "conclusion": "TOGGLE\u662f\u9996\u4e2a\u5c06\u5f62\u5f0f\u5316\u65b9\u6cd5\u5f15\u5165LLM\u538b\u7f29\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u6a21\u578b\u8f7b\u91cf\u5316\u4e0e\u8bed\u8a00\u7279\u6027\u4fdd\u6301\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u7684\u9a8c\u8bc1\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.16873", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16873", "abs": "https://arxiv.org/abs/2512.16873", "authors": ["Otman A. Basir"], "title": "The Social Responsibility Stack: A Control-Theoretic Architecture for Governing Socio-Technical AI", "comment": null, "summary": "Artificial intelligence systems are increasingly deployed in domains that shape human behaviour, institutional decision-making, and societal outcomes. Existing responsible AI and governance efforts provide important normative principles but often lack enforceable engineering mechanisms that operate throughout the system lifecycle. This paper introduces the Social Responsibility Stack (SRS), a six-layer architectural framework that embeds societal values into AI systems as explicit constraints, safeguards, behavioural interfaces, auditing mechanisms, and governance processes. SRS models responsibility as a closed-loop supervisory control problem over socio-technical systems, integrating design-time safeguards with runtime monitoring and institutional oversight. We develop a unified constraint-based formulation, introduce safety-envelope and feedback interpretations, and show how fairness, autonomy, cognitive burden, and explanation quality can be continuously monitored and enforced. Case studies in clinical decision support, cooperative autonomous vehicles, and public-sector systems illustrate how SRS translates normative objectives into actionable engineering and operational controls. The framework bridges ethics, control theory, and AI governance, providing a practical foundation for accountable, adaptive, and auditable socio-technical AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u201c\u793e\u4f1a\u8d23\u4efb\u6808\uff08SRS\uff09\u201d\uff0c\u4e00\u4e2a\u5c06\u793e\u4f1a\u4f26\u7406\u539f\u5219\u8f6c\u5316\u4e3a\u53ef\u6267\u884c AI \u5de5\u7a0b\u7ea6\u675f\u548c\u95ed\u73af\u76d1\u63a7\u673a\u5236\u7684\u516d\u5c42\u67b6\u6784\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7684\u8d1f\u8d23\u4efb AI \u6cbb\u7406\u5de5\u4f5c\u591a\u505c\u7559\u5728\u89c4\u8303\u6027\u539f\u5219\u5c42\u9762\uff0c\u7f3a\u4e4f\u5728\u6574\u4e2a\u7cfb\u7edf\u751f\u547d\u5468\u671f\u4e2d\u53ef\u64cd\u4f5c\u3001\u53ef\u5f3a\u5236\u6267\u884c\u7684\u5de5\u7a0b\u673a\u5236\u3002", "method": "\u901a\u8fc7\u4e00\u4e2a\u516d\u5c42\u67b6\u6784\u6846\u67b6\u5c06\u793e\u4f1a\u4ef7\u503c\u5d4c\u5165\u7cfb\u7edf\uff0c\u5e76\u5c06\u5176\u5efa\u6a21\u4e3a\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u7684\u95ed\u73af\u76d1\u7763\u63a7\u5236\u95ee\u9898\u3002\u5229\u7528\u7ea6\u675f\u516c\u5f0f\u3001\u5b89\u5168\u5305\u7edc\uff08safety-envelope\uff09\u548c\u53cd\u9988\u673a\u5236\uff0c\u5728\u8bbe\u8ba1\u548c\u8fd0\u884c\u65f6\u5b9e\u65bd\u76d1\u63a7\u3002", "result": "\u901a\u8fc7\u5728\u4e34\u5e8a\u51b3\u7b56\u3001\u534f\u4f5c\u81ea\u52a8\u9a7e\u9a76\u548c\u516c\u5171\u90e8\u95e8\u7cfb\u7edf\u4e2d\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u80fd\u5c06\u62bd\u8c61\u7684\u89c4\u8303\u76ee\u6807\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u5de5\u7a0b\u548c\u8fd0\u884c\u63a7\u5236\u6307\u6807\u3002", "conclusion": "SRS \u4e3a\u6784\u5efa\u53ef\u8d1f\u8d23\u3001\u53ef\u81ea\u9002\u5e94\u4e14\u53ef\u5ba1\u8ba1\u7684\u793e\u4f1a\u6280\u672f AI \u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8df5\u57fa\u7840\uff0c\u5f25\u5408\u4e86\u4f26\u7406\u3001\u63a7\u5236\u7406\u8bba\u4e0e\u6cbb\u7406\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2512.16876", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.16876", "abs": "https://arxiv.org/abs/2512.16876", "authors": ["Astrid Brull", "Sara Aguti", "V\u00e9ronique Bolduc", "Ying Hu", "Daniel M. Jimenez-Gutierrez", "Enrique Zuazua", "Joaquin Del-Rio", "Oleksii Sliusarenko", "Haiyan Zhou", "Francesco Muntoni", "Carsten G. B\u00f6nnemann", "Xabi Uribe-Etxebarria"], "title": "Training Together, Diagnosing Better: Federated Learning for Collagen VI-Related Dystrophies", "comment": null, "summary": "The application of Machine Learning (ML) to the diagnosis of rare diseases, such as collagen VI-related dystrophies (COL6-RD), is fundamentally limited by the scarcity and fragmentation of available data. Attempts to expand sampling across hospitals, institutions, or countries with differing regulations face severe privacy, regulatory, and logistical obstacles that are often difficult to overcome. The Federated Learning (FL) provides a promising solution by enabling collaborative model training across decentralized datasets while keeping patient data local and private. Here, we report a novel global FL initiative using the Sherpa.ai FL platform, which leverages FL across distributed datasets in two international organizations for the diagnosis of COL6-RD, using collagen VI immunofluorescence microscopy images from patient-derived fibroblast cultures. Our solution resulted in an ML model capable of classifying collagen VI patient images into the three primary pathogenic mechanism groups associated with COL6-RD: exon skipping, glycine substitution, and pseudoexon insertion. This new approach achieved an F1-score of 0.82, outperforming single-organization models (0.57-0.75). These results demonstrate that FL substantially improves diagnostic utility and generalizability compared to isolated institutional models. Beyond enabling more accurate diagnosis, we anticipate that this approach will support the interpretation of variants of uncertain significance and guide the prioritization of sequencing strategies to identify novel pathogenic variants.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u5728\u4e0d\u5171\u4eab\u539f\u59cb\u9690\u79c1\u6570\u636e\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u8de8\u56fd\u534f\u4f5c\u8bca\u65ad\u7f55\u89c1\u75c5\uff0c\u663e\u8457\u63d0\u5347\u4e86COL6-RD\u75be\u75c5\u5206\u7c7b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u7f55\u89c1\u75c5\uff08\u5982COL6-RD\uff09\u8bca\u65ad\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u4e14\u788e\u7247\u5316\u7684\u95ee\u9898\uff0c\u800c\u8de8\u673a\u6784\u7684\u6570\u636e\u6574\u5408\u53c8\u53d7\u5230\u9690\u79c1\u3001\u6cd5\u89c4\u548c\u7269\u6d41\u7684\u4e25\u91cd\u9650\u5236\u3002", "method": "\u5229\u7528Sherpa.ai\u8054\u90a6\u5b66\u4e60\u5e73\u53f0\uff0c\u5728\u4e24\u4e2a\u56fd\u9645\u7ec4\u7ec7\u7684\u5206\u5e03\u5f0f\u6570\u636e\u96c6\u4e0a\u534f\u540c\u8bad\u7ec3\u6a21\u578b\u3002\u8be5\u6a21\u578b\u57fa\u4e8e\u60a3\u8005\u6210\u7ea4\u7ef4\u7ec6\u80de\u57f9\u517b\u7269\u7684\u80f6\u539fVI\u514d\u75ab\u8367\u5149\u663e\u5fae\u955c\u56fe\u50cf\u8fdb\u884c\u75c5\u7406\u5206\u7c7b\u3002", "result": "\u8be5\u6a21\u578b\u6210\u529f\u5c06COL6-RD\u5206\u7c7b\u4e3a\u4e09\u7c7b\u4e3b\u8981\u81f4\u75c5\u673a\u5236\uff0c\u5176F1\u5206\u6570\u8fbe\u52300.82\uff0c\u663e\u8457\u4f18\u4e8e\u5404\u673a\u6784\u72ec\u7acb\u8bad\u7ec3\u7684\u6a21\u578b\uff080.57-0.75\uff09\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u6709\u6548\u514b\u670d\u4e86\u7f55\u89c1\u75c5\u7814\u7a76\u4e2d\u7684\u6570\u636e\u9e3f\u6c9f\uff0c\u4e3a\u5206\u5e03\u5f0f\u9690\u79c1\u6570\u636e\u7684\u534f\u4f5c\u8bca\u65ad\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\uff0c\u4e0d\u4ec5\u80fd\u8f85\u52a9\u89e3\u91ca\u4e0d\u786e\u5b9a\u610f\u4e49\u7684\u53d8\u5f02\uff0c\u8fd8\u80fd\u6307\u5bfc\u57fa\u56e0\u6d4b\u5e8f\u7b56\u7565\u3002"}}
