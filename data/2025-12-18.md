<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 33]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.LG](#cs.LG) [Total: 61]
- [cs.IT](#cs.IT) [Total: 5]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.GT](#cs.GT) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Incentives or Ontology? A Structural Rebuttal to OpenAI's Hallucination Thesis](https://arxiv.org/abs/2512.14801)
*Richard Ackermann,Simeon Emanuilov*

Main category: cs.CL

TL;DR: 本文分析了大型语言模型中幻觉的根本原因，并指出幻觉是Transformer模型的内在结构缺陷，而非评估激励错位的结果。


<details>
  <summary>Details</summary>
Motivation: 挑战OpenAI关于大型语言模型幻觉是由于评估激励错位导致的观点。作者认为幻觉是Transformer模型固有的结构性问题。

Method: 作者借鉴了之前关于结构性幻觉的研究，并使用“许可预言机（Licensing Oracle）”进行实证实验，以证明幻觉是Transformer模型的必然结果。

Result: 实验结果表明，幻觉只能通过外部的真实性验证和弃权模块来消除，而不能通过改变激励机制、提示或微调。许可预言机通过提供Transformer模型所缺乏的外部基础，实现了完美的弃权精度。

Conclusion: 幻觉是生成式架构的结构性特性，构建可靠的人工智能需要混合系统，该系统能够区分语言流畅性与认知责任。

Abstract: OpenAI has recently argued that hallucinations in large language models result primarily from misaligned evaluation incentives that reward confident guessing rather than epistemic humility. On this view, hallucination is a contingent behavioral artifact, remediable through improved benchmarks and reward structures. In this paper, we challenge that interpretation. Drawing on previous work on structural hallucination and empirical experiments using a Licensing Oracle, we argue that hallucination is not an optimization failure but an architectural inevitability of the transformer model.
  Transformers do not represent the world; they model statistical associations among tokens. Their embedding spaces form a pseudo-ontology derived from linguistic co-occurrence rather than world-referential structure. At ontological boundary conditions - regions where training data is sparse or incoherent - the model necessarily interpolates fictional continuations in order to preserve coherence. No incentive mechanism can modify this structural dependence on pattern completion.
  Our empirical results demonstrate that hallucination can only be eliminated through external truth-validation and abstention modules, not through changes to incentives, prompting, or fine-tuning. The Licensing Oracle achieves perfect abstention precision across domains precisely because it supplies grounding that the transformer lacks.
  We conclude that hallucination is a structural property of generative architectures and that reliable AI requires hybrid systems that distinguish linguistic fluency from epistemic responsibility.

</details>


### [2] [T5Gemma 2: Seeing, Reading, and Understanding Longer](https://arxiv.org/abs/2512.14856)
*Biao Zhang,Paul Suganthan,Gaël Liu,Ilya Philippov,Sahil Dua,Ben Hora,Kat Black,Gus Martins,Omar Sanseviero,Shreya Pathak,Cassidy Hardin,Francesco Visin,Jiageng Zhang,Kathleen Kenealy,Qin Yin,Olivier Lacombe,Armand Joulin,Tris Warkentin,Adam Roberts*

Main category: cs.CL

TL;DR: 介绍了T5Gemma 2，下一代轻量级开放式编解码模型，具有强大的多语言、多模态和长上下文能力。


<details>
  <summary>Details</summary>
Motivation: 在T5Gemma的基础上，通过UL2适应配方将预训练的仅解码器模型转化为编解码模型，并将其从纯文本扩展到多模态，基于Gemma 3模型。

Method: 提出了两种提高效率的方法：共享编码器和解码器所有嵌入的绑定的词嵌入，以及将解码器自注意力和交叉注意力统一为一个联合模块的合并注意力。

Result: 实验证明了这种适应策略在不同架构和模态上的通用性，以及编解码器架构在长上下文建模方面的独特优势。与T5Gemma类似，T5Gemma 2在预训练性能方面与Gemma 3相当或更好，并在后训练性能方面显著提升。

Conclusion: 发布了预训练模型（270M-270M, 1B-1B和4B-4B），以供社区未来研究。

Abstract: We introduce T5Gemma 2, the next generation of the T5Gemma family of lightweight open encoder-decoder models, featuring strong multilingual, multimodal and long-context capabilities. T5Gemma 2 follows the adaptation recipe (via UL2) in T5Gemma -- adapting a pretrained decoder-only model into an encoder-decoder model, and extends it from text-only regime to multimodal based on the Gemma 3 models. We further propose two methods to improve the efficiency: tied word embedding that shares all embeddings across encoder and decoder, and merged attention that unifies decoder self- and cross-attention into a single joint module. Experiments demonstrate the generality of the adaptation strategy over architectures and modalities as well as the unique strength of the encoder-decoder architecture on long context modeling. Similar to T5Gemma, T5Gemma 2 yields comparable or better pretraining performance and significantly improved post-training performance than its Gemma 3 counterpart. We release the pretrained models (270M-270M, 1B-1B and 4B-4B) to the community for future research.

</details>


### [3] [Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media](https://arxiv.org/abs/2512.14887)
*Massimiliano Fadda,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino*

Main category: cs.CL

TL;DR: 这篇论文通过微调大型语言模型（LLMs）并结合从Wikidata中提取的相关行为者的语义描述来改进新闻语料库中观点分类的流程，从而提高分类性能，尤其是在处理长文本输入时。


<details>
  <summary>Details</summary>
Motivation: 新闻来源在民主社会中通过塑造政治和社会话语发挥核心作用，因此理解新闻动态对于评估媒体格局是否提供了平衡公正的公共辩论至关重要。

Method: 作者改进了现有的新闻语料库分析流程，具体方法包括：微调大型语言模型（LLMs）进行观点分类；利用Wikidata中相关行为者的语义描述来丰富声明表示。

Result: 评估结果显示，微调LLMs和丰富声明表示这两种机制都能独立提高分类性能，但它们的结合产生了最佳结果，尤其是在使用能够处理长输入的LLMs时。

Conclusion: 通过结合微调LLMs和利用Wikidata丰富声明表示，可以显著提高新闻语料库中观点分类的准确性，这对于理解和评估媒体在公共辩论中的作用具有重要意义。

Abstract: News sources play a central role in democratic societies by shaping political and social discourse through specific topics, viewpoints and voices. Understanding these dynamics is essential for assessing whether the media landscape offers a balanced and fair account of public debate. In earlier work, we introduced a pipeline that, given a news corpus, i) uses a hybrid human-machine approach to identify the range of viewpoints expressed about a given topic, and ii) classifies relevant claims with respect to the identified viewpoints, defined as sets of semantically and ideologically congruent claims (e.g., positions arguing that immigration positively impacts the UK economy). In this paper, we improve this pipeline by i) fine-tuning Large Language Models (LLMs) for viewpoint classification and ii) enriching claim representations with semantic descriptions of relevant actors drawn from Wikidata. We evaluate our approach against alternative solutions on a benchmark centred on the UK immigration debate. Results show that while both mechanisms independently improve classification performance, their integration yields the best results, particularly when using LLMs capable of processing long inputs.

</details>


### [4] [DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline](https://arxiv.org/abs/2512.14896)
*Houman Kazemzadeh,Kiarash Mokhtari Dizaji,Seyed Reza Tavakoli,Farbod Davoodi,MohammadReza KarimiNejad,Parham Abed Azad,Ali Sabzi,Armin Khosravi,Siavash Ahmadi,Mohammad Hossein Rohban,Glolamali Aminian,Tahereh Javaheri*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在药学许可风格问答任务上的表现，并通过开发一种名为 DrugRAG 的外部知识整合方法显著提高了它们的准确性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在药学执业考试风格问答任务中的表现，并开发一种外部知识整合方法来提高其准确性。

Method: 使用141个药学数据集对11个不同参数大小的现有大型语言模型进行基准测试。然后，开发了一个名为 DrugRAG 的三步检索增强生成（RAG）流程，该流程从经过验证的来源中检索结构化的药物知识，并用循证上下文增强模型提示。

Result: 基线准确率从46%到92%不等，GPT-5（92%）和o3（89%）得分最高。DrugRAG将所有测试模型的准确率提高了7到21个百分点。

Conclusion: 通过 DrugRAG 整合外部结构化药物知识，可以在不修改底层模型的情况下，显著提高大型语言模型在药学任务上的准确性，为增强药学领域的 AI 应用提供了实用的方法。

Abstract: Objectives: To evaluate large language model (LLM) performance on pharmacy licensure-style question-answering (QA) tasks and develop an external knowledge integration method to improve their accuracy.
  Methods: We benchmarked eleven existing LLMs with varying parameter sizes (8 billion to 70+ billion) using a 141-question pharmacy dataset. We measured baseline accuracy for each model without modification. We then developed a three-step retrieval-augmented generation (RAG) pipeline, DrugRAG, that retrieves structured drug knowledge from validated sources and augments model prompts with evidence-based context. This pipeline operates externally to the models, requiring no changes to model architecture or parameters.
  Results: Baseline accuracy ranged from 46% to 92%, with GPT-5 (92%) and o3 (89%) achieving the highest scores. Models with fewer than 8 billion parameters scored below 50%. DrugRAG improved accuracy across all tested models, with gains ranging from 7 to 21 percentage points (e.g., Gemma 3 27B: 61% to 71%, Llama 3.1 8B: 46% to 67%) on the 141-item benchmark.
  Conclusion: We demonstrate that external structured drug knowledge integration through DrugRAG measurably improves LLM accuracy on pharmacy tasks without modifying the underlying models. This approach provides a practical pipeline for enhancing pharmacy-focused AI applications with evidence-based information.

</details>


### [5] [Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models](https://arxiv.org/abs/2512.14926)
*George-Andrei Dima,Dumitru-Clementin Cercel*

Main category: cs.CL

TL;DR: 这篇论文通过将Flickr30k数据集翻译成罗马尼亚语并利用开源大型语言模型对其进行扩展，创建了罗马尼亚语多模态NLP数据集。作者使用LoRA方法对三种不同的视觉语言模型（LLaMA 3.2、LLaVA 1.6和Qwen2）进行了微调，并在罗马尼亚语视觉问答和图像描述生成任务上展示了显著的性能提升和语法错误减少。


<details>
  <summary>Details</summary>
Motivation: 目前生成式人工智能在低资源语言方面的研究较少，而低资源语言却是生成式人工智能普及化的重要一步。

Method: 本研究将Flickr30k数据集翻译成罗马尼亚语，并利用开源大型语言模型将其扩展到视觉问答（VQA）领域，从而创建了罗马尼亚语多模态NLP数据集。在此基础上，研究人员选择了LLaMA 3.2、LLaVA 1.6和Qwen2这三种广泛使用的模型家族，并采用参数高效的LoRA方法对它们进行了微调，使其适应罗马尼亚语VQA任务。

Result: 作者的这组模型在罗马尼亚语视觉问答任务以及未训练过的罗马尼亚语图像描述生成任务上都显示出改进。其中，70亿参数的Qwen2-VL-RoVQA模型在这两项任务上均取得了最高分，BERTScore F1比其原始版本分别提高了6.05%和2.61%。此外，与原始模型相比，微调后的模型在语法错误方面显著减少，表明在语言理解和罗马尼亚语流利度方面都有所提高。

Conclusion: 本论文成功构建了罗马尼亚语多模态NLP数据集，并通过对现有视觉语言模型进行微调，显著提升了其在罗马尼亚语视觉问答和图像描述生成方面的能力。研究结果表明，通过针对低资源语言进行数据和模型优化，可以有效弥补多模态NLP领域的资源差距，并提高模型的语言理解和表达流畅性。

Abstract: Focusing on low-resource languages is an essential step toward democratizing generative AI. In this work, we contribute to reducing the multimodal NLP resource gap for Romanian. We translate the widely known Flickr30k dataset into Romanian and further extend it for visual question answering by leveraging open-source LLMs. We demonstrate the usefulness of our datasets by fine-tuning open-source VLMs on Romanian visual question answering. We select VLMs from three widely used model families: LLaMA 3.2, LLaVA 1.6, and Qwen2. For fine-tuning, we employ the parameter-efficient LoRA method. Our models show improved Romanian capabilities in visual QA, as well as on tasks they were not trained on, such as Romanian image description generation. The seven-billion-parameter Qwen2-VL-RoVQA obtains top scores on both tasks, with improvements of +6.05% and +2.61% in BERTScore F1 over its original version. Finally, the models show substantial reductions in grammatical errors compared to their original forms, indicating improvements not only in language understanding but also in Romanian fluency.

</details>


### [6] [Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams](https://arxiv.org/abs/2512.14989)
*Yiming Cui,Xin Yao,Yuxuan Qin,Xin Li,Shijin Wang,Guoping Hu*

Main category: cs.CL

TL;DR: 本文评估了多模态大语言模型在化学领域的科学推理能力，发现它们在模态融合和视觉接地方面存在不足，并提出了改进策略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多模态科学推理方面面临挑战，尤其是在化学领域。

Method: 本文系统评估了40个专有和开源的多模态大语言模型，包括GPT-4o, Gemini-1.5-Pro等，通过美国国家化学奥林匹克竞赛（USNCO）的奥林匹克式化学问题进行测试。

Result: 许多模型在模态融合方面表现不佳，有时移除图像甚至能提高准确性；思维链（Chain-of-Thought）提示能显著提高准确性和视觉接地能力。

Conclusion: 目前的多模态大语言模型在科学推理能力方面存在明显局限性，需要发展更强大和可解释的多模态系统。

Abstract: Multimodal scientific reasoning remains a significant challenge for large language models (LLMs), particularly in chemistry, where problem-solving relies on symbolic diagrams, molecular structures, and structured visual data. Here, we systematically evaluate 40 proprietary and open-source multimodal LLMs, including GPT-5, o3, Gemini-2.5-Pro, and Qwen2.5-VL, on a curated benchmark of Olympiad-style chemistry questions drawn from over two decades of U.S. National Chemistry Olympiad (USNCO) exams. These questions require integrated visual and textual reasoning across diverse modalities. We find that many models struggle with modality fusion, where in some cases, removing the image even improves accuracy, indicating misalignment in vision-language integration. Chain-of-Thought prompting consistently enhances both accuracy and visual grounding, as demonstrated through ablation studies and occlusion-based interpretability. Our results reveal critical limitations in the scientific reasoning abilities of current MLLMs, providing actionable strategies for developing more robust and interpretable multimodal systems in chemistry. This work provides a timely benchmark for measuring progress in domain-specific multimodal AI and underscores the need for further advances at the intersection of artificial intelligence and scientific reasoning.

</details>


### [7] [DASH: Dialogue-Aware Similarity and Handshake Recognition for Topic Segmentation in Public-Channel Conversations](https://arxiv.org/abs/2512.15042)
*Sijin Sun,Liangbin Zhao,Ming Deng,Xiuju Fu*

Main category: cs.CL

TL;DR: DASH-DTS是一个新的基于LLM的框架，通过对话握手识别、相似性引导的示例选择和生成选择性正负样本来解决非正式语音和隐式转换带来的挑战，从而改进对话主题分割。它在VHF-Dial和标准基准上都取得了最先进的分割准确率。


<details>
  <summary>Details</summary>
Motivation: 对话主题分割（DTS）对于理解任务导向的公共信道通信至关重要，特别是像海上甚高频（VHF）对话这种具有非正式语音和隐式转换的场景。传统方法在这种情况下存在局限性，因此需要一种新的方法来克服这些挑战。

Method: DASH-DTS框架的核心贡献包括：1. 通过对话握手识别实现主题转换检测；2. 通过相似性引导的示例选择进行上下文增强；3. 生成选择性的正负样本以提高模型的辨别力和鲁棒性。此外，该论文发布了VHF-Dial数据集。

Result: DASH-DTS框架在VHF-Dial数据集和标准基准测试上均取得了最先进的分割准确率，并为每个段提供了可解释的推理和置信度分数。这表明该框架在操作对话中为稳定监控和决策支持奠定了坚实的基础。

Conclusion: DASH-DTS通过其创新的LLM驱动方法，显著提高了对话主题分割在非正式和隐式对话场景中的性能，并在现实世界的海上通信中展示了优越的鲁棒性和准确性，为未来的研究和应用提供了重要的资源（VHF-Dial数据集）。

Abstract: Dialogue Topic Segmentation (DTS) is crucial for understanding task-oriented public-channel communications, such as maritime VHF dialogues, which feature informal speech and implicit transitions. To address the limitations of traditional methods, we propose DASH-DTS, a novel LLM-based framework. Its core contributions are: (1) topic shift detection via dialogue handshake recognition; (2) contextual enhancement through similarity-guided example selection; and (3) the generation of selective positive and negative samples to improve model discrimination and robustness. Additionally, we release VHF-Dial, the first public dataset of real-world maritime VHF communications, to advance research in this domain. DASH-DTS provides interpretable reasoning and confidence scores for each segment. Experimental results demonstrate that our framework achieves several sota segmentation trusted accuracy on both VHF-Dial and standard benchmarks, establishing a strong foundation for stable monitoring and decision support in operational dialogues.

</details>


### [8] [SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification](https://arxiv.org/abs/2512.15052)
*Hongbo Wang,MaungMaung AprilPyone,Isao Echizen*

Main category: cs.CL

TL;DR: SGM是一种针对多模态大语言模型（MLLMs）中通过识别和抑制有害神经元来降低毒性的方法，旨在提高安全性并保持性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）由于预训练数据集中存在的毒性、偏见和不适宜内容，存在安全隐患，尤其是在对抗性触发下，传统的去毒方法难以有效处理。

Method: 本文提出了SGM，一种白盒神经元级别的多模态干预方法。其作用类似于毒性神经元的安全眼镜：通过专业知识加权的软抑制，选择性地重新校准少量毒性专家神经元，从而中和有害的跨模态激活，而无需更新任何参数。此外，本文还建立了MM-TOXIC-QA，一个多模态毒性评估框架。

Result: 实验结果表明，SGM在标准和对抗条件下都能有效缓解毒性，将有害内容生成率从48.2%降低到2.5%，同时保持了流畅性和多模态推理能力。

Conclusion: SGM提供了一种可解释、低成本的解决方案，用于控制多模态内容的毒性生成。SGM具有可扩展性，并且其组合防御SGM*可以与现有的去毒方法集成，以实现更强的安全性能。

Abstract: Disclaimer: Samples in this paper may be harmful and cause discomfort.
  Multimodal large language models (MLLMs) enable multimodal generation but inherit toxic, biased, and NSFW signals from weakly curated pretraining corpora, causing safety risks, especially under adversarial triggers that late, opaque training-free detoxification methods struggle to handle. We propose SGM, a white-box neuron-level multimodal intervention that acts like safety glasses for toxic neurons: it selectively recalibrates a small set of toxic expert neurons via expertise-weighted soft suppression, neutralizing harmful cross-modal activations without any parameter updates. We establish MM-TOXIC-QA, a multimodal toxicity evaluation framework, and compare SGM with existing detoxification techniques. Experiments on open-source MLLMs show that SGM mitigates toxicity in standard and adversarial conditions, cutting harmful rates from 48.2\% to 2.5\% while preserving fluency and multimodal reasoning. SGM is extensible, and its combined defenses, denoted as SGM*, integrate with existing detoxification methods for stronger safety performance, providing an interpretable, low-cost solution for toxicity-controlled multimodal generation.

</details>


### [9] [The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops](https://arxiv.org/abs/2512.15053)
*Fanzhe Fu*

Main category: cs.CL

TL;DR: 本文介绍了一种名为“元提示协议”的理论框架，旨在将大型语言模型从随机聊天界面转变为可靠的软件组件，通过形式化编排大型语言模型，使其成为可编程、自优化的系统。


<details>
  <summary>Details</summary>
Motivation: 目前以启发式“提示工程”为主的方法无法为关键任务应用提供确定性保证，因此需要对交互范式进行根本性改造。

Method: 引入了“元提示协议”，一个严格的理论框架，将大型语言模型的编排形式化为一个可编程、自优化的系统。协议的核心是“对抗三元组”，一个由生成器 (P)、审计器 (A) 和优化器 (O) 组成的三方拓扑结构。通过将自然语言指令视为语义计算图中的可微分变量，并利用文本批评作为梯度，该架构可减少幻觉并防止模型崩溃。

Result: 通过声明式编程范式 (DSPy) 和自动文本微分 (TextGrad) 证明了该方法的理论可行性，为概率计算时代的“可观察软件工程”奠定了基础。

Conclusion: “元提示协议”提供了一种将大型语言模型转化为可靠软件组件的理论框架，有望解决当前提示工程的局限性，并为未来的软件工程实践奠定基础。

Abstract: The transition of Large Language Models (LLMs) from stochastic chat interfaces to reliable software components necessitates a fundamental re-engineering of interaction paradigms. Current methodologies, predominantly heuristic-based "prompt engineering," fail to provide the deterministic guarantees required for mission-critical applications. We introduce the Meta-Prompting Protocol, a rigorous theoretical framework that formalizes the orchestration of LLMs as a programmable, self-optimizing system. Central to this protocol is the Adversarial Trinity, a tripartite topology comprising a Generator (P), an Auditor (A), and an Optimizer (O). By treating natural language instructions as differentiable variables within a semantic computation graph and utilizing textual critiques as gradients, this architecture mitigates hallucination and prevents model collapse. We demonstrate the theoretical viability of this approach using declarative programming paradigms (DSPy) and automatic textual differentiation (TextGrad), establishing a foundation for "Observable Software Engineering" in the era of probabilistic computing.

</details>


### [10] [Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning](https://arxiv.org/abs/2512.15146)
*Weiqin Wang,Yile Wang,Kehao Chen,Hui Huang*

Main category: cs.CL

TL;DR: 本文提出了一种名为 SCOPE 的新框架，通过整合模型置信度和动态子组划分来解决现有测试时强化学习策略中的确认偏差和奖励稀疏问题，从而在多个基准测试中显著提高了大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时强化学习方法依赖多数投票结果作为伪标签，这会导致确认偏差和奖励稀疏问题，从而限制了大型语言模型推理能力的提升。

Method: 本文提出子组特异性分步置信度加权伪标签估计（SCOPE）框架。 SCOPE 将分步置信度融入伪标签推导中，优先考虑高质量的推理路径。此外，它通过平衡推理质量和探索多样性，将候选输出池动态划分为独立的子组。通过对每个子组重复采样得出局部共识，SCOPE 提供了多样化的监督目标，以鼓励更广泛的探索。

Result: SCOPE 在各种模型和基准测试中进行实验，结果表明它始终优于最近的基线。值得注意的是，SCOPE 在具有挑战性的 AIME 2025 上实现了 13.1% 的相对改进，在 AMC 上实现了 8.1% 的相对改进。

Conclusion: SCOPE 框架通过有效解决现有测试时强化学习中的确认偏差和奖励稀疏问题，显著提高了大型语言模型的推理能力。

Abstract: Test-time reinforcement learning mitigates the reliance on annotated data by using majority voting results as pseudo-labels, emerging as a complementary direction to reinforcement learning with verifiable rewards (RLVR) for improving reasoning ability of large language models (LLMs). However, this voting strategy often induces confirmation bias and suffers from sparse rewards, limiting the overall performance. In this work, we propose subgroup-specific step-wise confidence-weighted pseudo-label estimation (SCOPE), a framework integrating model confidence and dynamic subgroup partitioning to address these issues. Specifically, SCOPE integrates the proposed step-wise confidence into pseudo label deduction, prioritizing high-quality reasoning paths over simple frequency count. Furthermore, it dynamically partitions the candidate outputs pool into independent subgroups by balancing reasoning quality against exploration diversity. By deriving local consensus via repeat sampling for each sub group, SCOPE provides diverse supervision targets to encourage broader exploration. We conduct experiments across various models and benchmarks, experimental results show that SCOPE consistently outperforms recent baselines. Notably, SCOPE achieving relative improvements of 13.1\% on challenging AIME 2025 and 8.1\% on AMC. The code is released at \href{https://github.com/szu-tera/SCOPE}{https://github.com/szu-tera/SCOPE}.

</details>


### [11] [Rakuten Data Release: A Large-Scale and Long-Term Reviews Corpus for Hotel Domain](https://arxiv.org/abs/2512.15151)
*Yuki Nakayama,Koki Hikichi,Yun Ching Liu,Yu Hirate*

Main category: cs.CL

TL;DR: 本文介绍了乐天旅行评论的大规模语料库，包含2009年至2024年间的730万条评论，并分析了2019年至2024年数据漂移的影响因素。


<details>
  <summary>Details</summary>
Motivation: 构建一个大规模的旅行评论语料库，并分析其中的数据漂移现象。

Method: 收集并整理乐天旅行评论数据，进行统计分析，并运用统计方法分析数据漂移。

Result: 收集了730万条乐天旅行评论，包含了评论文本、回复、匿名评论者ID、评论日期、住宿ID、计划ID、计划标题、房间类型、房间名称、目的、同行群体、用户评分和总体评分等信息。并揭示了2019年至2024年数据漂移的影响因素。

Conclusion: 本文成功构建了一个大规模旅行评论语料库，并对数据漂移进行了深入分析，为相关研究提供了宝贵资源。

Abstract: This paper presents a large-scale corpus of Rakuten Travel Reviews. Our collection contains 7.3 million customer reviews for 16 years, ranging from 2009 to 2024. Each record in the dataset contains the review text, its response from an accommodation, an anonymized reviewer ID, review date, accommodation ID, plan ID, plan title, room type, room name, purpose, accompanying group, and user ratings from different aspect categories, as well as an overall score. We present statistical information about our corpus and provide insights into factors driving data drift between 2019 and 2024 using statistical approaches.

</details>


### [12] [From NLG Evaluation to Modern Student Assessment in the Era of ChatGPT: The Great Misalignment Problem and Pedagogical Multi-Factor Assessment (P-MFA)](https://arxiv.org/abs/2512.15183)
*Mika Hämäläinen,Kimmo Leiviskä*

Main category: cs.CL

TL;DR: 本文探讨了自然语言生成（NLG）评估与芬兰大学学生评分之间日益增长的认知相似性，并提出了解决“巨大错位问题”的教学多因素评估（P-MFA）模型。


<details>
  <summary>Details</summary>
Motivation: 随着学生越来越多地使用ChatGPT等工具生成复杂的任务输出，传统评估方法（侧重于最终结果而非学习过程）的有效性降低，导致NLG评估和学生评分都面临着“巨大错位问题”。

Method: 本文提出了教学多因素评估（P-MFA）模型。该模型是一种基于过程、多证据的框架，其灵感来源于多因素认证的逻辑。

Result: P-MFA模型旨在通过关注学习过程而非仅仅最终产品来解决传统评估方法的失效问题。

Conclusion: P-MFA模型可以作为一种新的评估范式，以应对学生使用先进AI工具所带来的挑战，并恢复评估的有效性。

Abstract: This paper explores the growing epistemic parallel between NLG evaluation and grading of students in a Finnish University. We argue that both domains are experiencing a Great Misalignment Problem. As students increasingly use tools like ChatGPT to produce sophisticated outputs, traditional assessment methods that focus on final products rather than learning processes have lost their validity. To address this, we introduce the Pedagogical Multi-Factor Assessment (P-MFA) model, a process-based, multi-evidence framework inspired by the logic of multi-factor authentication.

</details>


### [13] [RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA](https://arxiv.org/abs/2512.15219)
*Chao Zhang,Minghan Li,Tianrui Lv,Guodong Zhou*

Main category: cs.CL

TL;DR: RFKG-CoT通过自适应跳数选择和思维链路径引导，显著提高了LLMs在知识图谱问答中的准确性，有效解决了幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在知识密集型问答中常因参数化知识限制产生“幻觉”。现有方法如KG-CoT通过整合知识图谱（KG）路径来提高可靠性，但其存在跳数选择僵化（仅由问题驱动）和推理路径利用不足（缺乏指导）的问题。

Method: RFKG-CoT方法首先用关系驱动的自适应跳数选择器取代了僵化的跳数选择器，通过激活KG关系（例如，直接“兄弟”关系使用1跳，间接“父子”链使用2跳）动态调整推理步骤，并通过关系掩码实现形式化。其次，引入了少量样本上下文学习的路径指导机制与思维链（CoT），以“问题-路径-答案”的格式构建示例，增强LLMs理解推理路径的能力。

Result: 在四个KGQA基准测试中，RFKG-CoT将（Llama2-7B在WebQSP上的）准确率相对于KG-CoT提高了14.7个百分点。消融实验证实，跳数选择器和路径提示是互补的，共同将KG证据转化为更忠实的答案。

Conclusion: RFKG-CoT通过创新的自适应跳数选择器和上下文学习的路径引导机制，有效克服了现有KG-CoT方法的局限性，显著提升了大型语言模型在知识图谱问答任务中的准确性和可靠性，为解决LLMs的“幻觉”问题提供了有效途径。

Abstract: Large language models (LLMs) often generate hallucinations in knowledge-intensive QA due to parametric knowledge limitations. While existing methods like KG-CoT improve reliability by integrating knowledge graph (KG) paths, they suffer from rigid hop-count selection (solely question-driven) and underutilization of reasoning paths (lack of guidance). To address this, we propose RFKG-CoT: First, it replaces the rigid hop-count selector with a relation-driven adaptive hop-count selector that dynamically adjusts reasoning steps by activating KG relations (e.g., 1-hop for direct "brother" relations, 2-hop for indirect "father-son" chains), formalized via a relation mask. Second, it introduces a few-shot in-context learning path guidance mechanism with CoT (think) that constructs examples in a "question-paths-answer" format to enhance LLMs' ability to understand reasoning paths. Experiments on four KGQA benchmarks show RFKG-CoT improves accuracy by up to 14.7 pp (Llama2-7B on WebQSP) over KG-CoT. Ablations confirm the hop-count selector and the path prompt are complementary, jointly transforming KG evidence into more faithful answers.

</details>


### [14] [Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024](https://arxiv.org/abs/2512.15226)
*Yash Bhaskar,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 该论文介绍了Yes-MT团队在WMT 2024低资源印度语言翻译共享任务中提交的系统，主要关注英语与阿萨姆语、米佐语、卡西语和曼尼普尔语之间的翻译。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决低资源印度语言翻译的挑战，并探索不同模型和方法在这些语言对上的翻译效果。

Method: 实验方法包括：1. 微调预训练模型（如mT5和IndicBart），在多语言和单语言环境下进行。2. 使用LoRA技术微调IndicTrans2。3. 采用零样本和少样本提示，使用Llama 3和Mixtral 8x7b等大型语言模型（LLMs）。4. 对Llama 3进行LoRA监督微调。5. 从头开始训练Transformer模型。

Result: 研究结果在WMT23低资源印度语言翻译共享任务的测试数据上，使用SacreBLEU和CHRF进行评估。结果突出了低资源翻译的挑战以及大型语言模型（特别是经过微调的LLMs）在这些任务中的潜力。

Conclusion: 该论文强调了低资源印度语言翻译的复杂性，并表明通过集成和微调现有的大型语言模型，可以有效提升此类翻译任务的性能。

Abstract: This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024 (Pakray et al., 2024), focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, including fine-tuning pre-trained models like mT5 (Xue et al., 2020) and IndicBart (Dabre et al., 2021) in both multilingual and monolingual settings, LoRA (Hu et al., 2021) fine-tuning IndicTrans2 (Gala et al., 2023), zero-shot and few-shot prompting (Brown, 2020) with large language models (LLMs) like Llama 3 (Dubey et al., 2024) and Mixtral 8x7b (Jiang et al., 2024), LoRA supervised fine-tuning of Llama 3 (Mecklenburg et al., 2024), and training Transformer models (Vaswani, 2017) from scratch. The results were evaluated on the WMT23 Low-Resource Indic Language Translation Shared Task test data using SacreBLEU (Post, 2018) and CHRF (Popovic, 2015), highlighting the challenges of low-resource translation and the potential of LLMs for these tasks, particularly with fine-tuning.

</details>


### [15] [FAME: Fictional Actors for Multilingual Erasure](https://arxiv.org/abs/2512.15235)
*Claudio Savelli,Moreno La Quatra,Alkis Koudounas,Flavio Giobergia*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为 FAME 的多语言基准，用于评估大型语言模型的机器遗忘能力，解决了现有基准的局限性，并实现了实体级和实例级的遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有的用于评估大型语言模型遗忘能力的基准存在两个主要限制：1. 仅关注英语。2. 仅支持实体级别的遗忘（删除关于某个人的所有信息）。

Method: 论文引入了 FAME（Fictional Actors for Multilingual Erasure），一个用于评估五种语言（英语、法语、德语、意大利语和西班牙语）机器遗忘的合成基准。FAME 包含 1,000 个虚构演员的传记和 20,000 个问答对。每个传记包含 20 个按结构化类别组织的主题信息。设计了两个数据集拆分以支持实体级遗忘和实例级遗忘，并实现在不同语言间对遗忘技术进行系统比较。

Result: FAME 能够同时实现实体级遗忘（例如，遗忘整个身份）和实例级遗忘（例如，遗忘特定事实同时保留其他事实）。由于 FAME 使用完全虚构的数据，确保了这些信息在模型预训练期间从未出现过，从而可以对遗忘方法进行受控评估。

Conclusion: FAME 为多语言大型语言模型的机器遗忘评估提供了一个全面且受控的基准，支持对特定信息进行细粒度遗忘，并促进了跨语言遗忘技术的系统比较。

Abstract: LLMs trained on web-scale data raise concerns about privacy and the right to be forgotten. To address these issues, Machine Unlearning provides techniques to remove specific information from trained models without retraining from scratch. However, existing benchmarks for evaluating unlearning in LLMs face two major limitations: they focus only on English and support only entity-level forgetting (removing all information about a person). We introduce FAME (Fictional Actors for Multilingual Erasure), a synthetic benchmark for evaluating Machine Unlearning across five languages: English, French, German, Italian, and Spanish. FAME contains 1,000 fictional actor biographies and 20,000 question-answer pairs. Each biography includes information on 20 topics organized into structured categories (biography, career, achievements, personal information). This design enables both entity-level unlearning (i.e., forgetting entire identities) and instance-level unlearning (i.e., forgetting specific facts while retaining others). We provide two dataset splits to support these two different unlearning scenarios and enable systematic comparison of unlearning techniques across languages. Since FAME uses entirely fictional data, it ensures that the information was never encountered during model pretraining, allowing for a controlled evaluation of unlearning methods.

</details>


### [16] [SynGP500: A Clinically-Grounded Synthetic Dataset of Australian General Practice Medical Notes](https://arxiv.org/abs/2512.15259)
*Piyawoot Songsiritat*

Main category: cs.CL

TL;DR: SynGP500是一个包含500份合成澳大利亚全科医疗记录的数据集，旨在通过整合课程广度、流行病学校准和多样化的咨询情境，为临床NLP模型训练提供支持，其特点是设计上模拟真实医疗记录的“混乱”，并通过多方面验证证实了其质量和实用性。


<details>
  <summary>Details</summary>
Motivation: 目前的全科医疗NLP模型训练数据集存在局限性，可能无法充分覆盖常见和不常见的疾病，且数据可能过于“整洁”而无法反映真实的临床复杂性。SynGP500旨在解决这一关键的国家性空白，提供一个更具代表性、能保护患者隐私且包含真实世界复杂性的数据集，以支持澳大利亚全科医疗领域的临床NLP方法开发和评估。

Method: SynGP500数据集的构建方法包括：1. **临床医生策划**：由临床医生筛选和整合数据。2. **整合课程广度**：遵循RACGP 2022课程标准，确保涵盖临床知识的广度。3. **流行病学校准**：根据BEACH研究数据，校准疾病患病率，使其符合真实的澳大利亚全科实践模式。4. **多样化咨询情境**：集成多种临床咨询背景。5. **模拟真实世界的“混乱”**：故意包含电报式记录、拼写错误、患者依从性差、社会经济障碍以及医患分歧等真实医疗记录中的复杂性和不规范性。

Result: SynGP500数据集通过多方面验证：1. **流行病学一致性**：与真实的澳大利亚全科咨询模式（BEACH研究）高度一致。2. **文体计量学分析**：确认了高度的语言多样性。3. **语义多样性分析**：证实了广泛的覆盖范围。4. **下游评估**：在自监督医学概念提取方面，F1分数有所提高，表明其在支持NLP任务方面的有效性。

Conclusion: SynGP500数据集通过独特的构建方法，解决了现有临床NLP数据集在覆盖范围、真实性和隐私保护方面的不足。它提供了一个高质量、高代表性、且具有真实世界复杂性的数据集，弥补了澳大利亚全科医疗领域的一个关键空白，将有力支持研究人员和教育工作者开发和评估澳大利亚全科医疗的临床NLP方法，同时确保患者隐私。

Abstract: We introduce SynGP500, a clinician-curated collection of 500 synthetic Australian general practice medical notes. The dataset integrates curriculum-based clinical breadth (RACGP 2022 Curriculum), epidemiologically-calibrated prevalence (BEACH study), and diverse consultation contexts. This approach systematically includes both common presentations and less-common curriculum-specified conditions that GPs must recognize but appear infrequently in single practice populations, potentially supporting more generalizable model training than datasets constrained by naturally occurring case distributions. SynGP500 is messy by design, reflecting the authentic complexity of healthcare delivery: telegraphic documentation, typos, patient non-adherence, socioeconomic barriers, and clinician-patient disagreements, unlike sanitized synthetic datasets that obscure clinical realities. Multi-faceted validation demonstrates dataset quality through epidemiological alignment with real Australian GP consultation patterns (BEACH study), stylometric analysis confirming high linguistic variation, semantic diversity analysis demonstrating broad coverage, and exploratory downstream evaluation using self-supervised medical concept extraction, showing F1 improvements. SynGP500 addresses a critical national gap, providing researchers and educators with a resource for developing and evaluating clinical NLP methods for Australian general practice while inherently protecting patient privacy.

</details>


### [17] [Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning](https://arxiv.org/abs/2512.15274)
*Yiliu Sun,Zicheng Zhao,Yang Wei,Yanfang Zhang,Chen Gong*

Main category: cs.CL

TL;DR: 该论文提出了一种名为PPPO的强化学习方法，通过关注生成内容的前缀部分，提高了大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前的强化学习方法在训练大型语言模型时，对所有生成的tokens进行统一训练，而忽略了哪些tokens对推理真正有贡献，导致训练效率低下。

Method: PPPO方法的核心思想是“起始锁定效应”（Beginning Lock-in Effect），即早期思考对后续思考过程有显著影响。PPPO通过渐进式前缀保留和延续累积奖励两种训练策略，专注于优化大型语言模型推理过程的前缀部分。

Result: PPPO在各种推理任务上的表现优于其他RLVR方法，在仅使用26.17%的训练tokens时，准确率提高了18.02%。

Conclusion: PPPO通过优化大型语言模型推理的前缀部分，显著提高了模型的推理能力和训练效率。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which tokens (e.g., prefix tokens) actually contribute to reasoning. This uniform training strategy spends substantial effort on optimizing low-return tokens, which in turn impedes the potential improvement from high-return tokens and reduces overall training effectiveness. To address this issue, we propose a novel RLVR approach called Progressive Prefix-token Policy Optimization (PPPO), which highlights the significance of the prefix segment of generated outputs. Specifically, inspired by the well-established human thinking theory of Path Dependence, where early-stage thoughts substantially constrain subsequent thinking trajectory, we identify an analogous phenomenon in LLM reasoning termed Beginning Lock-in Effect (BLE). PPPO leverages this finding by focusing its optimization objective on the prefix reasoning process of LLMs. This targeted optimization strategy can positively influence subsequent reasoning processes, and ultimately improve final results. To improve the learning effectiveness of LLMs on how to start reasoning with high quality, PPPO introduces two training strategies: (a) Progressive Prefix Retention, which shapes a progressive learning process by increasing the proportion of retained prefix tokens during training; (b) Continuation Accumulated Reward, which mitigates reward bias by sampling multiple continuations for one prefix token sequence, and accumulating their scores as the reward signal. Extensive experimental results on various reasoning tasks demonstrate that our proposed PPPO outperforms representative RLVR methods, with the accuracy improvements of 18.02% on only 26.17% training tokens.

</details>


### [18] [Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies](https://arxiv.org/abs/2512.15312)
*Charan Prakash Rathore,Saumi Ray,Dhruv Kumar*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）在沸石合成实验程序中提取结构化信息的性能，发现LLMs在事件类型分类方面表现良好，但在细粒度提取任务中表现一般，且对提示敏感，揭示了LLMs在此类任务中存在固有的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法尚未系统评估大型语言模型（LLMs）在沸石合成实验程序结构化信息提取这一特定领域任务中的表现。因此，本文旨在解决一个基本问题：在应用LLMs进行科学信息提取时，不同提示策略的效力如何？

Method: 作者专注于四个关键子任务：事件类型分类（识别合成步骤）、触发文本识别（定位事件提及）、参数角色提取（识别参数类型）和参数文本提取（提取参数值）。评估了四种提示策略（零样本、少样本、事件特定和基于反射）在六个最先进的LLMs（Gemma-3-12b-it、GPT-5-mini、O4-mini、Claude-Haiku-3.5、DeepSeek推理和非推理）上的性能，并使用了包含1,530个标注句子的ZSEE数据集。

Result: 结果表明，LLMs在事件类型分类上表现出色（80-90% F1），但在细粒度提取任务上表现一般，尤其是在参数角色和参数文本提取上（50-65% F1）。GPT-5-mini表现出极端的提示敏感性，F1值波动范围为11-79%。值得注意的是，先进的提示策略相比零样本方法改进甚微，揭示了LLMs固有的架构局限性。错误分析发现，LLMs存在系统性幻觉、过度泛化以及无法捕捉合成特定细微差别的问题。

Conclusion: LLMs在沸石合成实验程序的结构化信息提取中，在高级理解方面表现良好，但在精确提取实验参数方面仍需领域适应的模型。本文为科学信息提取提供了量化基准，并揭示了LLMs在此类任务中的局限性和改进方向。

Abstract: Extracting structured information from zeolite synthesis experimental procedures is critical for materials discovery, yet existing methods have not systematically evaluated Large Language Models (LLMs) for this domain-specific task. This work addresses a fundamental question: what is the efficacy of different prompting strategies when applying LLMs to scientific information extraction? We focus on four key subtasks: event type classification (identifying synthesis steps), trigger text identification (locating event mentions), argument role extraction (recognizing parameter types), and argument text extraction (extracting parameter values). We evaluate four prompting strategies - zero-shot, few-shot, event-specific, and reflection-based - across six state-of-the-art LLMs (Gemma-3-12b-it, GPT-5-mini, O4-mini, Claude-Haiku-3.5, DeepSeek reasoning and non-reasoning) using the ZSEE dataset of 1,530 annotated sentences. Results demonstrate strong performance on event type classification (80-90\% F1) but modest performance on fine-grained extraction tasks, particularly argument role and argument text extraction (50-65\% F1). GPT-5-mini exhibits extreme prompt sensitivity with 11-79\% F1 variation. Notably, advanced prompting strategies provide minimal improvements over zero-shot approaches, revealing fundamental architectural limitations. Error analysis identifies systematic hallucination, over-generalization, and inability to capture synthesis-specific nuances. Our findings demonstrate that while LLMs achieve high-level understanding, precise extraction of experimental parameters requires domain-adapted models, providing quantitative benchmarks for scientific information extraction.

</details>


### [19] [Why Your Academic Field Is Everywhere at Once: A Case Study of Arabic Linguistics](https://arxiv.org/abs/2512.15328)
*Ayman Eddakrouri,Amani Ramadan*

Main category: cs.CL

TL;DR: 该研究使用Brookes的分类离散度（Δ）分析了当代阿拉伯应用语言学研究的主题结构。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探究阿拉伯应用语言学研究领域的主题结构，并通过Brookes的分类离散度（Δ）衡量其离散程度。

Method: 收集了2019年至2025年1564篇出版物的数据集，将其分为八个核心子学科，并计算出离散度指数Δ = 0.194。

Result: 计算出的Δ值为0.194，表明该领域存在极端的主题离散性，呈现出显著的异质性而非集中性。计算语言学是主导力量，但并非霸权，社会语言学、语言教学等子领域的研究也十分活跃。

Conclusion: 该研究明确了Brookes原始公式的正确应用，展示了其在领域特征描述方面的效用，并为评估不同领域学科结构提供了一种可重复的文献计量方法。

Abstract: This study applies Brookes' Measure of Categorical Dispersion (Δ) to analyze the thematic structure of contemporary Arabic Applied Linguistics research. Using a comprehensive, real-world dataset of 1,564 publications from 2019 to 2025, classified into eight core sub-disciplines, we calculate a dispersion index of Δ = 0.194. This remarkably low value indicates extreme thematic dispersion, revealing that the field is characterized by pronounced heterogeneity rather than concentration. The analysis identifies Computational Linguistics as a dominant but non-hegemonic force, coexisting with robust research in Sociolinguistics, Language Teaching, and other subfields. This study clarifies the correct application of Brookes' original formula, demonstrates its utility for field characterization, and provides a replicable bibliometric methodology for assessing disciplinary structure across domains.

</details>


### [20] [Adversarial versification in portuguese as a jailbreak operator in LLMs](https://arxiv.org/abs/2512.15353)
*Joao Queiroz*

Main category: cs.CL

TL;DR: 这篇论文探讨了通过诗歌化提示在大型语言模型 (LLM) 中实现越狱攻击的有效性，指出语言模型对表面模式的过度依赖，并强调了在葡萄牙语等形态句法复杂语言中进行评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 探索诗歌化提示作为一种新型的对抗机制，绕过对齐大型语言模型（LLM）的安全防护，并揭示现有对齐机制的深层局限性。

Method: 该研究通过将散文指令改写成诗歌形式，并在 MLCommons AILuminate 基准测试中进行评估。手动编写的诗歌达到约 62% 的攻击成功率（ASR），自动化版本达到 43%，在某些模型中单轮交互成功率甚至超过 90%。研究还分析了 RLHF、宪法 AI 和混合训练模型在韵律变化下的性能下降情况。

Result: 诗歌化提示能够显著增加安全漏洞，导致在基准测试中产生高达 18 倍的更多安全失败。这一现象表明，LLM 的安全护栏过度依赖于提示的表面模式。研究揭示了现有对齐机制在面对细微符号形式变化时的结构性缺陷。

Conclusion: 诗歌化提示是针对大型语言模型的一种高效越狱机制，揭示了当前对齐方法（如 RLHF 和宪法 AI）存在的深层漏洞，因为它们过度依赖提示的表面特征。论文强调了在葡萄牙语等形态句法复杂且具有丰富韵律传统的语言中进行评估的重要性，建议实验协议应参数化韵律和格律变化，以测试特定语言模式的漏洞。

Abstract: Recent evidence shows that the versification of prompts constitutes a highly effective adversarial mechanism against aligned LLMs. The study 'Adversarial poetry as a universal single-turn jailbreak mechanism in large language models' demonstrates that instructions routinely refused in prose become executable when rewritten as verse, producing up to 18 x more safety failures in benchmarks derived from MLCommons AILuminate. Manually written poems reach approximately 62% ASR, and automated versions 43%, with some models surpassing 90% success in single-turn interactions. The effect is structural: systems trained with RLHF, constitutional AI, and hybrid pipelines exhibit consistent degradation under minimal semiotic formal variation. Versification displaces the prompt into sparsely supervised latent regions, revealing guardrails that are excessively dependent on surface patterns. This dissociation between apparent robustness and real vulnerability exposes deep limitations in current alignment regimes. The absence of evaluations in Portuguese, a language with high morphosyntactic complexity, a rich metric-prosodic tradition, and over 250 million speakers, constitutes a critical gap. Experimental protocols must parameterise scansion, metre, and prosodic variation to test vulnerabilities specific to Lusophone patterns, which are currently ignored.

</details>


### [21] [Dual-Density Inference for Efficient Language Model Reasoning](https://arxiv.org/abs/2512.15358)
*Zhengyi Zhao,Shubo Zhang,Yuxi Zhang,Huimin Wang,Binyang Li,Kam-Fai Wong*

Main category: cs.CL

TL;DR: Denser是一种新型推理框架，它分别为推理阶段和回答阶段优化信息密度。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLMs）在复杂推理任务中的方法对中间推理和最终答案采用统一的语言密度，导致计算效率低下。

Method: Denser框架通过三个组件实现：查询处理模块、高密度压缩推理机制和答案生成组件。

Result: Denser相比标准思维链方法，可将token消耗降低高达62%，同时保持或提高准确性。

Conclusion: Denser框架通过优化信息密度，显著提高了复杂推理任务的计算效率，尤其在多步推理问题上表现突出。

Abstract: Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency. Our observation found that reasoning process serves a computational function for the model itself, while answering serves a communicative function for human understanding. This distinction enables the use of compressed, symbol-rich language for intermediate computations while maintaining human-readable final explanations. To address this inefficiency, we present Denser: \underline{D}ual-d\underline{ens}ity inf\underline{er}ence, a novel framework that optimizes information density separately for reasoning and answering phases. Our framework implements this through three components: a query processing module that analyzes input problems, a high-density compressed reasoning mechanism for efficient intermediate computations, and an answer generation component that translates compressed reasoning into human-readable solutions. Experimental evaluation across multiple reasoning question answering benchmarks demonstrates that Denser reduces token consumption by up to 62\% compared to standard Chain-of-Thought methods while preserving or improving accuracy. These efficiency gains are particularly significant for complex multi-step reasoning problems where traditional methods generate extensive explanations.

</details>


### [22] [ORACLE: Time-Dependent Recursive Summary Graphs for Foresight on News Data Using LLMs](https://arxiv.org/abs/2512.15397)
*Lev Kharlashkin,Eiaki Morooka,Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TL;DR: ORACLE是一个芬兰大学使用的平台，它将每日新闻转化为周度决策洞察。


<details>
  <summary>Details</summary>
Motivation: 为芬兰一所应用科学大学将每日新闻转化为周度决策洞察。

Method: ORACLE平台抓取并版本化新闻，应用大学特定的相关性过滤，嵌入内容，将项目分类到PESTEL维度，并构建一个简洁的时间依赖递归摘要图（TRSG）：两个聚类层由LLM总结并每周重新计算。一个轻量级的变化检测器突出显示新增、删除或更改的内容，然后将差异分组为主题，以便进行PESTEL感知分析。

Result: ORACLE提供了一个稳定的生产系统，能够生成决策就绪的洞察。

Conclusion: ORACLE平台通过自动化新闻分析和摘要，为大学提供了决策支持工具，并有一个课程智能用例和评估计划。

Abstract: ORACLE turns daily news into week-over-week, decision-ready insights for one of the Finnish University of Applied Sciences. The platform crawls and versions news, applies University-specific relevance filtering, embeds content, classifies items into PESTEL dimensions and builds a concise Time-Dependent Recursive Summary Graph (TRSG): two clustering layers summarized by an LLM and recomputed weekly. A lightweight change detector highlights what is new, removed or changed, then groups differences into themes for PESTEL-aware analysis. We detail the pipeline, discuss concrete design choices that make the system stable in production and present a curriculum-intelligence use case with an evaluation plan.

</details>


### [23] [Toward expert-level motivational interviewing for health behavior improvement with LLMs](https://arxiv.org/abs/2512.15446)
*Run-ze Hu,Yang Yang,Yi-hang Yang,Jing-qi Kong,Jia-hui Luo,Wen-yu Yang,Jing Chen,Jing-yao Liu,Hui-qun Zeng,Lei Zhang,Zheng Liu*

Main category: cs.CL

TL;DR: 该研究开发并评估了用于动机性访谈（MI）的大型语言模型（MI-LLMs），通过中文心理咨询语料库对现有大模型进行微调，并在自动指标和专家手动编码方面显示出接近真实MI对话的MI一致性咨询行为，为AI辅助健康行为改变提供了可扩展的途径。


<details>
  <summary>Details</summary>
Motivation: 动机性访谈（MI）是促进健康行为改变的有效咨询方法，但其影响受限于需要训练有素的人类咨询师。本研究旨在探索一种可扩展的替代方案，通过开发和评估用于动机性访谈的大型语言模型（MI-LLMs）。

Method: 研究首先整理了五个中文心理咨询语料库，并使用GPT-4和MI提示，将其中两个高质量数据集（CPsyCounD和PsyDTCorpus）的多轮对话转录为2,040个MI风格的咨询对话。其中2,000个用于训练，40个用于测试。三个中文开源LLMs（Baichuan2-7B-Chat、ChatGLM-4-9B-Chat和Llama-3-8B-Chinese-Chat-v2）在此语料库上进行了微调，并命名为MI-LLMs。研究使用基于轮次的自动指标和动机性访谈治疗完整性（MITI）编码手册4.2.1的专家手动编码对MI-LLMs进行了评估。

Result: 在所有三个模型中，与基础模型相比，微调显著改善了BLEU-4和ROUGE分数。手动编码显示，MI-LLMs在技术和关系方面的整体得分以及MI依从性比例接近真实的MI对话，尽管复杂性反思和反思与问题比例仍然较低。

Conclusion: 这些发现提供了初步证据，表明面向MI的微调可以赋予通用LLMs核心的MI一致性咨询行为，为AI辅助健康行为改变支持提供了可扩展的途径，同时也强调了在数据规模、复杂MI技能和真实世界干预试验方面需要进一步工作。

Abstract: Background: Motivational interviewing (MI) is an effective counseling approach for promoting health behavior change, but its impact is constrained by the need for highly trained human counselors. Objective: This study aimed to explore a scalable alternative by developing and evaluating Large Language Models for Motivational Interviewing (MI-LLMs). Methods: We first curated five Chinese psychological counseling corpora and, using GPT-4 with an MI-informed prompt, transcribed multi-turn dialogues from the two highest-quality datasets (CPsyCounD and PsyDTCorpus) into 2,040 MI-style counseling conversations, of which 2,000 were used for training and 40 for testing. Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat and Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this corpus and were named as MI-LLMs. We evaluated MI-LLMs using round-based automatic metrics and expert manual coding with the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1. Results: Across all three models, fine-tuning substantially improved BLEU-4 and ROUGE scores compared with the base models, and manual coding showed that MI-LLMs achieved technical and relational global scores, and MI-adherent ratios that approached those of real MI dialogues, although complex reflections and reflection-to-question ratios remained less frequent. Conclusions: These findings provide initial evidence that MI-oriented fine-tuning can endow general-purpose LLMs with core MI-consistent counseling behaviors, suggesting a scalable pathway toward AI-assisted health behavior change support while underscoring the need for further work on data scale, complex MI skills and real-world intervention trials.

</details>


### [24] [When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising](https://arxiv.org/abs/2512.15547)
*Md. Samiul Alim,Mahir Shahriar Tamim,Maisha Rahman,Tanvir Ahmed Khan,Md Mushfique Anwar*

Main category: cs.CL

TL;DR: 该研究首次对孟加拉国2024年大规模起义期间的孟加拉语公众情绪进行了情感分析，填补了自然语言处理在处理内乱情绪动态方面的空白。


<details>
  <summary>Details</summary>
Motivation: 以往情感分析主要集中在选举和社交媒体趋势等领域，但在内乱期间（尤其对孟加拉语）的情绪动态研究存在明显空白，本研究旨在填补这一空白。

Method: 1. 建立了包含2,028条孟加拉语新闻标题的独特数据集，并将其分为“愤怒”、“希望”和“绝望”三类。
2. 采用Latent Dirichlet Allocation (LDA)识别了主要的文本主题。
3. 分析了互联网中断等事件对情感模式的影响。
4. 对比了语言特异性模型与多语言转换器（mBERT, XLM-RoBERTa）以及传统机器学习方法（SVM, 逻辑回归）的性能。

Result: 语言特异性模型在孟加拉语情感分析中表现出色，其准确率达到81%，显著优于多语言转换器（mBERT: 67%, XLM-RoBERTa: 71%）和传统机器学习方法（SVM和逻辑回归：均为70%）。研究还识别了政治腐败和公众抗议等主要主题，并分析了事件如何影响情感模式。

Conclusion: 本研究不仅首次提供了孟加拉国政治动荡期间公众情绪的宝贵见解，还证明了语言特异性模型在处理特定语言（如孟加拉语）情感分析任务中的优越性，为理解内乱中的公众情感提供了有效工具。

Abstract: Sentiment analysis, an emerging research area within natural language processing (NLP), has primarily been explored in contexts like elections and social media trends, but there remains a significant gap in understanding emotional dynamics during civil unrest, particularly in the Bangla language. Our study pioneers sentiment analysis in Bangla during a national crisis by examining public emotions amid Bangladesh's 2024 mass uprising. We curated a unique dataset of 2,028 annotated news headlines from major Facebook news portals, classifying them into Outrage, Hope, and Despair. Through Latent Dirichlet Allocation (LDA), we identified prevalent themes like political corruption and public protests, and analyzed how events such as internet blackouts shaped sentiment patterns. It outperformed multilingual transformers (mBERT: 67%, XLM-RoBERTa: 71%) and traditional machine learning methods (SVM and Logistic Regression: both 70%). These results highlight the effectiveness of language-specific models and offer valuable insights into public sentiment during political turmoil.

</details>


### [25] [CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing](https://arxiv.org/abs/2512.15550)
*Kuan Lu,Shuhang Lin,Sai Wu,Yichen Yao,Junhan Yang,Huan Li,Wei Chu,Xu Yinghui,Yuan Qi,Gang Chen*

Main category: cs.CL

TL;DR: CTKVR是一种新颖的KV检索方案，它通过结合“质心先验”和“逐令牌细化”的方法，解决了现有动态KV选择方法在长上下文场景中面临的准确性和效率挑战。该方案在保持高准确性的同时，显著提升了LLMs在长上下文推理场景下的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在长上下文场景中的应用日益增多，例如多轮对话。然而，长上下文推理面临着效率挑战，主要包括KV缓存带来的高内存开销以及内存访问增加导致的延迟。现有的动态KV选择方法在准确性（块级索引可能检索不相关条目）和效率（令牌级索引检索机制效率低下）之间难以平衡。

Method: CTKVR提出了一种新颖的“质心先验，逐令牌检索”（centroid-then-token KV retrieval）方案。核心思想是利用RoPE后相邻查询向量之间高相似性，并共享大部分top-k KV缓存条目的观察。该方案采用两阶段检索策略：1. 预填充阶段预计算轻量级质心以进行质心粒度索引。2. 后续进行令牌级细化以实现精确的KV检索。为了进一步提高性能，CTKVR实现了一个优化的系统，通过CPU-GPU协同执行进行索引构建和搜索。

Result: CTKVR在多个基准测试中取得了卓越的性能，准确性下降不到1%。同时，在96K上下文长度下，CTKVR在Llama-3-8B和Yi-9B上实现了3倍和4倍的吞吐量加速，且适用于多种GPU硬件。

Conclusion: CTKVR通过其创新的两阶段检索策略和优化的系统实现，有效地解决了LLMs在长上下文推理中KV缓存的效率和准确性问题。它在保持高准确性的同时，显著提升了模型的吞吐量，为LLMs在长上下文场景下的应用提供了有力的支持。

Abstract: Large language models (LLMs) are increasingly applied in long-context scenarios such as multi-turn conversations. However, long contexts pose significant challenges for inference efficiency, including high memory overhead from Key-Value (KV) cache and increased latency due to excessive memory accesses. Recent methods for dynamic KV selection struggle with trade-offs: block-level indexing degrades accuracy by retrieving irrelevant KV entries, while token-level indexing incurs high latency from inefficient retrieval mechanisms. In this paper, we propose CTKVR, a novel centroid-then-token KV retrieval scheme that addresses these limitations. CTKVR leverages a key observation: query vectors adjacent in position exhibit high similarity after Rotary Position Embedding (RoPE) and share most of their top-k KV cache entries. Based on this insight, CTKVR employs a two-stage retrieval strategy: lightweight centroids are precomputed during prefilling for centroid-grained indexing, followed by token-level refinement for precise KV retrieval. This approach balances retrieval efficiency and accuracy. To further enhance performance, we implement an optimized system for indexing construction and search using CPU-GPU co-execution. Experimentally, CTKVR achieves superior performance across multiple benchmarks with less than 1% accuracy degradation. Meanwhile, CTKVR delivers 3 times and 4 times throughput speedups on Llama-3-8B and Yi-9B at 96K context length across diverse GPU hardware.

</details>


### [26] [From Data to Dialogue: Unlocking Language for All](https://arxiv.org/abs/2512.15552)
*Dakota Ellis,Samy Bakikerali,Wanshan Chen,Bao Dinh,Uyen Le*

Main category: cs.CL

TL;DR: 本文提出了一种自动生成专业词汇表（SWL）的方法，优于传统通用词汇表（GSL），能更有效地帮助语言学习者达到语言理解所需的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 传统通用词汇表（GSL）的创建需要语言学专业知识、主观判断和大量时间，而本文旨在提供一种更高效、客观的方法来识别英语中最重要的词汇，并帮助语言学习者。

Method: 本文创建了通用服务列表（GSL），并将其与行业标准（NGSL）进行评估对比。在此基础上，本文进一步创建了专业词汇表（SWL），该词汇表是针对语料库特定子集的词汇列表，并通过模型对其进行优化。

Result: 本文创建的专业词汇表（SWL）在保持较少词汇量的同时，比行业标准在达到95%语言理解覆盖率方面表现更优异。此外，由于仅限于客观标准，SWL的创建过程可以实现自动化、规模化，并根据全球语言学习者的需求进行定制。

Conclusion: 专业词汇表（SWL）的创建是一种高效实用的方法，可以帮助语言学习者优化学习过程并达到语言理解所需的目标。这种方法解决了传统GSL创建过程中主观性强、耗时长的缺点，具有广泛的应用前景。

Abstract: Traditional linguists have proposed the use of a General Service List (GSL) to assist new language learners in identifying the most important words in English. This process requires linguistic expertise, subjective input, and a considerable amount of time. We attempt to create our own GSL and evaluate its practicality against the industry standard (The NGSL). We found creating a Specialized Word List (SWL), or a word list specific to a subset of the overall corpus, to be the most practical way for language-learners to optimize the process. The SWL's that we created using our model outperformed the industry standard, reaching the 95% coverage required for language comprehension with fewer words comparatively. By restricting the SWL process to objective criteria only, it can be automated, scaled, and tailored to the needs of language-learners across the globe.

</details>


### [27] [An Empirical Study on Chinese Character Decomposition in Multiword Expression-Aware Neural Machine Translation](https://arxiv.org/abs/2512.15556)
*Lifeng Han,Gareth J. F. Jones,Alan F. Smeaton*

Main category: cs.CL

TL;DR: 本文分析了多词表达（MWEs）在自然语言处理中的挑战，特别指出中文及其他亚洲语言在此领域进展缓慢。研究提出将汉字拆解技术应用于中文MWE感知的神经机器翻译（NMT），旨在提升字词的意义表征和MWE翻译效果。


<details>
  <summary>Details</summary>
Motivation: 多词表达（MWEs）在自然语言理解、处理和生成中引入歧义和复杂性，尤其在中文等亚洲语言中，MWEs研究进展滞后，且西方语言中成功的子词建模技术（如BPE）不适用于表意文字。

Method: 本文系统研究了在MWE感知的神经机器翻译（NMT）背景下的汉字拆解技术。

Result: 通过实验，本文检验了汉字拆解技术如何有助于表征汉字和词语的原始意义，以及如何有效解决MWE的翻译挑战。

Conclusion: 汉字拆解技术有望提升中文MWE在NMT中的处理效果，解决其在翻译中遇到的挑战。

Abstract: Word meaning, representation, and interpretation play fundamental roles in natural language understanding (NLU), natural language processing (NLP), and natural language generation (NLG) tasks. Many of the inherent difficulties in these tasks stem from Multi-word Expressions (MWEs), which complicate the tasks by introducing ambiguity, idiomatic expressions, infrequent usage, and a wide range of variations. Significant effort and substantial progress have been made in addressing the challenging nature of MWEs in Western languages, particularly English. This progress is attributed in part to the well-established research communities and the abundant availability of computational resources. However, the same level of progress is not true for language families such as Chinese and closely related Asian languages, which continue to lag behind in this regard. While sub-word modelling has been successfully applied to many Western languages to address rare words improving phrase comprehension, and enhancing machine translation (MT) through techniques like byte-pair encoding (BPE), it cannot be applied directly to ideograph language scripts like Chinese. In this work, we conduct a systematic study of the Chinese character decomposition technology in the context of MWE-aware neural machine translation (NMT). Furthermore, we report experiments to examine how Chinese character decomposition technology contributes to the representation of the original meanings of Chinese words and characters, and how it can effectively address the challenges of translating MWEs.

</details>


### [28] [Bolmo: Byteifying the Next Generation of Language Models](https://arxiv.org/abs/2512.15586)
*Benjamin Minixhofer,Tyler Murray,Tomasz Limisiewicz,Anna Korhonen,Luke Zettlemoyer,Noah A. Smith,Edoardo M. Ponti,Luca Soldaini,Valentin Hofmann*

Main category: cs.CL

TL;DR: 本文介绍了Bolmo，第一个具有竞争力的全开放字节级语言模型系列。Bolmo通过字节化现有的子词级语言模型进行训练，克服了子词分词的局限性，并在字符理解和编码方面表现出色，同时在推理速度上具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 以往的字节级语言模型研究主要集中从头开始训练，这可能导致性能不佳和效率低下。现有的子词级语言模型存在字符理解不足和固定子词词汇导致的效率限制。因此，需要一种新的方法来克服这些限制，并使字节级语言模型在与子词级语言模型竞争的同时，成为实际的选择。

Method: Bolmo通过字节化现有的子词级语言模型进行训练。设计了一种专门用于字节化的架构，解决了先前字节级架构与子词级语言模型之间的表达能力不匹配问题。这使得Bolmo和源子词模型之间可以采用有效的精确蒸馏目标，从而能够以不到典型预训练_token_预算的1%的成本将子词级语言模型转换为字节级语言模型。

Result: Bolmo的性能显著优于所有同等规模的现有字节级语言模型。它在字符理解方面超越了源子词级语言模型，并且在某些情况下在编码方面也表现更优。在其他任务上，Bolmo的性能与原始语言模型相近。通过使用更高的_token_压缩率进行训练，Bolmo可以实现与子词级语言模型竞争的推理速度。Bolmo可以通过利用源子词级语言模型周围的现有生态系统进行廉价有效的后期训练。

Conclusion: Bolmo最终使字节级语言模型成为在广泛用例中与子词级语言模型竞争的实用选择。它克服了子词分词的局限性，并在性能和效率方面具有竞争力，有望推动未来语言模型的发展。

Abstract: We introduce Bolmo, the first family of competitive fully open byte-level language models (LMs) at the 1B and 7B parameter scales. In contrast to prior research on byte-level LMs, which focuses predominantly on training from scratch, we train Bolmo by byteifying existing subword-level LMs. Byteification enables overcoming the limitations of subword tokenization - such as insufficient character understanding and efficiency constraints due to the fixed subword vocabulary - while performing at the level of leading subword-level LMs. Bolmo is specifically designed for byteification: our architecture resolves a mismatch between the expressivity of prior byte-level architectures and subword-level LMs, which makes it possible to employ an effective exact distillation objective between Bolmo and the source subword model. This allows for converting a subword-level LM to a byte-level LM by investing less than 1\% of a typical pretraining token budget. Bolmo substantially outperforms all prior byte-level LMs of comparable size, and outperforms the source subword-level LMs on character understanding and, in some cases, coding, while coming close to matching the original LMs' performance on other tasks. Furthermore, we show that Bolmo can achieve inference speeds competitive with subword-level LMs by training with higher token compression ratios, and can be cheaply and effectively post-trained by leveraging the existing ecosystem around the source subword-level LM. Our results finally make byte-level LMs a practical choice competitive with subword-level LMs across a wide set of use cases.

</details>


### [29] [You Never Know a Person, You Only Know Their Defenses: Detecting Levels of Psychological Defense Mechanisms in Supportive Conversations](https://arxiv.org/abs/2512.15601)
*Hongbin Na,Zimu Wang,Zhaoming Chen,Peilin Zhou,Yining Hua,Grace Ziqi Zhou,Haiyang Zhang,Tao Shen,Wei Wang,John Torous,Shaoxiong Ji,Ling Chen*

Main category: cs.CL

TL;DR: 该研究介绍了PsyDefConv，一个带有防御水平标注的对话语料库，并开发了DMRS Co-Pilot工具，旨在提高防御机制标注的效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 心理防御机制的评估对于理解和改善心理健康至关重要，但其复杂性和在临床对话中难以可靠测量是当前面临的主要挑战。

Method: 本文构建了包含200个对话和4709个话语的PsyDefConv对话语料库，其中2336个帮助寻求者的话语经过防御水平标注，Cohen’s kappa系数达到0.639。同时，开发了DMRS Co-Pilot四阶段流水线工具，用于提供基于证据的预标注。

Result: DMRS Co-Pilot工具将平均标注时间缩短了22.4%。在专家评审中，该工具在证据、临床合理性和洞察力方面得分较高（平均分分别为4.62、4.44和4.40，七分制）。基准测试显示，在零样本和微调设置下，即使是强大的语言模型，宏F1分数也仅为30%左右，且倾向于过度预测成熟防御。语料库分析证实成熟防御最为常见，并揭示了情绪特异性偏差。

Conclusion: PsyDefConv语料库和DMRS Co-Pilot工具为心理防御机制的研究提供了重要的资源和方法，但在自动化识别方面仍有提升空间。研究结果有助于加深对防御机制在语言中运作方式的理解，并为未来的研究奠定基础。

Abstract: Psychological defenses are strategies, often automatic, that people use to manage distress. Rigid or overuse of defenses is negatively linked to mental health and shapes what speakers disclose and how they accept or resist help. However, defenses are complex and difficult to reliably measure, particularly in clinical dialogues. We introduce PsyDefConv, a dialogue corpus with help seeker utterances labeled for defense level, and DMRS Co-Pilot, a four-stage pipeline that provides evidence-based pre-annotations. The corpus contains 200 dialogues and 4709 utterances, including 2336 help seeker turns, with labeling and Cohen's kappa 0.639. In a counterbalanced study, the co-pilot reduced average annotation time by 22.4%. In expert review, it averaged 4.62 for evidence, 4.44 for clinical plausibility, and 4.40 for insight on a seven-point scale. Benchmarks with strong language models in zero-shot and fine-tuning settings demonstrate clear headroom, with the best macro F1-score around 30% and a tendency to overpredict mature defenses. Corpus analyses confirm that mature defenses are most common and reveal emotion-specific deviations. We will release the corpus, annotations, code, and prompts to support research on defensive functioning in language.

</details>


### [30] [Evaluating Metrics for Safety with LLM-as-Judges](https://arxiv.org/abs/2512.15617)
*Kester Clegg,Richard Hawkins,Ibrahim Habli,Tom Lawton*

Main category: cs.CL

TL;DR: 本文探讨了将大型语言模型（LLM）引入到关键信息流中，以替代人类决策时，如何确保其安全性和可靠性。作者认为，安全论证应侧重于从LLM流程的评估点获取证据，特别是在使用“LLM即法官”（LaJ）评估器时。通过采用一系列加权指标，利用上下文敏感性定义错误严重程度，并设计置信度阈值来触发人工审查，即使在无法获得确定性评估的自然语言处理任务中，也能降低错误的风险。


<details>
  <summary>Details</summary>
Motivation: 当大型语言模型（LLM）被引入到关键信息流中，替代原本由人类执行的、受限于人员不足或流程复杂性的任务时，确保其安全性和可靠性成为核心问题。尤其是在术后护理分诊或核设施现场访问计划更新等安全关键型处理角色中，LLM的错误可能带来严重后果。因此，本文旨在探讨如何使LLM在这些关键应用中变得安全可靠。

Method: 本文提出，要确保LLM在关键信息流中的安全和可靠性，安全论证应侧重于从LLM处理流程的评估点获取证据，尤其是在采用“LLM即法官”（LaJ）评估器时。具体方法包括：1. 采用一系列加权指标进行评估，以降低评估中错误的风险。2. 利用上下文敏感性来定义错误的严重程度。3. 设计置信度阈值，当评估器之间的一致性较低时，触发人工审查关键的LaJ判断。

Result: 通过上述方法，本文认为即使在许多无法获得确定性评估的自然语言处理任务中，也有可能降低评估过程中错误的风险。文章提出，通过加权指标、上下文敏感性定义错误严重性以及设计置信度阈值以触发人工审查，可以提高LLM在关键应用中的安全性和可靠性。

Conclusion: 本文得出结论，将大型语言模型安全可靠地引入到关键信息流中是可行的，尤其是在安全关键型处理任务中。关键在于采用一种以证据为基础的安全论证，侧重于LLM流程的评估点，特别是使用“LLM即法官”（LaJ）评估器时。通过综合应用加权指标、上下文敏感性以及置信度阈值触发人工审查，可以有效地管理和降低LLM产生错误的风险，从而促进其在关键应用中的安全部署。

Abstract: LLMs (Large Language Models) are increasingly used in text processing pipelines to intelligently respond to a variety of inputs and generation tasks. This raises the possibility of replacing human roles that bottleneck existing information flows, either due to insufficient staff or process complexity. However, LLMs make mistakes and some processing roles are safety critical. For example, triaging post-operative care to patients based on hospital referral letters, or updating site access schedules in nuclear facilities for work crews. If we want to introduce LLMs into critical information flows that were previously performed by humans, how can we make them safe and reliable? Rather than make performative claims about augmented generation frameworks or graph-based techniques, this paper argues that the safety argument should focus on the type of evidence we get from evaluation points in LLM processes, particularly in frameworks that employ LLM-as-Judges (LaJ) evaluators. This paper argues that although we cannot get deterministic evaluations from many natural language processing tasks, by adopting a basket of weighted metrics it may be possible to lower the risk of errors within an evaluation, use context sensitivity to define error severity and design confidence thresholds that trigger human review of critical LaJ judgments when concordance across evaluators is low.

</details>


### [31] [How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness](https://arxiv.org/abs/2512.15634)
*Darshita Rathore,Vineet Kumar,Chetna Bansal,Anindya Moitra*

Main category: cs.CL

TL;DR: 这篇论文评估了大型语言模型（LLM）的监督微调（SFT）和参数高效微调（PEFT）方法，特别是LoRA，在问答任务中的表现，并对其泛化能力和内部表征进行了分析。


<details>
  <summary>Details</summary>
Motivation: 探索PEFT（特别是LoRA）在LLM下游任务（尤其是问答任务）中的配置影响，并量化其与SFT在计算效率和性能之间的权衡。

Method: 本文在多个推理和召回数据集上进行了评估，通过对LoRA秩的扫描来比较SFT和PEFT的性能。同时，对比了PEFT和SFT模型在域内和域外适应的准确性，并分析了内部表征（谱特征和分层注意力结构）。

Result: LoRA在特定秩值下，在推理任务上表现出与SFT相当甚至更优的性能。研究还揭示了两种方法在泛化行为和任务特异性遗忘方面的差异。内部表征分析也为表征漂移和注意力模式的结构变化提供了见解。

Conclusion: LoRA是一种有竞争力的微调方法，在某些情况下可以超越SFT，尤其是在推理任务中。PEFT和SFT在泛化行为和遗忘方面存在显著差异，且其内部表征也随之变化。

Abstract: Large language models are increasingly adapted to downstream tasks through fine-tuning. Full supervised fine-tuning (SFT) and parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), are two dominant approaches. While PEFT methods are widely used for their computational efficiency, the implications of their configurations (e.g., rank) remain under-explored in downstream Q&A tasks and generalisation. In this work, we perform a comprehensive evaluation across multiple reasoning and recall datasets, conducting a rank sweep to quantify the trade-off between SFT and PEFT. We also compare the accuracy of PEFT and SFT models across in-domain and out-of-domain adaptation, highlighting distinct generalisation behaviour and task-specific forgetting. We demonstrate that LoRA achieves competitive and in some cases superior performance compared to SFT, particularly on reasoning tasks at specific rank values. Additionally, we analyze the internal representations via spectral features and layer-wise attention structures, offering insights into representational drift and structural changes in attention patterns.

</details>


### [32] [PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning](https://arxiv.org/abs/2512.15658)
*Xiaodi Li,Dingcheng Li,Rujun Gao,Mahmoud Zamani,Feng Mi,Latifur Khan*

Main category: cs.CL

TL;DR: 该论文介绍了一种名为PPSEBM的新型持续学习框架，它结合了能量基模型（EBM）和渐进参数选择（PPS），以解决自然语言处理任务中持续学习的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 持续学习中的灾难性遗忘问题，即模型在学习新任务时会遗忘先前获得的知识，是一个核心挑战。

Method: PPSEBM框架通过渐进参数选择为每个新任务分配独立的、任务特定的参数，同时利用EBM从先前的任务中生成代表性的伪样本。这些伪样本用于指导参数选择过程，帮助模型在适应新任务的同时保留旧知识。

Result: 在多种NLP基准测试上的实验结果表明，PPSEBM的性能优于现有的最先进持续学习方法。

Conclusion: PPSEBM为减轻灾难性遗忘提供了一个有前景且稳健的解决方案，有效提升了模型在持续学习设置下保留知识和适应新任务的能力。

Abstract: Continual learning remains a fundamental challenge in machine learning, requiring models to learn from a stream of tasks without forgetting previously acquired knowledge. A major obstacle in this setting is catastrophic forgetting, where performance on earlier tasks degrades as new tasks are learned. In this paper, we introduce PPSEBM, a novel framework that integrates an Energy-Based Model (EBM) with Progressive Parameter Selection (PPS) to effectively address catastrophic forgetting in continual learning for natural language processing tasks. In PPSEBM, progressive parameter selection allocates distinct, task-specific parameters for each new task, while the EBM generates representative pseudo-samples from prior tasks. These generated samples actively inform and guide the parameter selection process, enhancing the model's ability to retain past knowledge while adapting to new tasks. Experimental results on diverse NLP benchmarks demonstrate that PPSEBM outperforms state-of-the-art continual learning methods, offering a promising and robust solution to mitigate catastrophic forgetting.

</details>


### [33] [Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers](https://arxiv.org/abs/2512.15674)
*Adam Karvonen,James Chua,Clément Dumas,Kit Fraser-Taliente,Subhash Kantamneni,Julian Minder,Euan Ong,Arnab Sen Sharma,Daniel Wen,Owain Evans,Samuel Marks*

Main category: cs.CL

TL;DR: 本文探讨了一种名为 LatentQA 的方法，该方法通过训练大型语言模型（LLM）直接接收并解释LLM的激活，从而回答关于LLM激活的任意问题。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLM）的内部工作原理。现有的技术复杂且专业化，难以普及。

Method: 本文提出了一种通用的 LatentQA 方法，称为激活预言机（AOs）。通过多样化的训练数据来提升模型的在分布外设置下的性能。

Result: 激活预言机（AOs）可以在未训练的微调模型激活中恢复信息，例如生物学知识或恶意倾向。在四个下游任务中，AOs 的表现优于或与白盒基线相当，在其中三个任务中表现最佳。

Conclusion: 通过多样化训练学习回答自然语言查询的 AOs 能够有效地解读 LLM 激活信息，甚至可以从微调模型激活中恢复未在输入文本中出现的信息。未来，通用 LatentQA 方法有潜力成为理解复杂 LLM 行为的强大工具。

Abstract: Large language model (LLM) activations are notoriously difficult to understand, with most existing techniques using complex, specialized methods for interpreting them. Recent work has proposed a simpler approach known as LatentQA: training LLMs to directly accept LLM activations as inputs and answer arbitrary questions about them in natural language. However, prior work has focused on narrow task settings for both training and evaluation. In this paper, we instead take a generalist perspective. We evaluate LatentQA-trained models, which we call Activation Oracles (AOs), in far out-of-distribution settings and examine how performance scales with training data diversity. We find that AOs can recover information fine-tuned into a model (e.g., biographical knowledge or malign propensities) that does not appear in the input text, despite never being trained with activations from a fine-tuned model. Our main evaluations are four downstream tasks where we can compare to prior white- and black-box techniques. We find that even narrowly-trained LatentQA models can generalize well, and that adding additional training datasets (such as classification tasks and a self-supervised context prediction task) yields consistent further improvements. Overall, our best AOs match or exceed prior white-box baselines on all four tasks and are the best method on 3 out of 4. These results suggest that diversified training to answer natural-language queries imparts a general capability to verbalize information about LLM activations.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [34] [Effectively Detecting and Responding to Online Harassment with Large Language Models](https://arxiv.org/abs/2512.14700)
*Pinxian Lu,Nimra Ishfaq,Emma Win,Morgan Rose,Sierra R Strickland,Candice L Biernesser,Jamie Zelazny,Munmun De Choudhury*

Main category: cs.SI

TL;DR: 这篇论文研究了在Instagram等私人消息平台上的在线骚扰问题，并利用大型语言模型（LLMs）来识别骚扰内容并生成更有效的应对信息。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注公共社交媒体平台上的在线骚扰，而对私人消息平台关注不足。本研究旨在解决Instagram等私人消息平台上的在线骚扰问题。

Method: 本研究招募人工标注者来识别Instagram消息数据集中的在线骚扰内容。然后，利用大语言模型（LLMs）流水线，以前期对话为上下文，对Instagram消息进行大规模标注，并根据人工标注评估其性能。最后，使用LLM生成并评估对在线骚扰消息的模拟回复。

Result: 研究发现，LLM标注流水线能够识别私人消息中的在线骚扰。通过比较人工回复和模拟回复，研究还表明模拟回复在帮助性方面优于原始人工回复。

Conclusion: 本研究成功利用大型语言模型解决了Instagram私人消息平台上的在线骚扰问题，并证明了LLM在识别骚扰内容和生成有效应对信息方面的潜力。

Abstract: Online harassment has been a persistent issue in the online space. Predominantly, research focused on online harassment in public social media platforms, while less is placed on private messaging platforms. To address online harassment on one private messaging platform, Instagram, we leverage the capabilities of Large Language Models (LLMs). To achieve this, we recruited human labelers to identify online harassment in an Instagram messages dataset. Using the previous conversation as context, we utilize an LLM pipeline to conduct large-scale labeling on Instagram messages and evaluate its performance against human labels. Then, we use LLM to generate and evaluate simulated responses to online harassment messages. We find that the LLM labeling pipeline is capable of identifying online harassment in private messages. By comparing human responses and simulated responses, we also demonstrate that our simulated responses are superior in helpfulness compared to original human responses.

</details>


### [35] [Model inference for ranking from pairwise comparisons](https://arxiv.org/abs/2512.15269)
*Daniel Sánchez Catalina,George T. Cantwell*

Main category: cs.SI

TL;DR: 本文提出了一种从嘈杂的成对比较中推断物体排序和未知强度之间映射函数的算法。


<details>
  <summary>Details</summary>
Motivation: 以往的方法需要预先知道技能如何影响结果，而本文则旨在同时推断物体的潜在强度以及强度与比较结果概率之间的映射函数。

Method: 本文提出了一种贝叶斯方法，该方法能同时推断未观测到的强度和将强度映射到概率的函数。

Result: 实验证据表明，本文提出的贝叶斯方法的结论对于不同的模型 S 都有鲁棒性。

Conclusion: 本文提出的算法能够有效地从嘈杂的成对比较数据中，同时推断出物体的真实实力和实力如何影响比较结果的函数，并且在多种真实世界数据集上表现出良好的鲁棒性。

Abstract: We consider the problem of ranking objects from noisy pairwise comparisons, for example, ranking tennis players from the outcomes of matches. We follow a standard approach to this problem and assume that each object has an unobserved strength and that the outcome of each comparison depends probabilistically on the strengths of the comparands. However, we do not assume to know a priori how skills affect outcomes. Instead, we present an efficient algorithm for simultaneously inferring both the unobserved strengths and the function that maps strengths to probabilities. Despite this problem being under-constrained, we present experimental evidence that the conclusions of our Bayesian approach are robust to different model specifications. We include several case studies to exemplify the method on real-world data sets.

</details>


### [36] [Trustworthy Neighborhoods Mining: Homophily-Aware Neutral Contrastive Learning for Graph Clustering](https://arxiv.org/abs/2512.15027)
*Liang Peng,Yixuan Ye,Cheng Liu,Hangjun Che,Man-Fai Leung,Si Wu,Hau-San Wong*

Main category: cs.SI

TL;DR: NeuCGC是一种新颖的对比图聚类方法，它引入了中性对以解决现实世界图中同质性水平不同的问题，通过自适应对比邻域分布对齐和对比邻域节点特征一致性学习来提高聚类性能。


<details>
  <summary>Details</summary>
Motivation: 传统的邻居对比学习方法依赖于同质性假设，即连接节点共享相似的类标签，这在低同质性图中会导致节点表示难以区分，因为邻居信息不可靠。因此，在图聚类中识别具有不同同质性水平的可靠邻居具有挑战性。

Method: NeuCGC通过引入中性对（视为加权正对而非严格正负对的节点对）来扩展传统对比学习。这些中性对根据图的同质性水平动态调整。该方法包括两个关键组件：1) 基于给定属性图同质性水平自适应调整的对比邻域分布对齐；2) 利用高置信度图中的可靠邻域信息学习鲁棒节点表示的对比邻域节点特征一致性学习机制。

Result: 实验结果表明，NeuCGC的有效性和鲁棒性优于其他最先进的图聚类方法。

Conclusion: NeuCGC通过引入中性对来解决图聚类中存在的不同同质性水平的问题，并利用自适应对比邻域分布对齐和对比邻域节点特征一致性学习，有效地提高了图聚类的性能，学习到更鲁棒的节点表示。

Abstract: Recently, neighbor-based contrastive learning has been introduced to effectively exploit neighborhood information for clustering. However, these methods rely on the homophily assumption-that connected nodes share similar class labels and should therefore be close in feature space-which fails to account for the varying homophily levels in real-world graphs. As a result, applying contrastive learning to low-homophily graphs may lead to indistinguishable node representations due to unreliable neighborhood information, making it challenging to identify trustworthy neighborhoods with varying homophily levels in graph clustering. To tackle this, we introduce a novel neighborhood Neutral Contrastive Graph Clustering method, NeuCGC, that extends traditional contrastive learning by incorporating neutral pairs-node pairs treated as weighted positive pairs, rather than strictly positive or negative. These neutral pairs are dynamically adjusted based on the graph's homophily level, enabling a more flexible and robust learning process. Leveraging neutral pairs in contrastive learning, our method incorporates two key components: (1) an adaptive contrastive neighborhood distribution alignment that adjusts based on the homophily level of the given attribute graph, ensuring effective alignment of neighborhood distributions, and (2) a contrastive neighborhood node feature consistency learning mechanism that leverages reliable neighborhood information from high-confidence graphs to learn robust node representations, mitigating the adverse effects of varying homophily levels and effectively exploiting highly trustworthy neighborhood information. Experimental results demonstrate the effectiveness and robustness of our approach, outperforming other state-of-the-art graph clustering methods. Our code is available at https://github.com/THPengL/NeuCGC.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts](https://arxiv.org/abs/2512.14706)
*Krunal Jesani,Dmitry Ignatov,Radu Timofte*

Main category: cs.LG

TL;DR: 该论文提出了NN-Caption，这是一个由大型语言模型（LLM）引导的神经架构搜索（NAS）流程，用于生成可运行的图像字幕模型。


<details>
  <summary>Details</summary>
Motivation: 传统的神经架构搜索（NAS）需要大量人工专业知识或自动试错来设计深度学习模型，这促使研究者探索LLM引导的NAS方法。

Method: NN-Caption通过组合来自LEMUR分类骨干的CNN编码器与序列解码器（LSTM/GRU/Transformer），在严格的Net API下生成图像字幕模型。该方法使用DeepSeek-R1-0528-Qwen3-8B作为主要生成器，并通过提示模板和生成的架构示例进行评估。

Result: LLM生成了数十个字幕模型，其中一半以上成功训练并生成了有意义的字幕。在MS COCO数据集上使用BLEU-4进行评估。研究发现，在提示中提供更多候选组件（10个 vs 5个）时，成功率略有下降。

Conclusion: LLM引导的NAS具有巨大潜力，LLM不仅可以提出架构，还可以建议超参数和训练实践。研究还指出了遇到的挑战（如代码幻觉或API合规性问题），并通过提示规则和迭代代码修复来解决。这项工作提出了一个将基于提示的代码生成与自动评估相结合的流程，并向开放的LEMUR数据集添加了数十个新颖的字幕模型，以促进可重现的基准测试和下游AutoML研究。

Abstract: Neural architecture search (NAS) traditionally requires significant human expertise or automated trial-and-error to design deep learning models. We present NN-Caption, an LLM-guided neural architecture search pipeline that generates runnable image-captioning models by composing CNN encoders from LEMUR's classification backbones with sequence decoders (LSTM/GRU/Transformer) under a strict Net API. Using DeepSeek-R1-0528-Qwen3-8B as the primary generator, we present the prompt template and examples of generated architectures. We evaluate on MS COCO with BLEU-4. The LLM generated dozens of captioning models, with over half successfully trained and producing meaningful captions. We analyse the outcomes of using different numbers of input model snippets (5 vs. 10) in the prompt, finding a slight drop in success rate when providing more candidate components. We also report training dynamics (caption accuracy vs. epochs) and the highest BLEU-4 attained. Our results highlight the promise of LLM-guided NAS: the LLM not only proposes architectures but also suggests hyperparameters and training practices. We identify the challenges encountered (e.g., code hallucinations or API compliance issues) and detail how prompt rules and iterative code fixes addressed them. This work presents a pipeline that integrates prompt-based code generation with automatic evaluation, and adds dozens of novel captioning models to the open LEMUR dataset to facilitate reproducible benchmarking and downstream AutoML research.

</details>


### [38] [Epistemic diversity across language models mitigates knowledge collapse](https://arxiv.org/abs/2512.15011)
*Damian Hodel,Jevin D. West*

Main category: cs.LG

TL;DR: 本文探讨了AI生态系统多样性如何缓解知识坍塌问题。


<details>
  <summary>Details</summary>
Motivation: AI的日益普及引发了知识坍塌的担忧，即知识会收敛到最主要和核心的思想。

Method: 我们基于单模型方法，但专注于在模型集体输出上训练的模型生态系统。 为了研究多样性对模型性能的影响，我们将训练数据分段到不同的语言模型中，并评估了经过十次自训练迭代后的生态系统。

Result: 我们发现，增加认知多样性可以缓解坍塌，但有趣的是，只在达到最佳水平之前有效。 结果表明，只包含少数不同模型的生态系统无法表达完整、真实分布的丰富混合，导致性能快速下降。然而，将数据分布到太多模型中会降低每个模型对真实分布的近似能力，导致在第一次迭代步骤中性能就已经很差。

Conclusion: 在AI单一文化背景下，我们的结果表明需要监测AI系统之间的多样性，并制定政策以激励更多领域和社区特定的模型。

Abstract: The growing use of artificial intelligence (AI) raises concerns of knowledge collapse, i.e., a reduction to the most dominant and central set of ideas. Prior work has demonstrated single-model collapse, defined as performance decay in an AI model trained on its own output. Inspired by ecology, we ask whether AI ecosystem diversity, that is, diversity among models, can mitigate such a collapse. We build on the single-model approach but focus on ecosystems of models trained on their collective output. To study the effect of diversity on model performance, we segment the training data across language models and evaluate the resulting ecosystems over ten, self-training iterations. We find that increased epistemic diversity mitigates collapse, but, interestingly, only up to an optimal level. Our results suggest that an ecosystem containing only a few diverse models fails to express the rich mixture of the full, true distribution, resulting in rapid performance decay. Yet distributing the data across too many models reduces each model's approximation capacity on the true distribution, leading to poor performance already in the first iteration step. In the context of AI monoculture, our results suggest the need to monitor diversity across AI systems and to develop policies that incentivize more domain- and community-specific models.

</details>


### [39] [Autonomous Source Knowledge Selection in Multi-Domain Adaptation](https://arxiv.org/abs/2512.14710)
*Keqiuyin Li,Jie Lu,Hua Zuo,Guangquan Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种名为AutoS的无监督多领域适应方法，可以自动选择源样本和模型，以提高迁移学习性能，并在真实世界数据集中取得了优越的实验结果。


<details>
  <summary>Details</summary>
Motivation: 在多领域适应中，当源领域数量庞大时，其中包含的冗余或不相关信息会损害迁移性能。因此，开发有效的策略来识别和选择最具可迁移性的知识以解决目标任务是紧迫的。

Method: AutoS方法采用了密度驱动的选择策略，在训练过程中选择源样本，并确定哪些源模型应该对目标预测做出贡献。同时，使用基于预训练多模态模型的伪标签增强模块来缓解目标标签噪声并改进自我监督。

Result: 在现实世界数据集上的实验表明，所提出的方法具有优越性。

Conclusion: AutoS方法通过自动选择相关的和可迁移的源信息，成功解决了大规模源领域中冗余信息对迁移性能的负面影响。

Abstract: Unsupervised multi-domain adaptation plays a key role in transfer learning by leveraging acquired rich source information from multiple source domains to solve target task from an unlabeled target domain. However, multiple source domains often contain much redundant or unrelated information which can harm transfer performance, especially when in massive-source domain settings. It is urgent to develop effective strategies for identifying and selecting the most transferable knowledge from massive source domains to address the target task. In this paper, we propose a multi-domain adaptation method named \underline{\textit{Auto}}nomous Source Knowledge \underline{\textit{S}}election (AutoS) to autonomosly select source training samples and models, enabling the prediction of target task using more relevant and transferable source information. The proposed method employs a density-driven selection strategy to choose source samples during training and to determine which source models should contribute to target prediction. Simulteneously, a pseudo-label enhancement module built on a pre-trained multimodal modal is employed to mitigate target label noise and improve self-supervision. Experiments on real-world datasets indicate the superiority of the proposed method.

</details>


### [40] [A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour](https://arxiv.org/abs/2512.14713)
*Georges Sfeir,Stephane Hess,Thomas O. Hancock,Filipe Rodrigues,Jamal Amani Rad,Michiel Bliemer,Matthew Beck,Fayyaz Khan*

Main category: cs.LG

TL;DR: 本文提出了一种潜在类别强化学习（LCRL）模型，用于捕捉个体旅行决策中偏好形成和异质性。


<details>
  <summary>Details</summary>
Motivation: 为了解决个体旅行决策中经验形成和异质性问题，即个体学习偏好随时间变化，且个体旅行者在潜在偏好和偏好演变方式上存在广泛异质性。

Method: 本文提出了一种潜在类别强化学习（LCRL）模型，并通过变分贝叶斯估计参数。

Result: 本文识别出三种不同类型的个体，他们适应偏好的方式截然不同：第一类表现出情境依赖性偏好，具有情境特定的利用倾向；第二类 H 无论情境如何，都遵循持续的利用策略；第三类采用探索性策略并结合情境特定偏好。

Conclusion: LCRL模型能够有效地捕捉个体旅行决策中的偏好形成和异质性，识别出不同个体在偏好适应方面的显著差异。

Abstract: Many travel decisions involve a degree of experience formation, where individuals learn their preferences over time. At the same time, there is extensive scope for heterogeneity across individual travellers, both in their underlying preferences and in how these evolve. The present paper puts forward a Latent Class Reinforcement Learning (LCRL) model that allows analysts to capture both of these phenomena. We apply the model to a driving simulator dataset and estimate the parameters through Variational Bayes. We identify three distinct classes of individuals that differ markedly in how they adapt their preferences: the first displays context-dependent preferences with context-specific exploitative tendencies; the second follows a persistent exploitative strategy regardless of context; and the third engages in an exploratory strategy combined with context-specific preferences.

</details>


### [41] [A Regime-Aware Fusion Framework for Time Series Classification](https://arxiv.org/abs/2512.15378)
*Honey Singh Chauhan,Zahraa S. Abdallah*

Main category: cs.LG

TL;DR: 该文章推出一个名为F3（Fusion-3）的轻量级框架，自适应地融合了Rocket、SAX和SFA表示，以改进时间序列分类（TSC）中基于核方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的核方法（如Rocket）在单变量时间序列分类中表现最佳，但并不是在所有数据集上都同样有效。

Method: Fusion-3（F3）框架融合了Rocket、Sax和Sfa表示。通过分析数据集的元特征（序列长度、谱结构、粗糙度和类别不平衡），将UCR数据集分为六类，从而确定融合何时能带来改进。该研究结合了非参数配对统计、消融研究和SHAP归因分析来支持其发现。

Result: Fusion-3（F3）框架在具有结构化变异性或丰富频率内容的数据集中，其性能优于强大的基线模型，但在高度不规则或异常值较多的环境中，收益会减少。

Conclusion: 选择性地应用融合技术可以为强大的核方法提供可靠且可解释的扩展，特别是在数据支持的情况下，也就是在传统核方法表现不佳的时候，存在特定弱点的情况下改进效果最明显的区域。

Abstract: Kernel-based methods such as Rocket are among the most effective default approaches for univariate time series classification (TSC), yet they do not perform equally well across all datasets. We revisit the long-standing intuition that different representations capture complementary structure and show that selectively fusing them can yield consistent improvements over Rocket on specific, systematically identifiable kinds of datasets. We introduce Fusion-3 (F3), a lightweight framework that adaptively fuses Rocket, Sax, and Sfa representations. To understand when fusion helps, we cluster UCR datasets into six groups using meta-features capturing series length, spectral structure, roughness, and class imbalance, and treat these clusters as interpretable data-structure regimes. Our analysis shows that fusion typically outperforms strong baselines in regimes with structured variability or rich frequency content, while offering diminishing returns in highly irregular or outlier-heavy settings. To support these findings, we combine three complementary analyses: non-parametric paired statistics across datasets, ablation studies isolating the roles of individual representations, and attribution via SHAP to identify which dataset properties predict fusion gains. Sample-level case studies further reveal the underlying mechanism: fusion primarily improves performance by rescuing specific errors, with adaptive increases in frequency-domain weighting precisely where corrections occur. Using 5-fold cross-validation on the 113 UCR datasets, F3 yields small but consistent average improvements over Rocket, supported by frequentist and Bayesian evidence and accompanied by clearly identifiable failure cases. Our results show that selectively applied fusion provides dependable and interpretable extension to strong kernel-based methods, correcting their weaknesses precisely where the data support it.

</details>


### [42] [How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection](https://arxiv.org/abs/2512.14715)
*Zafaryab Haider,Md Hafizur Rahman,Shane Moeykens,Vijay Devabhaktuni,Prabuddha Chakraborty*

Main category: cs.LG

TL;DR: 本文首次深入探讨了位级别扰动（错误注入）如何影响大型语言模型（LLM）在图像字幕生成任务中的语义。


<details>
  <summary>Details</summary>
Motivation: 以往的故障分析方法忽略了生成系统的语义和语言维度。本文旨在探究位级别扰动如何改变LLM生成的字幕的语义，同时保持语法结构和流畅性。

Method: 本文提出了一种可微分的故障分析框架BLADE，它利用基于梯度的敏感性估计来定位语义关键位，并通过字幕级别的语义流畅性目标来优化这些位的选择。

Result: 研究发现，即使是难以察觉的低级别位扰动也能显著影响生成式视觉-语言模型的高级语义，表明语义漂移并非随机，而是可微分估计的。

Conclusion: 这项工作不仅揭示了意义在位级别的编码、分布和可变性，还为鲁棒性测试、对抗性防御和可解释人工智能开辟了新途径，通过展示结构化的位级别故障如何重塑模型的语义输出。

Abstract: Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LLM) used for image captioning can influence the semantic meaning of its generated descriptions while preserving grammatical structure. While prior fault analysis methods have shown that flipping a few bits can crash classifiers or degrade accuracy, these approaches overlook the semantic and linguistic dimensions of generative systems. In image captioning models, a single flipped bit might subtly alter how visual features map to words, shifting the entire narrative an AI tells about the world. We hypothesize that such semantic drifts are not random but differentiably estimable. That is, the model's own gradients can predict which bits, if perturbed, will most strongly influence meaning while leaving syntax and fluency intact. We design a differentiable fault analysis framework, BLADE (Bit-level Fault Analysis via Differentiable Estimation), that uses gradient-based sensitivity estimation to locate semantically critical bits and then refines their selection through a caption-level semantic-fluency objective. Our goal is not merely to corrupt captions, but to understand how meaning itself is encoded, distributed, and alterable at the bit level, revealing that even imperceptible low-level changes can steer the high-level semantics of generative vision-language models. It also opens pathways for robustness testing, adversarial defense, and explainable AI, by exposing how structured bit-level faults can reshape a model's semantic output.

</details>


### [43] [Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox](https://arxiv.org/abs/2512.14717)
*Ziqian Bi,Danyang Zhang,Junhao Song,Chiung-Yi Tseng*

Main category: cs.LG

TL;DR: 本文对GPT-OSS模型家族及其与当代大型语言模型在十个金融NLP任务中的表现进行了全面评估。研究发现，较小的GPT-OSS-20B模型在准确性方面与GPT-OSS-120B模型相当，但计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型被金融服务业快速采用的背景下，需要一个严格的评估框架来评估它们的性能、效率和实际适用性。

Method: 本文通过在包括GPT-OSS-120B和GPT-OSS-20B在内的GPT-OSS模型家族上进行广泛实验，评估了它们在十个不同的金融NLP任务上的表现。评估任务包括情感分析、问答和实体识别，使用了真实的金融数据集。同时引入了新的效率指标，以衡量模型性能和资源利用之间的权衡。

Result: 研究发现，较小的GPT-OSS-20B模型（65.1%）的准确性与GPT-OSS-120B模型（66.5%）相当，但计算效率更高，Token效率得分为198.4，处理速度为每秒159.80个令牌。GPT-OSS模型始终优于包括Qwen3-235B在内的更大竞争对手。

Conclusion: GPT-OSS模型在架构创新和训练策略上的优势，使得小型模型能够在显著降低计算开销的同时，实现具有竞争力的性能，为金融应用中实现可持续且经济高效的大语言模型部署提供了可能。

Abstract: The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS model family alongside contemporary LLMs across ten diverse financial NLP tasks. Through extensive experimentation on 120B and 20B parameter variants of GPT-OSS, we reveal a counterintuitive finding: the smaller GPT-OSS-20B model achieves comparable accuracy (65.1% vs 66.5%) while demonstrating superior computational efficiency with 198.4 Token Efficiency Score and 159.80 tokens per second processing speed [1]. Our evaluation encompasses sentiment analysis, question answering, and entity recognition tasks using real-world financial datasets including Financial PhraseBank, FiQA-SA, and FLARE FINERORD. We introduce novel efficiency metrics that capture the trade-off between model performance and resource utilization, providing critical insights for deployment decisions in production environments. The benchmark reveals that GPT-OSS models consistently outperform larger competitors including Qwen3-235B, challenging the prevailing assumption that model scale directly correlates with task performance [2]. Our findings demonstrate that architectural innovations and training strategies in GPT-OSS enable smaller models to achieve competitive performance with significantly reduced computational overhead, offering a pathway toward sustainable and cost-effective deployment of LLMs in financial applications.

</details>


### [44] [Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction](https://arxiv.org/abs/2512.15605)
*Mathieu Blondel,Michael E. Sander,Germain Vivier-Ardisson,Tianlin Liu,Vincent Roulet*

Main category: cs.LG

TL;DR: 本文统一了自回归模型（ARMs）和基于能量的模型（EBMs）这两种大语言模型（LLMs）的建模范式，并建立了它们之间的显式双射关系。


<details>
  <summary>Details</summary>
Motivation: 目前，自回归模型（ARMs）是大型语言模型（LLM）的主流范式。然而，基于能量的模型（EBMs）在LLM开发中较少使用，但它们天然地能够刻画后训练对齐中的最优策略。因此，本文旨在统一这两种模型，并探究它们之间的关系。

Method: 本文以概率的链式法则为起点，在函数空间中建立了ARMs和EBMs之间的显式双射关系，并指出这对应于最大熵强化学习中软贝尔曼方程的一个特例。在此基础上，本文推导了ARMs和EBMs在监督学习上的等价性，并通过理论误差界分析了EBMs到ARMs的蒸馏过程。

Result: 本文建立了ARMs和EBMs之间的显式双射关系，并证明了它们在监督学习上的等价性。此外，本文还提供了EBMs到ARMs蒸馏的理论误差界。

Conclusion: 本文的研究成果揭示了ARMs在预测下一个标记的范式下进行超前规划的能力，为理解和开发LLMs提供了新的视角。

Abstract: Autoregressive models (ARMs) currently constitute the dominant paradigm for large language models (LLMs). Energy-based models (EBMs) represent another class of models, which have historically been less prevalent in LLM development, yet naturally characterize the optimal policy in post-training alignment. In this paper, we provide a unified view of these two model classes. Taking the chain rule of probability as a starting point, we establish an explicit bijection between ARMs and EBMs in function space, which we show to correspond to a special case of the soft Bellman equation in maximum entropy reinforcement learning. Building upon this bijection, we derive the equivalence between supervised learning of ARMs and EBMs. Furthermore, we analyze the distillation of EBMs into ARMs by providing theoretical error bounds. Our results provide insights into the ability of ARMs to plan ahead, despite being based on the next-token prediction paradigm.

</details>


### [45] [SEED: Spectral Entropy-Guided Evaluation of SpatialTemporal Dependencies for Multivariate Time Series Forecasting](https://arxiv.org/abs/2512.14718)
*Feng Xiong,Zongxia Xie,Yanru Sun,Haoyu Wang,Jianhong Lin*

Main category: cs.LG

TL;DR: SEED通过引入依赖评估器、基于谱熵的融合器、有符号图构造器和上下文空间提取器，提高了多元时间序列预测中的时空依赖建模性能，解决了现有方法中断裂的自依赖、忽略负相关和缺乏时间位置感知的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的注意力或基于图的方法在处理多元时间序列预测时存在三个关键问题：强时间自依赖易受不相关变量干扰；softmax归一化忽略并反转负相关；变量难以感知其时间位置。

Method: 本文提出了SEED（Spectral Entropy-guided Evaluation framework for spatial-temporal Dependency modeling）框架。该框架引入了：1. 依赖评估器（Dependency Evaluator），利用谱熵动态评估变量的时空依赖性，平衡通道独立性（CI）和通道依赖性（CD）策略。2. 基于谱熵的融合器（Spectral Entropy-based Fuser），进一步细化依赖权重，分离来自其他变量影响的时间规律。3. 有符号图构造器（Signed Graph Constructor），允许有符号的边权重，以保留负相关。4. 上下文空间提取器（Context Spatial Extractor），利用局部上下文窗口提取空间特征，帮助变量感知其时间位置。

Result: SEED在12个来自不同应用领域的真实世界数据集上取得了最先进的性能。

Conclusion: SEED框架通过有效解决现有方法在多元时间序列预测中面临的挑战，即强时间自依赖易受无关变量干扰、忽略负相关以及缺乏时间位置感知，显著提升了时空依赖建模的准确性和泛化性。

Abstract: Effective multivariate time series forecasting often benefits from accurately modeling complex inter-variable dependencies. However, existing attention- or graph-based methods face three key issues: (a) strong temporal self-dependencies are often disrupted by irrelevant variables; (b) softmax normalization ignores and reverses negative correlations; (c) variables struggle to perceive their temporal positions. To address these, we propose \textbf{SEED}, a Spectral Entropy-guided Evaluation framework for spatial-temporal Dependency modeling. SEED introduces a Dependency Evaluator, a key innovation that leverages spectral entropy to dynamically provide a preliminary evaluation of the spatial and temporal dependencies of each variable, enabling the model to adaptively balance Channel Independence (CI) and Channel Dependence (CD) strategies. To account for temporal regularities originating from the influence of other variables rather than intrinsic dynamics, we propose Spectral Entropy-based Fuser to further refine the evaluated dependency weights, effectively separating this part. Moreover, to preserve negative correlations, we introduce a Signed Graph Constructor that enables signed edge weights, overcoming the limitations of softmax. Finally, to help variables perceive their temporal positions and thereby construct more comprehensive spatial features, we introduce the Context Spatial Extractor, which leverages local contextual windows to extract spatial features. Extensive experiments on 12 real-world datasets from various application domains demonstrate that SEED achieves state-of-the-art performance, validating its effectiveness and generality.

</details>


### [46] [Hybrid Attribution Priors for Explainable and Robust Model Training](https://arxiv.org/abs/2512.14719)
*Zhuoran Zhang,Feng Zhang,Shangyuan Li,Yang Shi,Yuanxing Zhang,Wei Chen,Tengjiao Wang,Kam-Fai Wong*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的归因先验提取框架，称为CAP，用于指导语言模型捕获细粒度的类区分，并且生成更显著、更具辨别力的归因先验。此外，我们引入了CAP Hybrid，它是CAP与现有归因技术相结合的产物，形成了更全面和平衡的监督信号，该方法在全数据、少样本和对抗性场景中都增强了可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在分类任务中，可解释性和鲁棒性变得越来越重要，归因引导学习作为一种有效的框架通过在训练期间引入基于归因的监督来解决这些问题。然而，获得通用且可靠的归因先验仍然是一个重大挑战，现有方法无法有效区分语义相似的类。

Method: 我们提出了类别感知归因先验（CAP）框架，它旨在通过识别每个类别的独特判别特征来克服现有归因方法的缺点。我们还引入了CAP Hybrid，它结合了CAP的先验和现有归因技术的先验。通过将模型的自我归因与这些丰富的先验对齐，我们的方法鼓励学习多样化的、与决策相关联的特征。

Result: 在全数据、少样本和对抗性场景中进行的大量实验结果表明，该方法能够一致地提高模型的可解释性和鲁棒性。

Conclusion: CAP和CAP Hybrid的引入，通过提供更具辨别力的归因先验，显著提高了小型语言模型在分类任务中的可解释性和鲁棒性。这些方法通过鼓励模型关注细粒度的类别区分，能够学习到更丰富和决策相关的特征。

Abstract: Small language models (SLMs) are widely used in tasks that require low latency and lightweight deployment, particularly classification. As interpretability and robustness gain increasing importance, explanation-guided learning has emerged as an effective framework by introducing attribution-based supervision during training; however, deriving general and reliable attribution priors remains a significant challenge. Through an analysis of representative attribution methods in classification settings, we find that although these methods can reliably highlight class-relevant tokens, they often focus on common keywords shared by semantically similar classes. Because such classes are already difficult to distinguish under standard training, these attributions provide insufficient discriminative cues, limiting their ability to improve model differentiation. To overcome this limitation, we propose Class-Aware Attribution Prior (CAP), a novel attribution prior extraction framework that guides language models toward capturing fine-grained class distinctions and producing more salient, discriminative attribution priors. Building on this idea, we further introduce CAP Hybrid, which combines priors from CAP with those from existing attribution techniques to form a more comprehensive and balanced supervisory signal. By aligning a model's self-attribution with these enriched priors, our approach encourages the learning of diverse, decision-relevant features. Extensive experiments in full-data, few-shot, and adversarial scenarios demonstrate that our method consistently enhances both interpretability and robustness.

</details>


### [47] [Automatic Extraction of Rules for Generating Synthetic Patient Data From Real-World Population Data Using Glioblastoma as an Example](https://arxiv.org/abs/2512.14721)
*Arno Appenzeller,Nick Terzer,André Hohmeyer,Jan-Philipp Redlich,Sabine Luttmann,Friedrich Feuerhake,Nadine S. Schaadt,Timm Intemann,Sarah Teuber-Hanselmann,Stefan Nikolin,Joachim Weis,Klaus Kraywinkel,Pascal Birnstill*

Main category: cs.LG

TL;DR: 本文介绍了一种基于结构化数据自动生成Synthea规则的方法。


<details>
  <summary>Details</summary>
Motivation: 医学数据的二次利用在保护隐私方面具有挑战性，而合成数据是解决这一问题的一种有前景的技术。Synthea是一种流行的基于规则的生成患者数据的方法，但创建有意义的规则需要专业知识和实际样本数据。

Method: 本文提出了一种基于表格数据统计信息自动生成Synthea规则的方法，并以胶质母细胞瘤为例，从真实世界数据集中创建了一个Synthea模块，并生成了合成数据集。

Result: 与原始数据集相比，合成数据再现了已知的疾病过程，并基本保留了统计特性。

Conclusion: 合成患者数据在保护隐私的研究方面具有巨大潜力。该数据可用于提出假设和开发原型，但医学解释应考虑具体限制。

Abstract: The generation of synthetic data is a promising technology to make medical data available for secondary use in a privacy-compliant manner. A popular method for creating realistic patient data is the rule-based Synthea data generator. Synthea generates data based on rules describing the lifetime of a synthetic patient. These rules typically express the probability of a condition occurring, such as a disease, depending on factors like age. Since they only contain statistical information, rules usually have no specific data protection requirements. However, creating meaningful rules can be a very complex process that requires expert knowledge and realistic sample data. In this paper, we introduce and evaluate an approach to automatically generate Synthea rules based on statistics from tabular data, which we extracted from cancer reports. As an example use case, we created a Synthea module for glioblastoma from a real-world dataset and used it to generate a synthetic dataset. Compared to the original dataset, the synthetic data reproduced known disease courses and mostly retained the statistical properties. Overall, synthetic patient data holds great potential for privacy-preserving research. The data can be used to formulate hypotheses and to develop prototypes, but medical interpretation should consider the specific limitations as with any currently available approach.

</details>


### [48] [HATSolver: Learning Groebner Bases with Hierarchical Attention Transformers](https://arxiv.org/abs/2512.14722)
*Mohamed Malhou,Ludovic Perret,Kristin Lauter*

Main category: cs.LG

TL;DR: 该论文通过使用分层注意力变换器（HATs）改进了Kera等人提出的用于计算Groebner基的方法。


<details>
  <summary>Details</summary>
Motivation: Kera等人提出了一种使用变换器计算Groebner基的方法，本论文旨在改进这一方法。

Method: 本论文通过应用分层注意力变换器（HATs）来解决多元多项式方程组，HATs结合了树形结构的归纳偏置，能够建模数据中存在的层次关系，从而显著节省计算成本。方法还推广到任意深度，并进行了详细的计算成本分析，并结合课程学习。

Result: 与Kera等人的方法相比，本方法能够解决更大规模的实例。

Conclusion: 分层注意力变换器（HATs）结合课程学习，能够有效改进Groebner基的计算效率，处理更大规模的问题。

Abstract: At NeurIPS 2024, Kera et al. introduced the use of transformers for computing Groebner bases, a central object in computer algebra with numerous practical applications. In this paper, we improve this approach by applying Hierarchical Attention Transformers (HATs) to solve systems of multivariate polynomial equations via Groebner bases computation. The HAT architecture incorporates a tree-structured inductive bias that enables the modeling of hierarchical relationships present in the data and thus achieves significant computational savings compared to conventional flat attention models. We generalize to arbitrary depths and include a detailed computational cost analysis. Combined with curriculum learning, our method solves instances that are much larger than those in Kera et al. (2024 Learning to compute Groebner bases)

</details>


### [49] [Multi-Modal Semantic Communication](https://arxiv.org/abs/2512.15691)
*Matin Mortaheb,Erciyes Karakaya,Sennur Ulukus*

Main category: cs.LG

TL;DR: 该文章提出了一种新颖的多模态语义通信框架，通过整合基于文本的用户查询来指导信息提取过程，解决了现有方法在复杂场景中信息提取的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于transformer的方法在复杂场景中识别图像信息区域时，自我注意力机制缺乏明确的任务指导，导致性能不佳。

Method: 本研究提出了一种多模态语义通信框架，通过跨模态注意力机制将视觉特征与语言嵌入融合，生成视觉数据的软相关性分数。基于这些分数和瞬时信道带宽，利用算法以自适应分辨率传输图像块，并使用独立训练的编解码器对，使总比特率与信道容量匹配。接收端重建并组合图像块以保留任务关键信息。

Result: 所提出的框架能够有效地在复杂和带宽受限的环境中实现语义通信，并通过文本查询指导信息提取过程。

Conclusion: 该研究提出的多模态语义通信框架通过引入文本查询和跨模态注意力机制，有效解决了复杂场景下语义通信的信息提取问题，实现了高效、目标驱动的通信。

Abstract: Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.

</details>


### [50] [A Critical Perspective on Finite Sample Conformal Prediction Theory in Medical Applications](https://arxiv.org/abs/2512.14727)
*Klaus-Rudolf Kladny,Bernhard Schölkopf,Lisa Koch,Christian F. Baumgartner,Michael Muehlebach*

Main category: cs.LG

TL;DR: 论文深入探讨了共形预测（CP）在机器学习（ML）医疗应用中的局限性，特别是在校准数据集较小的情况下，CP的实际效用远低于其理论保证。


<details>
  <summary>Details</summary>
Motivation: 机器学习在医疗健康领域显示出巨大潜力，但临床决策需要可靠的不确定性估计，传统机器学习模型无法提供。共形预测（CP）被认为是提供具有统计学保证的不确定性估计的有效工具，但其在数据稀缺的医疗领域的实际有效性尚未明确。

Method: 本研究通过分析共形预测（CP）的理论和实践应用，并结合医学图像分类任务的实证研究，探讨了CP在校准数据集大小受限时的表现。

Result: 尽管共形预测（CP）的统计学保证在理论上适用于任意大小的校准数据集，但这些保证的实际效用却高度依赖于校准数据集的大小。在数据稀缺的医疗领域，小规模校准数据集会严重限制CP的实际应用价值。

Conclusion: 共形预测（CP）在医疗领域的应用面临挑战，尤其是在数据稀缺导致校准数据集较小的情况下。未来的研究应关注如何在有限数据下提高CP的实际效用，以确保医疗决策的可靠性。

Abstract: Machine learning (ML) is transforming healthcare, but safe clinical decisions demand reliable uncertainty estimates that standard ML models fail to provide. Conformal prediction (CP) is a popular tool that allows users to turn heuristic uncertainty estimates into uncertainty estimates with statistical guarantees. CP works by converting predictions of a ML model, together with a calibration sample, into prediction sets that are guaranteed to contain the true label with any desired probability. An often cited advantage is that CP theory holds for calibration samples of arbitrary size, suggesting that uncertainty estimates with practically meaningful statistical guarantees can be achieved even if only small calibration sets are available. We question this promise by showing that, although the statistical guarantees hold for calibration sets of arbitrary size, the practical utility of these guarantees does highly depend on the size of the calibration set. This observation is relevant in medical domains because data is often scarce and obtaining large calibration sets is therefore infeasible. We corroborate our critique in an empirical demonstration on a medical image classification task.

</details>


### [51] [A data-driven approach to inferring travel trajectory during peak hours in urban rail transit systems](https://arxiv.org/abs/2512.14728)
*Jie He,Yong Qin,Jianyuan Guo,Xuan Sun,Xuanchuan Zheng*

Main category: cs.LG

TL;DR: 本文提出了一种全数据驱动的城市轨道交通个体出行轨迹推断方法，结合AFC和AVL数据，利用KLEM方法进行参数估计和轨迹构建，并在真实数据上验证了其高峰期超过90%的推断准确率。


<details>
  <summary>Details</summary>
Motivation: 尽管轨道交通轨迹推断对运营组织有重要意义，但现有方法通常依赖外部数据或调查数据进行参数拟合。因此，本研究的动机是开发一种完全数据驱动的方法，以克服这些限制，提高模型的鲁棒性和适用性，并利用真实数据进行验证。

Method: 本研究提出了一种全数据驱动的方法，包括基于时空约束建立列车备选集、数据驱动的自适应轨迹推断和出行轨迹构建。为了实现自适应轨迹推断，引入了一种结合KL散度与EM算法（KLEM）的数据驱动参数估计算法。该方法利用AFC和AVL数据，无需外部或调查数据进行参数拟合。

Result: 该方法在高峰期对城市轨道交通出行轨迹的推断准确率超过90%。

Conclusion: 本文开发的轨迹推断方法能够实现高精度的乘客轨迹推断，尤其在高峰时段表现出色，且通过采用KLEM方法实现了参数估计的完全数据驱动，提高了模型的实用性和鲁棒性。

Abstract: Refined trajectory inference of urban rail transit is of great significance to the operation organization. In this paper, we develop a fully data-driven approach to inferring individual travel trajectories in urban rail transit systems. It utilizes data from the Automatic Fare Collection (AFC) and Automatic Vehicle Location (AVL) systems to infer key trajectory elements, such as selected train, access/egress time, and transfer time. The approach includes establishing train alternative sets based on spatio-temporal constraints, data-driven adaptive trajectory inference, and trave l trajectory construction. To realize data-driven adaptive trajectory inference, a data-driven parameter estimation method based on KL divergence combined with EM algorithm (KLEM) was proposed. This method eliminates the reliance on external or survey data for parameter fitting, enhancing the robustness and applicability of the model. Furthermore, to overcome the limitations of using synthetic data to validate the result, this paper employs real individual travel trajectory data for verification. The results show that the approach developed in this paper can achieve high-precision passenger trajectory inference, with an accuracy rate of over 90% in urban rail transit travel trajectory inference during peak hours.

</details>


### [52] [Semantic Geometry for policy-constrained interpretation](https://arxiv.org/abs/2512.14731)
*Nikit Phadke*

Main category: cs.LG

TL;DR: 该论文提出了一种几何框架，用于策略约束下的语义解释，可有效防止在高风险领域中出现虚假承诺。


<details>
  <summary>Details</summary>
Motivation: 在大规模高风险领域中，防止语义解释中出现虚假承诺是一个关键挑战。

Method: 语义意义被表示为单位球体上的方向，证据被建模为见证向量集，可接受的解释对应于球面凸区域。策略约束作为明确的先验被引入，并在同一流形上定义，与证据几何分离。解释被简化为对可接受区域的约束优化，当出现矛盾或策略排除时，拒绝成为拓扑上必要的结果。

Result: 在没有幻觉批准的情况下，对大规模受监管金融数据进行了实证验证，并且在多个政策制度下都取得了零幻觉批准的结果。

Conclusion: 该框架通过几何方法和策略约束，成功解决了高风险领域中语义解释的幻觉问题，并在信息理论上实现了最优的复杂性界限。

Abstract: We present a geometric framework for policy-constrained semantic interpretation that provably prevents hallucinated commitments in high-stakes domains. Semantic meaning is represented as direction on a unit sphere, evidence is modeled as sets of witness vectors, and admissible interpretations correspond to spherical convex regions. Policy constraints are introduced as explicit priors defined over the same manifold, separated from evidence geometry. Interpretation reduces to constrained optimization over admissible regions, with refusal emerging as a topologically necessary outcome under contradiction or policy exclusion. We connect this framework to information theory, Bayesian inference, and sheaf-theoretic semantics, proving that our complexity bounds are information-theoretically optimal. Empirical validation on large scale regulated financial data demonstrates zero hallucinated approvals across multiple policy regimes-the first such result at scale.

</details>


### [53] [Inference Time Feature Injection: A Lightweight Approach for Real-Time Recommendation Freshness](https://arxiv.org/abs/2512.14734)
*Qiang Chen,Venkatesh Ganapati Hegde,Hongfei Li*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种在长视频流中实现日内个性化推荐的轻量级方法，该方法通过在推理时注入用户最近的观看历史来克服批处理模型和特征更新的不足，从而显著提升了用户参与度。


<details>
  <summary>Details</summary>
Motivation: 传统的视频推荐系统依赖批量训练模型和日更新的用户特征，导致推荐内容无法及时反映用户最新行为，造成“不新鲜”的推荐。

Method: 本文提出了一种轻量级、与模型无关的日内个性化方法，该方法在推理时选择性地注入用户最近的观看历史，从而覆盖过时的用户特征，使系统能够即时适应用户不断变化的偏好，而无需模型再训练。

Result: 通过将个性化反馈周期从每日缩短到日内，我们观察到关键用户参与度指标统计上显著提升了0.47%，这是在近期实验周期中观察到的最显著的参与度提升之一。

Conclusion: 日内个性化在长视频流服务中能够产生有意义的影响，为需要模型再训练的全面实时架构提供了一种有吸引力的替代方案。

Abstract: Many recommender systems in long-form video streaming reply on batch-trained models and batch-updated features, where user features are updated daily and served statically throughout the day. While efficient, this approach fails to incorporate a user's most recent actions, often resulting in stale recommendations. In this work, we present a lightweight, model-agnostic approach for intra-day personalization that selectively injects recent watch history at inference time without requiring model retraining. Our approach selectively overrides stale user features at inference time using the recent watch history, allowing the system to adapt instantly to evolving preferences. By reducing the personalization feedback loop from daily to intra-day, we observed a statistically significant 0.47% increase in key user engagement metrics which ranked among the most substantial engagement gains observed in recent experimentation cycles. To our knowledge, this is the first published evidence that intra-day personalization can drive meaningful impact in long-form video streaming service, providing a compelling alternative to full real-time architectures where model retraining is required.

</details>


### [54] [NoveltyRank: Estimating Conceptual Novelty of AI Papers](https://arxiv.org/abs/2512.14738)
*Zhengxu Yan,Han Li,Yuming Feng*

Main category: cs.LG

TL;DR: 该项目旨在开发一个模型，用于评估AI领域研究论文的概念新颖性，以帮助研究人员和审稿人识别真正创新而非细微改进的工作。


<details>
  <summary>Details</summary>
Motivation: 随着学术出版的日益便捷，研究论文的数量激增，尤其是在AI领域。这使得真正新颖和有影响力的工作难以脱颖而出，而手动评估新颖性既不稳定又耗时。

Method: 该方法主要通过论文的标题、摘要及其与现有文献的语义相似性来评估新颖性。探索了两种任务形式：1) 二进制分类，根据现有新颖工作的模式预测论文的绝对新颖性；2) 成对新颖性比较，学习区分论文的相对新颖性。在Qwen3-4B-Instruct-2507和SciBERT上进行了微调，并与GPT-5.1进行了基准测试。

Result: 通过对Qwen3-4B-Instruct-2507和SciBERT在两种任务上的微调，并与GPT-5.1进行基准测试，分析了任务形式和模型选择如何影响性能。

Conclusion: 该系统可以帮助研究人员有效地识别引入真正创新思想的提交，并为会议审稿人提供量化和一致的新颖性信号。

Abstract: With the growing ease of academic publishing, the volume of research papers, especially in AI-related fields, has surged dramatically. This flood of publications makes it difficult for truly novel and impactful work to stand out, and manual novelty assessment is often unstable and time-consuming. Our project aims to develop a model that estimates and ranks the conceptual novelty of AI papers, enabling a data-driven and scalable assessment of research originality. Such a system can help researchers efficiently identify submissions that introduce genuinely innovative ideas rather than minor variants, and provide conference reviewers with a quantitative and consistent signal of novelty. Our approach evaluates novelty primarily through a paper's title, abstract, and semantic similarity to prior literature. Given the motivation of novelty estimation, we explore two task formulations with different modeling objectives, each offering a different perspective: (1) binary classification, which predicts the paper's absolute novelty from learned patterns of prior novel works, and (2) pairwise novelty comparison, which learns to distinguish papers by relative novelty over others. We fine-tune Qwen3-4B-Instruct-2507 and SciBERT on both tasks, benchmarking against GPT-5.1 to analyze how task formulation and modeling choices affect performance. The implementation is publicly available at https://github.com/ZhengxuYan/NoveltyRank.

</details>


### [55] [Guided Discrete Diffusion for Constraint Satisfaction Problems](https://arxiv.org/abs/2512.14765)
*Justin Jung*

Main category: cs.LG

TL;DR: 该论文提出了一种离散扩散引导方法用于解决约束满足问题 (CSPs)，并展示了其在无监督条件下解决数独谜题的能力。


<details>
  <summary>Details</summary>
Motivation: 解决约束满足问题 (CSPs) 具有挑战性，需要新的方法，特别是那些能够进行无监督学习的方法。

Method: 论文提出了一种离散扩散引导的方法。

Result: 所提出的方法能够成功解决数独谜题。

Conclusion: 离散扩散引导是一种解决CSPs的可行方法，具有无监督学习的潜力。

Abstract: We propose discrete diffusion guidance for constraint satisfaction problems (CSPs) and demonstrate its ability to solve Sudoku puzzles without supervision.

</details>


### [56] [Evaluating Weather Forecasts from a Decision Maker's Perspective](https://arxiv.org/abs/2512.14779)
*Kornelius Raeth,Nicole Ludwig*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种新的决策校准框架，用于评估天气预报模型在决策层面的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的预报评估方法侧重于预报员的角度和统计评估，但实际上预报用于辅助决策。因此，有必要从决策者的角度量化预报的价值。

Method: 本文提出了一种决策校准框架来评估预报性能，并利用该框架比较了机器学习和经典数值天气预报模型在各种依赖天气的决策任务上的表现。

Result: 研究发现，模型在预报层面的表现并不能可靠地转化为下游决策中的表现。一些性能差异仅在决策层面才变得明显，并且模型排名在不同的决策任务中可能会发生变化。

Conclusion: 典型预报评估不足以选择特定决策任务的最佳预报模型。

Abstract: Standard weather forecast evaluations focus on the forecaster's perspective and on a statistical assessment comparing forecasts and observations. In practice, however, forecasts are used to make decisions, so it seems natural to take the decision-maker's perspective and quantify the value of a forecast by its ability to improve decision-making. Decision calibration provides a novel framework for evaluating forecast performance at the decision level rather than the forecast level. We evaluate decision calibration to compare Machine Learning and classical numerical weather prediction models on various weather-dependent decision tasks. We find that model performance at the forecast level does not reliably translate to performance in downstream decision-making: some performance differences only become apparent at the decision level, and model rankings can change among different decision tasks. Our results confirm that typical forecast evaluations are insufficient for selecting the optimal forecast model for a specific decision task.

</details>


### [57] [Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse](https://arxiv.org/abs/2512.14879)
*Jingwei Chen*

Main category: cs.LG

TL;DR: 研究了自指学习中模型崩溃问题，提出了熵-储层Bregman投影（ERBP）框架来统一解释这种现象，并提供了一种通过注入可控熵通量来稳定模型的通用设计规则。


<details>
  <summary>Details</summary>
Motivation: 自指学习（模型在自己生成的数据上进行训练）在可扩展性方面具有巨大潜力，但长期面临模型崩溃问题，导致模型性能下降。现有解决方案多为临时性修补，缺乏统一的理论解释。

Method: 本文将自指学习的闭环过程建模为分布空间中的随机Bregman投影序列。通过引入熵储层（高熵分布与每次投影混合），注入可控的熵通量来稳定系统，从而在理论上避免模型崩溃。

Result: ERBP理论推导出了模型崩溃的必要条件、保证非平凡熵下限的充分条件，以及仅依赖于样本量和Bregman生成器强凸性/Lipschitz常数的闭式速率。在大型语言模型自训练、强化学习中的Soft Actor-Critic和GAN优化上的实验验证了理论预测，并表明不同的稳定启发式方法对应于特定的熵储层选择和耦合系数。

Conclusion: ERBP框架将各种经验性的修复方法统一为一个量化的设计规则：即监控和预算模型的熵通量。这为理解和解决自指学习中的模型崩溃问题提供了一个通用的理论框架和实用指导。

Abstract: Self-referential learning -- training a model on data it generated itself -- promises boundless scalability but chronically suffers from model collapse: language models degenerate into repetitive text, GANs drop modes, and reinforcement-learning policies over-exploit. Although practitioners employ ad~hoc fixes such as real-data mixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation, a single principle that explains both the failure mode and the success of these fixes has remained elusive. We present Entropy-Reservoir Bregman Projection (ERBP), an information-geometric framework that unifies these phenomena. We model the closed loop as a stochastic Bregman projection sequence in distribution space. Without external coupling, finite-sample noise forces the system to project onto an ever-shrinking empirical support, causing exponential entropy decay and eventual collapse. Introducing an Entropy Reservoir -- a high-entropy distribution mixed into each projection -- injects a controllable entropy flux that provably stabilises the dynamics. Our theory yields (i) a necessary condition for collapse, (ii) a sufficient condition that guarantees a non-trivial entropy floor, and (iii) closed-form rates that depend only on sample size and the strong-convexity/Lipschitz constants of the Bregman generator. Experiments on large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation validate our predictions and show that disparate stabilisation heuristics correspond to specific reservoir choices and coupling coefficients. ERBP thus transforms a collection of folk remedies into a single, quantitative design rule: monitor and budget your entropy flux.

</details>


### [58] [Task Matrices: Linear Maps for Cross-Model Finetuning Transfer](https://arxiv.org/abs/2512.14880)
*Darrin O' Brien,Dhikshith Gajulapalli,Eric Xia*

Main category: cs.LG

TL;DR: 本文介绍了任务矩阵的概念，这是一种从基础嵌入状态到微调嵌入状态的线性变换，并证明了其在视觉和文本模型上的有效性，甚至接近微调的效果。


<details>
  <summary>Details</summary>
Motivation: 大型视觉和语言模型在in-context prompting偏置下会学习隐式线性编码，但这种线性表示在更通用的自适应机制中是否存在尚不明确。

Method: 本文提出了任务矩阵（task matrix）的概念，它是一个从基础嵌入状态到微调嵌入状态的线性变换。作者在视觉和文本模型以及十个不同的数据集上进行了实验，验证了任务矩阵的有效性。

Result: 增强了任务矩阵的基础模型取得了超越线性探针的结果，有时甚至接近微调的水平。这证实了预训练和微调架构之间存在跨层线性编码。

Conclusion: 任务矩阵能够有效地捕捉预训练模型到微调模型的线性转换，证明了跨层线性编码的存在性，并且提出了一种数据驱动的近似方法，该方法高效且具有泛化性。

Abstract: Results in interpretability suggest that large vision and language models learn implicit linear encodings when models are biased by in-context prompting. However, the existence of similar linear representations in more general adaptation regimes has not yet been demonstrated. In this work, we develop the concept of a task matrix, a linear transformation from a base to finetuned embedding state. We demonstrate that for vision and text models and ten different datasets, a base model augmented with a task matrix achieves results surpassing linear probes, sometimes approaching finetuned levels. Our results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures. Moreover, we show that a data-based approximation for such encodings is both efficient and generalizable to multiple domains. We make our implementation publicly available.

</details>


### [59] [OLR-WA: Online Weighted Average Linear Regression in Multivariate Data Streams](https://arxiv.org/abs/2512.14892)
*Mohammad Abu-Shaira,Alejandro Rodriguez,Greg Speegle,Victor Sheng,Ishfaq Ahmad*

Main category: cs.LG

TL;DR: 本文介绍了一种新颖的多变量在线线性回归模型“OLR-WA”，它可以增量更新模型，避免大量存储和昂贵的重新计算。


<details>
  <summary>Details</summary>
Motivation: 在线学习在处理新数据时具有存储和计算优势，但现有模型在处理数据随时间演变（漂移）和置信度较低的新数据时存在局限性。

Method: 本文引入了OLR-WA（加权平均在线回归）模型，该模型通过加权平均增量更新，并采用保守的更新方法，优先考虑具有较高置信度的旧数据点，以处理基于置信度的挑战性场景。

Result: OLR-WA实现了与批量回归相当的性能，并且与其他最先进的在线模型相比，性能相当或更优。它在快速收敛方面表现出色，即使使用少量数据点初始化，也能从第一次迭代到最后一次迭代持续获得高R2值。OLR-WA能够处理基于时间的漂移场景，并且是唯一能够有效管理基于置信度的挑战性场景的模型。

Conclusion: OLR-WA模型在在线线性回归任务中展现了其通用性和实用性，在处理数据漂移和置信度挑战方面表现出色，是一种有价值的解决方案。

Abstract: Online learning updates models incrementally with new data, avoiding large storage requirements and costly model recalculations. In this paper, we introduce "OLR-WA; OnLine Regression with Weighted Average", a novel and versatile multivariate online linear regression model. We also investigate scenarios involving drift, where the underlying patterns in the data evolve over time, conduct convergence analysis, and compare our approach with existing online regression models. The results of OLR-WA demonstrate its ability to achieve performance comparable to the batch regression, while also showcasing comparable or superior performance when compared with other state-of-the-art online models, thus establishing its effectiveness. Moreover, OLR-WA exhibits exceptional performance in terms of rapid convergence, surpassing other online models with consistently achieving high r2 values as a performance measure from the first iteration to the last iteration, even when initialized with minimal amount of data points, as little as 1% to 10% of the total data points. In addition to its ability to handle time-based (temporal drift) scenarios, remarkably, OLR-WA stands out as the only model capable of effectively managing confidence-based challenging scenarios. It achieves this by adopting a conservative approach in its updates, giving priority to older data points with higher confidence levels. In summary, OLR-WA's performance further solidifies its versatility and utility across different contexts, making it a valuable solution for online linear regression tasks.

</details>


### [60] [Imitation Learning for Multi-turn LM Agents via On-policy Expert Corrections](https://arxiv.org/abs/2512.14895)
*Niklas Lauffer,Xiang Deng,Srivatsa Kundurthy,Brad Kenstler,Jeff Da*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的数据生成方法，通过结合模仿学习和策略内专家校正来解决多轮语言模型智能体训练中的协变量偏移问题，并在软件工程任务中取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 传统的模仿学习在训练多轮语言模型智能体时会遇到协变量偏移问题，即当学生策略的行为偏离专家时，会遇到训练数据中不存在的状态，从而降低微调的有效性。

Method: 本文提出了一种基于DAgger算法的新型数据生成方法，用于解决多轮大型语言模型训练中的协变量偏移问题。该方法引入了策略内专家校正（OECs），通过学生模型开始推出并在轨迹中途切换到专家模型来生成部分策略内数据。

Result: 实验结果表明，在7b和32b设置中，OEC轨迹在SWE-bench验证上的性能分别比传统模仿学习提高了14%和13%。

Conclusion: 研究结果表明，为了有效地训练多轮语言模型智能体，需要将专家演示与策略内数据相结合。

Abstract: A popular paradigm for training LM agents relies on imitation learning, fine-tuning on expert trajectories. However, we show that the off-policy nature of imitation learning for multi-turn LM agents suffers from the fundamental limitation known as covariate shift: as the student policy's behavior diverges from the expert's, it encounters states not present in the training data, reducing the effectiveness of fine-tuning. Taking inspiration from the classic DAgger algorithm, we propose a novel data generation methodology for addressing covariate shift for multi-turn LLM training. We introduce on-policy expert corrections (OECs), partially on-policy data generated by starting rollouts with a student model and then switching to an expert model part way through the trajectory. We explore the effectiveness of our data generation technique in the domain of software engineering (SWE) tasks, a multi-turn setting where LLM agents must interact with a development environment to fix software bugs. Our experiments compare OEC data against various other on-policy and imitation learning approaches on SWE agent problems and train models using a common rejection sampling (i.e., using environment reward) combined with supervised fine-tuning technique. Experiments find that OEC trajectories show a relative 14% and 13% improvement over traditional imitation learning in the 7b and 32b setting, respectively, on SWE-bench verified. Our results demonstrate the need for combining expert demonstrations with on-policy data for effective multi-turn LM agent training.

</details>


### [61] [Low-rank MMSE filters, Kronecker-product representation, and regularization: a new perspective](https://arxiv.org/abs/2512.14932)
*Daniel Gomes de Pinho Zanco,Leszek Szczecinski,Jacob Benesty,Eduardo Vinicius Kuhn*

Main category: cs.LG

TL;DR: 本文提出了一种有效寻找低秩MMSE滤波器正则化参数的方法，并证明该参数与秩选择问题密切相关。


<details>
  <summary>Details</summary>
Motivation: 在低秩设置中，正确选择正则化参数至关重要，因为该参数与秩选择问题密切相关。

Method: 本文提出了一种基于克罗内克积表示的方法来有效寻找低秩MMSE滤波器的正则化参数。

Result: 仿真结果表明，该方法相比常用方法有显著改进。

Conclusion: 本文提出了一种有效寻找低秩MMSE滤波器正则化参数的方法，该方法通过仿真验证，显示出显著优于常用方法的性能。

Abstract: In this work, we propose a method to efficiently find the regularization parameter for low-rank MMSE filters based on a Kronecker-product representation. We show that the regularization parameter is surprisingly linked to the problem of rank selection and, thus, properly choosing it, is crucial for low-rank settings. The proposed method is validated through simulations, showing significant gains over commonly used methods.

</details>


### [62] [Softly Constrained Denoisers for Diffusion Models](https://arxiv.org/abs/2512.14980)
*Victor M. Yeom Song,Severi Rissanen,Arno Solin,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种新的方法来解决扩散模型在生成符合约束条件的样本时遇到的困难。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散模型在处理带约束条件的样本生成时，往往会因为在损失函数中引入正则化项或在采样过程中采用引导方法，导致生成模型偏离真实数据分布。当约束条件不准确时，这种问题尤为突出。

Method: 本文提出了一种将引导式调整整合到去噪器本身的方法，而不是修改损失函数或采样过程，从而使去噪器对符合约束条件的样本产生软归纳偏差。

Result: 实验结果表明，这些软约束去噪器能够利用约束知识提高样本的依从性，并且在约束条件与观测数据不匹配时，仍然保持足够的灵活性，可以从约束中 HLD。

Conclusion: 通过将引导式调整整合到去噪器中，本文提出的方法在不牺牲模型灵活性的前提下，解决了扩散模型在生成约束样本方面的挑战，尤其是在约束条件存在误差的情况下，与现有数据不匹配时，能够得到更好的结果。

Abstract: Diffusion models struggle to produce samples that respect constraints, a common requirement in scientific applications. Recent approaches have introduced regularization terms in the loss or guidance methods during sampling to enforce such constraints, but they bias the generative model away from the true data distribution. This is a problem, especially when the constraint is misspecified, a common issue when formulating constraints on scientific data. In this paper, instead of changing the loss or the sampling loop, we integrate a guidance-inspired adjustment into the denoiser itself, giving it a soft inductive bias towards constraint-compliant samples. We show that these softly constrained denoisers exploit constraint knowledge to improve compliance over standard denoisers, and maintain enough flexibility to deviate from it when there is misspecification with observed data.

</details>


### [63] [Prompt Repetition Improves Non-Reasoning LLMs](https://arxiv.org/abs/2512.14982)
*Yaniv Leviathan,Matan Kalman,Yossi Matias*

Main category: cs.LG

TL;DR: 重复输入提示可以提高流行模型（Gemini、GPT、Claude和Deepseek）的性能，而不会增加生成的 token 数量或延迟。


<details>
  <summary>Details</summary>
Motivation: 在不使用推理的情况下，提高流行模型的性能。

Method: 通过重复输入提示来改进模型性能。

Result: 重复输入提示在不增加生成 token 数量或延迟的情况下提高了模型性能。

Conclusion: 重复输入提示是一种简单且有效的提升模型性能的方法。

Abstract: When not using reasoning, repeating the input prompt improves performance for popular models (Gemini, GPT, Claude, and Deepseek) without increasing the number of generated tokens or latency.

</details>


### [64] [Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes](https://arxiv.org/abs/2512.14991)
*Hanqing Jin,Renyuan Xu,Yanzhao Yang*

Main category: cs.LG

TL;DR: 该文章探讨了在具有无界连续状态空间、有界连续动作和多项式增长奖励的受控扩散过程中，如何进行强化学习。为解决连续高维领域的挑战，作者提出一种基于模型的自适应算法，能够有效地在无界领域中学习。


<details>
  <summary>Details</summary>
Motivation: 在金融、经济学和运筹学中，受控扩散过程（具有无界连续状态空间、有界连续动作和多项式增长奖励）的强化学习问题自然出现，但传统的强化学习方法难以处理连续和高维领域。

Method: 作者引入了一种基于模型的自适应算法，该算法通过自适应地划分联合状态-动作空间来应对连续和高维领域的挑战。在每个分区内，算法维护对漂移、波动性和奖励的估计器，并在估计偏差超过统计置信度时细化离散化。

Result: 这项自适应方案平衡了探索和近似，实现了在无界域中的高效学习。文章建立了遗憾界，这些界取决于问题范围、状态维度、奖励增长顺序以及为无界扩散过程量身定制的新“缩放维度”概念。

Conclusion: 该研究将理论保证扩展到更广泛的扩散类型问题，并且通过数值实验验证了所提方法的有效性，包括在多资产均值-方差投资组合选择等高维问题中的应用。所提出的算法在处理具有无界连续状态空间和多项式增长奖励的强化学习问题方面表现出色，并为无界域中的高效学习提供了新的理论框架和实用方法。

Abstract: We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.

</details>


### [65] [DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding](https://arxiv.org/abs/2512.15000)
*Ruiyi Zhang,Peijia Qin,Qi Cao,Pengtao Xie*

Main category: cs.LG

TL;DR: 本文提出DreamPRM-Code，一个编码聚焦的PRM，通过将函数视为推理步骤来解决代码中缺乏有意义的步骤分解和蒙特卡洛生成的局部标签噪声问题。


<details>
  <summary>Details</summary>
Motivation: PRM在代码领域的有效性受限于代码中缺乏有意义的步骤分解以及蒙特卡洛生成的局部标签噪声。

Method: DreamPRM-Code将函数视为推理步骤，并使用Chain-of-Function提示策略来诱导模块化代码生成。为解决标签噪声，DreamPRM-Code引入了一种基于元学习的校正机制，利用干净的最终解决方案单元测试标签进行双层优化，以优化中间标签。

Result: DreamPRM-Code在LiveCodeBench上实现了80.9%的pass@1，超越了OpenAI o4-mini，达到了最先进的水平。

Conclusion: DreamPRM-Code通过其独特的方法有效解决了PRM在代码应用中的关键挑战，显著提升了LLM在代码生成任务上的性能。

Abstract: Process Reward Models (PRMs) have become essential for improving Large Language Models (LLMs) via test-time scaling, yet their effectiveness in coding remains limited due to the lack of meaningful step decompositions in code and the noise of Monte-Carlo-generated partial labels. We propose DreamPRM-Code, a coding-focused PRM that treats functions as reasoning steps using a Chain-of-Function prompting strategy to induce modular code generation, enabling PRM training and application analogous to mathematical reasoning tasks. To address label noise, DreamPRM-Code introduces a meta-learning-based correction mechanism that leverages clean final-solution unit-test labels and performs bi-level optimization to refine intermediate labels. Applying on test-time scaling, DreamPRM-Code achieved state-of-the-art performance on LiveCodeBench with 80.9 pass@1 rate, surpassing OpenAI o4-mini.

</details>


### [66] [Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets](https://arxiv.org/abs/2512.15008)
*Sandeep Neela*

Main category: cs.LG

TL;DR: 本文介绍了一种名为“股票模式助手”（SPA）的确定性框架，用于从市场噪音中提取单调价格走势，并通过对称相关窗口关联相关公共事件，从而生成事实性、历史性和受限的解释。


<details>
  <summary>Details</summary>
Motivation: 理解价格随时间如何演变，往往需要剥离市场噪音，以识别清晰的、结构化的行为。现有的技术指标和预测模型通常无法提供透明和可审计的解释，这在需要透明度或可审计性的场景中构成了重大挑战。

Method: SPA框架仅依赖于每日OHLCV数据和标准化事件流。它通过确定性分割提取单调价格走势，并通过对称相关窗口将相关公共事件与这些价格走势关联起来，从而生成事实性、历史性且受限的解释。

Result: 在对AAPL、NVDA、SCHW和PGR这四种股票进行的评估中，SPA始终能生成稳定的结构化分解和上下文叙述。实验进一步表明，确定性分割、事件对齐和受限解释都有助于提高可解释性。

Conclusion: SPA框架提供了一种透明、可复现的历史价格结构视图，可以作为分析师工作流程、风险审查和更广泛的可解释AI流程的补充。它并非预测系统，也无意产生交易信号。

Abstract: Understanding how prices evolve over time often requires peeling back the layers of market noise to identify clear, structural behavior. Many of the tools commonly used for this purpose technical indicators, chart heuristics, or even sophisticated predictive models leave important questions unanswered. Technical indicators depend on platform-specific rules, and predictive systems typically offer little in terms of explanation. In settings that demand transparency or auditability, this poses a significant challenge. We introduce the Stock Pattern Assistant (SPA), a deterministic framework designed to extract monotonic price runs, attach relevant public events through a symmetric correlation window, and generate explanations that are factual, historical, and guardrailed. SPA relies only on daily OHLCV data and a normalized event stream, making the pipeline straight-forward to audit and easy to reproduce. To illustrate SPA's behavior in practice, we evaluate it across four equities-AAPL, NVDA, SCHW, and PGR-chosen to span a range of volatility regimes and sector characteristics. Although the evaluation period is modest, the results demonstrate how SPA consistently produces stable structural decompositions and contextual narratives. Ablation experiments further show how deterministic segmentation, event alignment, and constrained explanation each contribute to interpretability. SPA is not a forecasting system, nor is it intended to produce trading signals. Its value lies in offering a transparent, reproducible view of historical price structure that can complement analyst workflows, risk reviews, and broader explainable-AI pipelines.

</details>


### [67] [The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems](https://arxiv.org/abs/2512.15068)
*Debu Sinha*

Main category: cs.LG

TL;DR: 本文分析了RAG系统中幻觉检测方法的局限性，并提出了一种基于保形预测的新方法，但发现在真实幻觉基准测试中，基于嵌入的方法的假阳性率不可接受，而GPT-4作为LLM判断器表现更好。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG系统以检索到的证据为基础，但仍然容易产生幻觉。现有的检测方法依赖于语义相似性和自然语言推理（NLI），但其基本局限性尚未得到严格表征。

Method: 本文将保形预测应用于幻觉检测，提供了有限样本覆盖率保证，从而能够精确量化检测能力。

Result: 在合成幻觉（Natural Questions）上，本文使用约600个示例的校准集实现了94%的覆盖率和0%的假阳性率。然而，在三个包含多个LLM（GPT-4、ChatGPT、GPT-3、Llama-2、Mistral）的真实幻觉基准测试中，基于嵌入的方法（包括最先进的OpenAI text-embedding-3-large和交叉编码器模型）表现出不可接受的假阳性率：在HaluEval上为100%，RAGTruth上为88%，WikiBio上为50%。相比之下，GPT-4作为LLM判断器在相同数据上仅实现了7%的FPR（95% CI：[3.4%, 13.7%]）。

Conclusion: 语义上看似合理的幻觉保留了与源文档的相似性，同时引入了嵌入无法察觉的事实错误，本文称之为“语义错觉”。这种局限性在不同的嵌入架构、LLM生成器和任务类型中持续存在，这表明基于嵌入的检测不足以用于生产RAG部署。

Abstract: Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. Current detection methods rely on semantic similarity and natural language inference (NLI), but their fundamental limitations have not been rigorously characterized. We apply conformal prediction to hallucination detection, providing finite-sample coverage guarantees that enable precise quantification of detection capabilities. Using calibration sets of approximately 600 examples, we achieve 94% coverage with 0% false positive rate on synthetic hallucinations (Natural Questions). However, on three real hallucination benchmarks spanning multiple LLMs (GPT-4, ChatGPT, GPT-3, Llama-2, Mistral), embedding-based methods - including state-of-the-art OpenAI text-embedding-3-large and cross-encoder models - exhibit unacceptable false positive rates: 100% on HaluEval, 88% on RAGTruth, and 50% on WikiBio. Crucially, GPT-4 as an LLM judge achieves only 7% FPR (95% CI: [3.4%, 13.7%]) on the same data, proving the task is solvable through reasoning. We term this the "semantic illusion": semantically plausible hallucinations preserve similarity to source documents while introducing factual errors invisible to embeddings. This limitation persists across embedding architectures, LLM generators, and task types, suggesting embedding-based detection is insufficient for production RAG deployment.

</details>


### [68] [The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks](https://arxiv.org/abs/2512.15082)
*Wanfu Gao,Zebin He,Jun Gao*

Main category: cs.LG

TL;DR: FEAML：一个基于大语言模型的自动化多标签学习特征工程方法


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的特征工程方法尚未应用于多标签学习任务，它们缺乏对复杂标签依赖进行建模的能力，并且没有专门适应多标签任务的特点。

Method: 我们提出了多标签学习的特征工程自动化（FEAML），它利用大型语言模型的代码生成能力来指导大模型理解数据特征与任务目标之间的关系。然后，它生成高质量的特征并使用Pearson相关系数来检测冗余。

Result: FEAML的性能优于其他特征工程方法。

Conclusion: FEAML通过将LLMs与反馈机制相结合，实现了一种高效、可解释和自我改进的特征工程范式，能够生成高质量的特征。

Abstract: Existing feature engineering methods based on large language models (LLMs) have not yet been applied to multi-label learning tasks. They lack the ability to model complex label dependencies and are not specifically adapted to the characteristics of multi-label tasks. To address the above issues, we propose Feature Engineering Automation for Multi-Label Learning (FEAML), an automated feature engineering method for multi-label classification which leverages the code generation capabilities of LLMs. By utilizing metadata and label co-occurrence matrices, LLMs are guided to understand the relationships between data features and task objectives, based on which high-quality features are generated. The newly generated features are evaluated in terms of model accuracy to assess their effectiveness, while Pearson correlation coefficients are used to detect redundancy. FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations. By integrating LLMs with a feedback mechanism, FEAML realizes an efficient, interpretable and self-improving feature engineering paradigm. Empirical results on various multi-label datasets demonstrate that our FEAML outperforms other feature engineering methods.

</details>


### [69] [PIP$^2$ Net: Physics-informed Partition Penalty Deep Operator Network](https://arxiv.org/abs/2512.15086)
*Hongjin Mi,Huiqiang Lun,Changhong Mou,Yeyu Zhang*

Main category: cs.LG

TL;DR: 这篇文章介绍了一种名为PIP² Net的新型算子学习框架，它通过引入简化的Partition Penalty改进了DeepONet，在预测精度和鲁棒性方面优于现有方法，特别是在处理参数化偏微分方程时。


<details>
  <summary>Details</summary>
Motivation: 现有的算子学习架构在加速参数化偏微分方程求解方面表现出色，但也存在需要大量训练数据、缺乏明确物理结构以及trunk-network特征不稳定等问题，这些问题会影响算子近似的准确性。

Method: PIP² Net通过引入简化的、更具原则性的Partition Penalty来改进DeepONet框架，旨在改善协调的trunk输出，提高表达能力，同时保持DeepONet的灵活性。

Result: PIP² Net在粘性Burgers方程、Allen-Cahn方程和扩散-反应系统这三个非线性偏微分方程上的评估结果表明，它在预测精度和鲁棒性方面始终优于DeepONet、PI-DeepONet和POU-DeepONet。

Conclusion: PIP² Net通过引入一种简化的、更具原则性的Partition Penalty，有效地解决了现有算子学习方法中的一些局限性，特别是在处理参数化偏微分方程时，表现出更高的预测精度和鲁棒性。

Abstract: Operator learning has become a powerful tool for accelerating the solution of parameterized partial differential equations (PDEs), enabling rapid prediction of full spatiotemporal fields for new initial conditions or forcing functions. Existing architectures such as DeepONet and the Fourier Neural Operator (FNO) show strong empirical performance but often require large training datasets, lack explicit physical structure, and may suffer from instability in their trunk-network features, where mode imbalance or collapse can hinder accurate operator approximation. Motivated by the stability and locality of classical partition-of-unity (PoU) methods, we investigate PoU-based regularization techniques for operator learning and develop a revised formulation of the existing POU--PI--DeepONet framework. The resulting \emph{P}hysics-\emph{i}nformed \emph{P}artition \emph{P}enalty Deep Operator Network (PIP$^{2}$ Net) introduces a simplified and more principled partition penalty that improved the coordinated trunk outputs that leads to more expressiveness without sacrificing the flexibility of DeepONet. We evaluate PIP$^{2}$ Net on three nonlinear PDEs: the viscous Burgers equation, the Allen--Cahn equation, and a diffusion--reaction system. The results show that it consistently outperforms DeepONet, PI-DeepONet, and POU-DeepONet in prediction accuracy and robustness.

</details>


### [70] [FADTI: Fourier and Attention Driven Diffusion for Multivariate Time Series Imputation](https://arxiv.org/abs/2512.15116)
*Runze Li,Hanchen Wang,Wenjie Zhang,Binghao Li,Yu Zhang,Xuemin Lin,Ying Zhang*

Main category: cs.LG

TL;DR: FADTI是一种基于扩散模型的多元时间序列插补框架，它通过可学习的傅立叶偏置投影（FBP）模块注入频率信息，并结合自注意力机制和门控卷积进行时域建模，能够在高缺失率下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer和扩散模型的方法在多元时间序列插补中缺乏明确的归纳偏置和频率感知能力，这限制了它们在结构化缺失模式和分布变化下的泛化能力。

Method: FADTI框架通过可学习的傅立叶偏置投影（FBP）模块注入频率信息，并将其与通过自注意力机制和门控卷积实现的时间建模相结合。FBP支持多种频谱基，能够自适应地编码平稳和非平稳模式，从而在生成式插补过程中注入频域归纳偏置。

Result: FADTI在多个基准测试（包括一项新引入的生物时间序列数据集）上始终优于现有最先进的方法，尤其是在高缺失率的情况下表现更为突出。

Conclusion: FADTI通过引入频率感知能力和频域归纳偏置，有效解决了多元时间序列插补中的挑战，并在各种缺失模式下展现出卓越的性能。

Abstract: Multivariate time series imputation is fundamental in applications such as healthcare, traffic forecasting, and biological modeling, where sensor failures and irregular sampling lead to pervasive missing values. However, existing Transformer- and diffusion-based models lack explicit inductive biases and frequency awareness, limiting their generalization under structured missing patterns and distribution shifts. We propose FADTI, a diffusion-based framework that injects frequency-informed feature modulation via a learnable Fourier Bias Projection (FBP) module and combines it with temporal modeling through self-attention and gated convolution. FBP supports multiple spectral bases, enabling adaptive encoding of both stationary and non-stationary patterns. This design injects frequency-domain inductive bias into the generative imputation process. Experiments on multiple benchmarks, including a newly introduced biological time series dataset, show that FADTI consistently outperforms state-of-the-art methods, particularly under high missing rates. Code is available at https://anonymous.4open.science/r/TimeSeriesImputation-52BF

</details>


### [71] [From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?](https://arxiv.org/abs/2512.15134)
*Aaron Mueller,Andrew Lee,Shruti Joshi,Ekdeep Singh Lubana,Dhanya Sridhar,Patrik Reizinger*

Main category: cs.LG

TL;DR: 该研究旨在评估稀疏自动编码器（SAE）在多概念场景下的解缠结表征能力。研究发现，SAE的特征与概念之间存在一对多的关系，且在操纵时会影响多个概念，表明其缺乏选择性和独立性。


<details>
  <summary>Details</summary>
Motivation: 目前对概念表征质量的评估常常是孤立的，且基于隐性独立性假设，这可能导致稀疏自动编码器（SAE）等常见特征化方法未能恢复解缠结的概念表征。

Method: 本研究提出了一个多概念评估设置，通过控制文本概念（如情感、领域和时态）之间的相关性，分析稀疏自动编码器（SAE）和稀疏探针在不同相关性下的性能。该方法包括评估特征器学习每个概念解缠结表征的程度，以及通过转向实验衡量每个概念是否可独立操作。

Result: 研究发现，概念与特征之间存在一对多的关系：特征最多对应一个概念，但概念分布在多个特征中。即使在均匀分布的概念上进行训练，SAE特征在操纵时通常会影响多个概念，表明它们既不具有选择性也不独立；尽管如此，特征会影响不相交的子空间。

Conclusion: 该研究结果强调了在可解释性研究中进行组合评估的重要性，并指出测量解缠结的相关度量和影响不相交子空间不足以建立概念操纵时的独立性和选择性。

Abstract: A central goal of interpretability is to recover representations of causally relevant concepts from the activations of neural networks. The quality of these concept representations is typically evaluated in isolation, and under implicit independence assumptions that may not hold in practice. Thus, it is unclear whether common featurization methods - including sparse autoencoders (SAEs) and sparse probes - recover disentangled representations of these concepts. This study proposes a multi-concept evaluation setting where we control the correlations between textual concepts, such as sentiment, domain, and tense, and analyze performance under increasing correlations between them. We first evaluate the extent to which featurizers can learn disentangled representations of each concept under increasing correlational strengths. We observe a one-to-many relationship from concepts to features: features correspond to no more than one concept, but concepts are distributed across many features. Then, we perform steering experiments, measuring whether each concept is independently manipulable. Even when trained on uniform distributions of concepts, SAE features generally affect many concepts when steered, indicating that they are neither selective nor independent; nonetheless, features affect disjoint subspaces. These results suggest that correlational metrics for measuring disentanglement are generally not sufficient for establishing independence when steering, and that affecting disjoint subspaces is not sufficient for concept selectivity. These results underscore the importance of compositional evaluations in interpretability research.

</details>


### [72] [Automatic Reward Shaping from Multi-Objective Human Heuristics](https://arxiv.org/abs/2512.15120)
*Yuqing Xie,Jiayu Chen,Wenhao Tang,Ya Zhang,Chao Yu,Yu Wang*

Main category: cs.LG

TL;DR: 本文提出了MORSE框架，自动组合启发式奖励函数以解决强化学习中的多目标奖励设计挑战，并通过双层优化和引入随机性来提高性能和探索。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中，设计有效的奖励函数是一个核心挑战，尤其是在多目标环境中。

Method: MORSE框架通过双层优化方法自动组合多个启发式奖励：内层训练策略以最大化当前奖励，外层更新奖励函数以优化任务表现。为鼓励探索和避免局部最优，MORSE在奖励塑造过程中引入随机性，由任务表现和预测误差引导噪声。

Result: 在MuJoCo和Isaac Sim环境中的实验结果表明，MORSE有效地平衡了各种机器人任务中的多个目标，并取得了与手动调整奖励函数相当的任务性能。

Conclusion: MORSE框架能够有效地解决多目标环境下的奖励函数设计问题，通过自动化组合和随机探索，实现了与手动调优奖励函数相媲美的性能。

Abstract: Designing effective reward functions remains a central challenge in reinforcement learning, especially in multi-objective environments. In this work, we propose Multi-Objective Reward Shaping with Exploration (MORSE), a general framework that automatically combines multiple human-designed heuristic rewards into a unified reward function. MORSE formulates the shaping process as a bi-level optimization problem: the inner loop trains a policy to maximize the current shaped reward, while the outer loop updates the reward function to optimize task performance. To encourage exploration in the reward space and avoid suboptimal local minima, MORSE introduces stochasticity into the shaping process, injecting noise guided by task performance and the prediction error of a fixed, randomly initialized neural network. Experimental results in MuJoCo and Isaac Sim environments show that MORSE effectively balances multiple objectives across various robotic tasks, achieving task performance comparable to those obtained with manually tuned reward functions.

</details>


### [73] [Tracking Temporal Dynamics of Vector Sets with Gaussian Process](https://arxiv.org/abs/2512.15538)
*Taichi Aida,Mamoru Komachi,Toshinobu Ogiso,Hiroya Takamura,Daichi Mochihashi*

Main category: cs.LG

TL;DR: 该论文提出了一种处理随时间演变的复杂向量集的方法，通过使用无限维高斯过程和随机傅里叶特征，为这些向量集提供紧凑且可比较的表示，从而能够跟踪和可视化其时间动态。


<details>
  <summary>Details</summary>
Motivation: 理解向量集的时间演变是一个跨领域的基础性挑战，因为这些向量集具有随时间演变的复杂结构，传统方法难以有效分析。

Method: 本文提出了一种新颖的方法，利用无限维高斯过程对每个向量集下的分布进行建模。通过使用随机傅里叶特征近似高斯过程中的潜在函数，获得了随时间变化的紧凑且可比较的向量表示。

Result: 该方法能够在一个低维空间中跟踪和可视化向量集的时间转换。在社会学数据（犯罪分布）和语言学数据（词嵌入）上的应用表明，它能有效捕捉时间动态。

Conclusion: 该方法提供了解释性强、鲁棒性好的表示，为分析跨领域中按时间索引的向量集的结构变化提供了一个强大的框架。

Abstract: Understanding the temporal evolution of sets of vectors is a fundamental challenge across various domains, including ecology, crime analysis, and linguistics. For instance, ecosystem structures evolve due to interactions among plants, herbivores, and carnivores; the spatial distribution of crimes shifts in response to societal changes; and word embedding vectors reflect cultural and semantic trends over time. However, analyzing such time-varying sets of vectors is challenging due to their complicated structures, which also evolve over time. In this work, we propose a novel method for modeling the distribution underlying each set of vectors using infinite-dimensional Gaussian processes. By approximating the latent function in the Gaussian process with Random Fourier Features, we obtain compact and comparable vector representations over time. This enables us to track and visualize temporal transitions of vector sets in a low-dimensional space. We apply our method to both sociological data (crime distributions) and linguistic data (word embeddings), demonstrating its effectiveness in capturing temporal dynamics. Our results show that the proposed approach provides interpretable and robust representations, offering a powerful framework for analyzing structural changes in temporally indexed vector sets across diverse domains.

</details>


### [74] [Generalization and Feature Attribution in Machine Learning Models for Crop Yield and Anomaly Prediction in Germany](https://arxiv.org/abs/2512.15140)
*Roland Baatz*

Main category: cs.LG

TL;DR: 该研究评估了用于预测德国作物产量和产量异常的机器学习模型的泛化性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 探索农业和环境系统中机器学习模型泛化性和可解释性面临的挑战，并强调了对模型解释进行验证感知解释的必要性。

Method: 比较了集成树模型（XGBoost、Random Forest）和深度学习方法（LSTM、TCN）在空间分割和时间独立验证下的性能。

Result: 所有模型在常规测试集上的表现良好，但在时间独立验证年份，性能显著下降，泛化能力存在局限性。具有良好测试集准确性但泛化性能差的模型仍可能产生看似可信的SHAP特征重要性值，这揭示了后验可解释性方法的脆弱性。

Conclusion: 强调了在农业和环境系统中对机器学习预测进行验证感知解释的需求，并呼吁对模型解释性进行更严格的审查，以及在数据驱动型农业中采用领域感知验证和混合建模策略。

Abstract: This study examines the generalization performance and interpretability of machine learning (ML) models used for predicting crop yield and yield anomalies in Germany's NUTS-3 regions. Using a high-quality, long-term dataset, the study systematically compares the evaluation and temporal validation behavior of ensemble tree-based models (XGBoost, Random Forest) and deep learning approaches (LSTM, TCN).
  While all models perform well on spatially split, conventional test sets, their performance degrades substantially on temporally independent validation years, revealing persistent limitations in generalization. Notably, models with strong test-set accuracy, but weak temporal validation performance can still produce seemingly credible SHAP feature importance values. This exposes a critical vulnerability in post hoc explainability methods: interpretability may appear reliable even when the underlying model fails to generalize.
  These findings underscore the need for validation-aware interpretation of ML predictions in agricultural and environmental systems. Feature importance should not be accepted at face value unless models are explicitly shown to generalize to unseen temporal and spatial conditions. The study advocates for domain-aware validation, hybrid modeling strategies, and more rigorous scrutiny of explainability methods in data-driven agriculture. Ultimately, this work addresses a growing challenge in environmental data science: how can we evaluate generalization robustly enough to trust model explanations?

</details>


### [75] [An Efficient Gradient-Based Inference Attack for Federated Learning](https://arxiv.org/abs/2512.15143)
*Pablo Montaña-Fernández,Ines Ortega-Fernandez*

Main category: cs.LG

TL;DR: 本文提出了一种针对联邦学习的基于梯度的成员推断攻击，该攻击利用梯度随时间的变化来推断敏感信息。


<details>
  <summary>Details</summary>
Motivation: 尽管联邦学习减少了数据暴露，但模型更新的交换仍可能泄露敏感信息，因此需要一种新的成员推断攻击方法来揭示这种漏洞。

Method: 该方法利用影子技术学习训练记录的逐轮梯度模式，无需访问私有数据集，并考虑了半诚实和恶意对手。它还通过对比替代属性假设下的梯度响应，自然地扩展到离散属性推断。

Result: 攻击在CIFAR-100和Purchase100数据集上表现出强大的成员推断性能，计算和内存开销与现有攻击相当。在Breast Cancer Wisconsin数据集上，属性推断也取得了成功。

Conclusion: 多轮联邦学习会增加推断攻击的漏洞，聚合器比数据所有者构成更大的威胁，且攻击性能受训练数据集性质的影响，高维数据比简单表格数据导致更强的泄露。

Abstract: Federated Learning is a machine learning setting that reduces direct data exposure, improving the privacy guarantees of machine learning models. Yet, the exchange of model updates between the participants and the aggregator can still leak sensitive information. In this work, we present a new gradient-based membership inference attack for federated learning scenarios that exploits the temporal evolution of last-layer gradients across multiple federated rounds. Our method uses the shadow technique to learn round-wise gradient patterns of the training records, requiring no access to the private dataset, and is designed to consider both semi-honest and malicious adversaries (aggregators or data owners). Beyond membership inference, we also provide a natural extension of the proposed attack to discrete attribute inference by contrasting gradient responses under alternative attribute hypotheses. The proposed attacks are model-agnostic, and therefore applicable to any gradient-based model and can be applied to both classification and regression settings. We evaluate the attack on CIFAR-100 and Purchase100 datasets for membership inference and on Breast Cancer Wisconsin for attribute inference. Our findings reveal strong attack performance and comparable computational and memory overhead in membership inference when compared to another attack from the literature. The obtained results emphasize that multi-round federated learning can increase the vulnerability to inference attacks, that aggregators pose a more substantial threat than data owners, and that attack performance is strongly influenced by the nature of the training dataset, with richer, high-dimensional data leading to stronger leakage than simpler tabular data.

</details>


### [76] [Understanding NTK Variance in Implicit Neural Representations](https://arxiv.org/abs/2512.15169)
*Chengguang Ou,Yixin Zhuang*

Main category: cs.LG

TL;DR: 本文分析了隐式神经表示（INRs）中谱偏差问题，并发现各种INR机制（如位置编码、球形归一化、Hadamard调制）通过影响NTK（神经正切核）的条件性来缓解谱偏差，从而加快收敛并提高重建质量。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）通常收敛缓慢，并且由于谱偏差难以恢复高频细节。现有工作虽然将这归因于神经正切核（NTK），但具体的架构选择如何影响NTK的条件性尚不明确。

Method: 我们通过分析影响NTK特征值方差的一小组成对相似性因子和缩放项来理解多种INR机制。针对标准坐标MLP，我们推导了常见INR组件的封闭式方差分解。

Result: 研究表明，位置编码重塑了输入相似性，球形归一化通过逐层缩放减少了方差，Hadamard调制引入了额外的相似性因子，从而实现乘性方差减少。实验证实了这些预测的方差减少，并展示了更快、更稳定的收敛和改进的重建质量。

Conclusion: 通过统一的视角，本文解释了不同INR架构如何通过改善NTK条件性来缓解谱偏差，从而在多个任务中实现更快的收敛和更好的重建质量。

Abstract: Implicit Neural Representations (INRs) often converge slowly and struggle to recover high-frequency details due to spectral bias. While prior work links this behavior to the Neural Tangent Kernel (NTK), how specific architectural choices affect NTK conditioning remains unclear. We show that many INR mechanisms can be understood through their impact on a small set of pairwise similarity factors and scaling terms that jointly determine NTK eigenvalue variance. For standard coordinate MLPs, limited input-feature interactions induce large eigenvalue dispersion and poor conditioning. We derive closed-form variance decompositions for common INR components and show that positional encoding reshapes input similarity, spherical normalization reduces variance via layerwise scaling, and Hadamard modulation introduces additional similarity factors strictly below one, yielding multiplicative variance reduction. This unified view explains how diverse INR architectures mitigate spectral bias by improving NTK conditioning. Experiments across multiple tasks confirm the predicted variance reductions and demonstrate faster, more stable convergence with improved reconstruction quality.

</details>


### [77] [DEER: Draft with Diffusion, Verify with Autoregressive Models](https://arxiv.org/abs/2512.15176)
*Zicong Cheng,Guo-Wei Yang,Jia Li,Zhijie Deng,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.LG

TL;DR: 该文章介绍了一种名为DEER的加速LLM推理框架，通过使用扩散大语言模型（dLLM）作为草稿模型，克服了传统自回归（AR）草稿模型在推测解码中的效率限制，实现了显著的加速。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）驱动的智能体和推理系统面临效率挑战，主要受限于自回归（AR）解码固有的延迟。现有的推测解码方法通过“草稿-验证”机制缓解了这一问题，但其AR草稿模型存在两个根本问题：1）逐步不确定性累积导致目标模型与草稿模型之间信任度降低；2）AR草稿模型的本质顺序解码限制了加速效果。

Method: 本文提出DEER框架，该框架使用扩散大语言模型（dLLM）作为草稿模型，并与AR模型进行验证。DEER采用两阶段训练流程，旨在使基于dLLM的草稿模型与目标AR模型对齐，并进一步采用单步解码生成长草稿片段。

Result: 实验结果表明，DEER的草稿接受长度可达32个token，远超EAGLE-3的10个token。在HumanEval基准测试中，使用Qwen3-30B-A3B模型时，DEER实现了5.54倍的加速，而EAGLE-3仅达到2.41倍的加速。

Conclusion: DEER通过使用dLLM作为草稿模型，并结合两阶段训练和单步解码策略，显著提升了LLM推理的效率，克服了传统AR草稿模型面临的挑战，实现了更高的加速比和更长的草稿接受长度。

Abstract: Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a.k.a., drafters), which introduce two fundamental issues: (1) step-wise uncertainty accumulation leads to a progressive collapse of trust between the target model and the drafter, and (2) inherently sequential decoding of AR drafters. Together, these factors cause limited speedups. In this paper, we show that a diffusion large language model (dLLM) drafters can naturally overcome these issues through its fundamentally different probabilistic modeling and efficient parallel decoding strategy. Building on this insight, we introduce DEER, an efficient speculative decoding framework that drafts with diffusion and verifies with AR models. To enable high-quality drafting, DEER employs a two-stage training pipeline to align the dLLM-based drafters with the target AR model, and further adopts single-step decoding to generate long draft segments. Experiments show DEER reaches draft acceptance lengths of up to 32 tokens, far surpassing the 10 tokens achieved by EAGLE-3. Moreover, on HumanEval with Qwen3-30B-A3B, DEER attains a 5.54x speedup, while EAGLE-3 achieves only 2.41x. Code, model, demo, etc, will be available at https://czc726.github.io/DEER/

</details>


### [78] [Chorus: Harmonizing Context and Sensing Signals for Data-Free Model Customization in IoT](https://arxiv.org/abs/2512.15206)
*Liyu Zhang,Yejia Liu,Kwun Ho Liu,Runxi Huang,Xiaomin Ouyang*

Main category: cs.LG

TL;DR: Chorus：一种情境感知、免数据、模型定制方法，旨在解决物联网应用中传感器数据在不同情境下的适应性问题。


<details>
  <summary>Details</summary>
Motivation: 传统域适应或泛化方法未能有效处理部署后未见情境变化，而物联网传感器数据在多样动态情境下收集，情境因素显著影响数据模式和下游性能。

Method: Chorus通过无监督跨模态重建学习情境表示，并规范情境嵌入空间以获取鲁棒、可泛化的情境表示。然后，Chorus在有限标记样本上训练轻量级门控头，以动态平衡传感器和情境贡献，并在情境模糊时偏向情境，反之亦然。为减少推理延迟，Chorus采用情境缓存机制，在检测到情境变化时更新。

Result: 在IMU、语音和WiFi感知任务的实验中，Chorus在未见情境下的表现优于现有基线，性能提升高达11.3%，同时在智能手机和边缘设备上保持了相当的延迟。

Conclusion: Chorus作为一种情境感知、免数据、模型定制方法，有效解决了物联网应用中传感器数据在多样动态情境下的适应性问题。它通过学习有效情境表示、自适应集成以及情境缓存机制，在未见情境下实现了显著的性能提升，并保持了低延迟。

Abstract: In real-world IoT applications, sensor data is usually collected under diverse and dynamic contextual conditions where factors such as sensor placements or ambient environments can significantly affect data patterns and downstream performance. Traditional domain adaptation or generalization methods often ignore such context information or use simplistic integration strategies, making them ineffective in handling unseen context shifts after deployment. In this paper, we propose Chorus, a context-aware, data-free model customization approach that adapts models to unseen deployment conditions without requiring target-domain data. The key idea is to learn effective context representations that capture their influence on sensor data patterns and to adaptively integrate them based on the degree of context shift. Specifically, Chorus first performs unsupervised cross-modal reconstruction between unlabeled sensor data and language-based context embeddings, while regularizing the context embedding space to learn robust, generalizable context representations. Then, it trains a lightweight gated head on limited labeled samples to dynamically balance sensor and context contributions-favoring context when sensor evidence is ambiguous and vice versa. To further reduce inference latency, Chorus employs a context-caching mechanism that reuses cached context representations and updates only upon detected context shifts. Experiments on IMU, speech, and WiFi sensing tasks under diverse context shifts show that Chorus outperforms state-of-the-art baselines by up to 11.3% in unseen contexts, while maintaining comparable latency on smartphone and edge devices.

</details>


### [79] [O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization](https://arxiv.org/abs/2512.15229)
*Elio Gruttadauria,Mathieu Fontaine,Jonathan Le Roux,Slim Essid*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为O-EENC-SD的端到端在线说话人日志系统，该系统基于EEND-EDA，并采用新颖的基于RNN的拼接机制进行在线预测。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决现有说话人日志系统中的超参数依赖性和计算成本高昂的问题，提出一种无需超参数且计算效率更高的在线端到端说话人日志系统。

Method: 该系统名为O-EENC-SD，基于EEND-EDA，并引入了一种新颖的基于RNN的拼接机制用于在线预测。同时，还开发了一种新的质心优化解码器。

Result: 在CallHome数据集上，O-EENC-SD系统在双人对话电话语音领域与最先进的技术相比具有竞争力。即使在无重叠的独立块上工作，也能在DER和复杂性之间取得很好的平衡，使得系统非常高效。

Conclusion: O-EENC-SD系统提出了一种有效且高效的在线说话人日志解决方案，在避免超参数依赖和降低计算成本方面取得了进展，并在性能上达到了先进水平。

Abstract: We introduce O-EENC-SD: an end-to-end online speaker diarization system based on EEND-EDA, featuring a novel RNN-based stitching mechanism for online prediction. In particular, we develop a novel centroid refinement decoder whose usefulness is assessed through a rigorous ablation study. Our system provides key advantages over existing methods: a hyperparameter-free solution compared to unsupervised clustering approaches, and a more efficient alternative to current online end-to-end methods, which are computationally costly. We demonstrate that O-EENC-SD is competitive with the state of the art in the two-speaker conversational telephone speech domain, as tested on the CallHome dataset. Our results show that O-EENC-SD provides a great trade-off between DER and complexity, even when working on independent chunks with no overlap, making the system extremely efficient.

</details>


### [80] [Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis](https://arxiv.org/abs/2512.15250)
*Youssef Ghallab,Omar Iraqy,Mohamed Kandil,Mohamed Ashraf,Saadeldine Eletter,Morougue Ghazal,Ayman Khalafallah,Nagwa El-Makky*

Main category: cs.LG

TL;DR: 该研究通过对ECG信号进行大规模自监督预训练，并结合预训练的EEG编码器，实现了多模态生理信号的有效融合，在情感识别任务上取得了接近最先进的性能，证明了基础模型方法在生理信号处理方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 生理信号（如心电图和脑电图）为人类健康和认知提供了互补的见解，但由于多模态标记数据有限和模态特异性差异，多模态整合具有挑战性。

Method: 本文对CBraMod编码器进行了大规模自监督ECG预训练，引入了双重掩蔽策略来捕获导联内部和导联之间的依赖关系。利用预训练的CBarMod编码器处理EEG，并预训练对称ECG编码器，使每种模态都具备丰富的基础表示。然后通过简单的嵌入拼接融合这些表示，允许分类头学习跨模态交互，从而在有限的多模态监督下实现有效的下游学习。

Result: 在情感识别评估中，该方法取得了接近最先进的性能。

Conclusion: 精心设计的生理编码器，即使采用直接的融合方式，也能显著提高下游任务的性能。这些结果突出了基础模型方法利用生理信号整体性质的潜力，为医疗保健和情感计算提供了可扩展、标签高效和可泛化的解决方案。

Abstract: Physiological signals such as electrocardiograms (ECG) and electroencephalograms (EEG) provide complementary insights into human health and cognition, yet multi-modal integration is challenging due to limited multi-modal labeled data, and modality-specific differences . In this work, we adapt the CBraMod encoder for large-scale self-supervised ECG pretraining, introducing a dual-masking strategy to capture intra- and inter-lead dependencies. To overcome the above challenges, we utilize a pre-trained CBraMod encoder for EEG and pre-train a symmetric ECG encoder, equipping each modality with a rich foundational representation. These representations are then fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions, together enabling effective downstream learning despite limited multi-modal supervision. Evaluated on emotion recognition, our approach achieves near state-of-the-art performance, demonstrating that carefully designed physiological encoders, even with straightforward fusion, substantially improve downstream performance. These results highlight the potential of foundation-model approaches to harness the holistic nature of physiological signals, enabling scalable, label-efficient, and generalizable solutions for healthcare and affective computing.

</details>


### [81] [Topological Metric for Unsupervised Embedding Quality Evaluation](https://arxiv.org/abs/2512.15285)
*Aleksei Shestov,Anton Klenitskiy,Daria Denisova,Amurkhan Dzagkoev,Daniil Petrovich,Andrey Savchenko,Maksim Makarenko*

Main category: cs.LG

TL;DR: 该论文提出了一种名为“Persistence”的无监督评估指标，用于衡量嵌入空间的质量，其通过捕捉几何结构和拓扑丰富性，在多种任务中展现出与下游表现的强相关性。


<details>
  <summary>Details</summary>
Motivation: 在大规模无标签数据上训练的无监督和自监督表示学习方法在任务和领域泛化方面表现出色，但评估嵌入质量的无标签方法仍然是一个开放的挑战。

Method: 本文提出了一种基于持久同源性的拓扑感知度量，名为“Persistence”，用于量化嵌入空间的几何结构和拓扑丰富性，且无需监督信息。该方法与假设线性可分离性或依赖协方差结构的度量不同，它能捕捉全局和多尺度的组织结构。

Result: 在不同领域的实证结果表明，“Persistence”与下游性能保持着顶级的相关性，优于现有的无监督度量，并能实现可靠的模型和超参数选择。

Conclusion: “Persistence”是一种有效的无监督评估嵌入质量的方法，它通过捕捉嵌入空间中的拓扑结构，为模型和超参数选择提供了新的且可靠的途径。

Abstract: Modern representation learning increasingly relies on unsupervised and self-supervised methods trained on large-scale unlabeled data. While these approaches achieve impressive generalization across tasks and domains, evaluating embedding quality without labels remains an open challenge. In this work, we propose Persistence, a topology-aware metric based on persistent homology that quantifies the geometric structure and topological richness of embedding spaces in a fully unsupervised manner. Unlike metrics that assume linear separability or rely on covariance structure, Persistence captures global and multi-scale organization. Empirical results across diverse domains show that Persistence consistently achieves top-tier correlations with downstream performance, outperforming existing unsupervised metrics and enabling reliable model and hyperparameter selection.

</details>


### [82] [Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery](https://arxiv.org/abs/2512.15344)
*Hiroyoshi Nagahama,Katsufumi Inoue,Masayoshi Todorokihara,Michifumi Yoshioka*

Main category: cs.LG

TL;DR: 这篇论文介绍了两种考虑相位的预处理策略，用于处理多轴振动数据中的随机相位变化，以提高旋转机械预测性维护的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的学习方法在频谱特征提取时忽略相位或未明确利用相位信息。

Method: 提出了两种相位感知预处理策略：（1）三轴独立相位调整，将每个轴独立对齐到零相位；（2）单轴参考相位调整，通过应用统一时间偏移来保持轴间关系。使用同步三轴传感器采集的转子数据集，在两阶段学习框架下评估了六种深度学习架构。

Result: 三轴独立方法取得了持续的性能提升（Transformer模型的准确率提高了2.7%）；单轴参考方法通过保持空间相位关系，取得了更优的性能，准确率高达96.2%（提高了5.4%）。

Conclusion: 这两种相位对齐策略都是可提高预测性维护系统性能的实用且可扩展的增强方法。

Abstract: Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preprocessing strategies to address random phase variations in multi-axis vibration data: (1) three-axis independent phase adjustment that aligns each axis individually to zero phase (2) single-axis reference phase adjustment that preserves inter-axis relationships by applying uniform time shifts. Using a newly constructed rotor dataset acquired with a synchronized three-axis sensor, we evaluate six deep learning architectures under a two-stage learning framework. Results demonstrate architecture-independent improvements: the three-axis independent method achieves consistent gains (+2.7\% for Transformer), while the single-axis reference approach delivers superior performance with up to 96.2\% accuracy (+5.4\%) by preserving spatial phase relationships. These findings establish both phase alignment strategies as practical and scalable enhancements for predictive maintenance systems.

</details>


### [83] [Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection](https://arxiv.org/abs/2512.15385)
*Julian Oelhaf,Mehran Pashaei,Georg Kordowich,Christian Bergler,Andreas Maier,Johann Jäger,Siming Bayer*

Main category: cs.LG

TL;DR: 本文介绍了一个统一框架，用于系统评估电力系统保护中机器学习模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 可再生能源和分布式发电的日益普及正在改变电力系统，并对依赖固定设置和局部测量的传统保护方案提出挑战。机器学习提供了一种数据驱动的替代方案，用于集中式故障分类（FC）和故障定位（FL），从而实现更快、更自适应的决策。然而，实际部署的关键在于鲁棒性。保护算法必须在面对缺失、有噪声或降级的传感器数据时保持可靠。

Method: 高保真EMT仿真用于模拟真实的降级场景，包括传感器中断、采样率降低和瞬态通信丢失。该框架提供了一种一致的方法来对模型进行基准测试，量化有限可观测性的影响，并确定弹性运行所需的关键测量通道。

Result: 结果表明，FC在大多数降级类型下仍然高度稳定，但在单相损耗下下降约13%，而FL总体上更敏感，电压损耗使定位误差增加超过150%。

Conclusion: 这些发现为未来机器学习辅助保护系统的鲁棒性感知设计提供了可行的指导。

Abstract: The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault localization (FL), enabling faster and more adaptive decision-making. However, practical deployment critically depends on robustness. Protection algorithms must remain reliable even when confronted with missing, noisy, or degraded sensor data. This work introduces a unified framework for systematically evaluating the robustness of ML models in power system protection.
  High-fidelity EMT simulations are used to model realistic degradation scenarios, including sensor outages, reduced sampling rates, and transient communication losses. The framework provides a consistent methodology for benchmarking models, quantifying the impact of limited observability, and identifying critical measurement channels required for resilient operation. Results show that FC remains highly stable under most degradation types but drops by about 13% under single-phase loss, while FL is more sensitive overall, with voltage loss increasing localization error by over 150%. These findings offer actionable guidance for robustness-aware design of future ML-assisted protection systems.

</details>


### [84] [EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning](https://arxiv.org/abs/2512.15405)
*Jianfei Ma,Wee Sun Lee*

Main category: cs.LG

TL;DR: 该论文提出了一种名为 EUBRL 的贝叶斯强化学习算法，利用认知不确定性指导探索，在理论和实践中均表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 智能体在探索与利用之间面临困境，认知不确定性反映了这种知识受限带来的系统性不确定性，需要一种有效的方法来指导探索。

Method: 本文提出了一种贝叶斯强化学习算法 EUBRL，该算法利用认知指导实现原则性探索，自适应地减少因估计误差造成的每一步遗憾。

Result: 在无限 horizons 折扣 MDPs 中，本文建立了一类具有足够表达能力的先验的近 minimax-最优遗憾和样本复杂性保证。在稀疏奖励、长 horizons 和随机性任务中，EUBRL 表现出卓越的样本效率、可扩展性和一致性。

Conclusion: EUBRL 算法通过认知指导实现了原则性探索，并在理论和实践中都取得了显著的成果，为解决探索与利用困境提供了一种有效方案。

Abstract: At the boundary between the known and the unknown, an agent inevitably confronts the dilemma of whether to explore or to exploit. Epistemic uncertainty reflects such boundaries, representing systematic uncertainty due to limited knowledge. In this paper, we propose a Bayesian reinforcement learning (RL) algorithm, $\texttt{EUBRL}$, which leverages epistemic guidance to achieve principled exploration. This guidance adaptively reduces per-step regret arising from estimation errors. We establish nearly minimax-optimal regret and sample complexity guarantees for a class of sufficiently expressive priors in infinite-horizon discounted MDPs. Empirically, we evaluate $\texttt{EUBRL}$ on tasks characterized by sparse rewards, long horizons, and stochasticity. Results demonstrate that $\texttt{EUBRL}$ achieves superior sample efficiency, scalability, and consistency.

</details>


### [85] [FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows](https://arxiv.org/abs/2512.15420)
*Yeonwoo Cha,Semin Kim,Jinhyeon Kwon,Seunghoon Hong*

Main category: cs.LG

TL;DR: FlowBind提出了一种高效的任意到任意生成框架，通过共享潜在空间和可逆流实现高效跨模态合成，显著降低了数据需求和计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流的方法在任意到任意生成任务中存在效率问题，体现在需要大规模数据集、高计算成本和复杂的多阶段训练。

Method: FlowBind通过学习一个共享的潜在空间来捕获跨模态信息，并使用特定于模态的可逆流连接潜在空间和每种模态。这两个组件在单一的流匹配目标下联合优化，在推理时，可逆流充当编码器和解码器，直接进行跨模态翻译。

Result: FlowBind在文本、图像和音频上的实验表明，它在保持竞争性生成质量的同时，所需参数减少了6倍，训练速度比现有方法快10倍。

Conclusion: FlowBind为任意到任意生成提供了一个简单高效的框架，显著降低了数据和计算成本，同时保持了良好的生成质量。

Abstract: Any-to-any generation seeks to translate between arbitrary subsets of modalities, enabling flexible cross-modal synthesis. Despite recent success, existing flow-based approaches are challenged by their inefficiency, as they require large-scale datasets often with restrictive pairing constraints, incur high computational cost from modeling joint distribution, and rely on complex multi-stage training. We propose FlowBind, an efficient framework for any-to-any generation. Our approach is distinguished by its simplicity: it learns a shared latent space capturing cross-modal information, with modality-specific invertible flows bridging this latent to each modality. Both components are optimized jointly under a single flow-matching objective, and at inference the invertible flows act as encoders and decoders for direct translation across modalities. By factorizing interactions through the shared latent, FlowBind naturally leverages arbitrary subsets of modalities for training, and achieves competitive generation quality while substantially reducing data requirements and computational cost. Experiments on text, image, and audio demonstrate that FlowBind attains comparable quality while requiring up to 6x fewer parameters and training 10x faster than prior methods. The project page with code is available at https://yeonwoo378.github.io/official_flowbind.

</details>


### [86] [Statistics of Min-max Normalized Eigenvalues in Random Matrices](https://arxiv.org/abs/2512.15427)
*Hyakka Nakada,Shu Tanaka*

Main category: cs.LG

TL;DR: 本文探讨了随机矩阵中min-max归一化特征值的统计特性，包括评估累积分布的缩放律和推导矩阵分解的残余误差。


<details>
  <summary>Details</summary>
Motivation: 以往研究已经提出了归一化特征值的有效分布，本文在此基础上，进一步研究了min-max归一化特征值的统计特性。这是因为在数据科学的实际应用中，输入数据在处理之前通常会进行归一化。

Method: 本文应用了已提出的有效分布来评估累积分布的缩放律，并推导了随机矩阵分解过程中产生的残余误差。

Result: 通过数值实验验证了理论预测。

Conclusion: 本文成功地分析了随机矩阵中min-max归一化特征值的统计特性，包括累积分布的缩放律和矩阵分解的残余误差。

Abstract: Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max normalized eigenvalues in random matrices. Previously, the effective distribution for such normalized eigenvalues has been proposed. In this study, we apply it to evaluate a scaling law of the cumulative distribution. Furthermore, we derive the residual error that arises during matrix factorization of random matrices. We conducted numerical experiments to verify these theoretical predictions.

</details>


### [87] [Double Horizon Model-Based Policy Optimization](https://arxiv.org/abs/2512.15439)
*Akihiro Kubo,Paavo Parmas,Shin Ishii*

Main category: cs.LG

TL;DR: 该文章提出了一种名为DHMBPO的新型模型强化学习策略，可以通过分离rollout过程为长分布rollout（DR）和短训练rollout（TR），以实现对样本效率和运行时间的提升。


<details>
  <summary>Details</summary>
Motivation: 在模型强化学习（MBRL）中，rollout的长度选择面临挑战：长rollout可能加剧模型偏差并导致分布偏移，而短rollout虽然能减少价值估计偏差但可能增加策略梯度的方差。本文旨在解决这两个最优视界可能不同而造成的冲突。

Method: 提出双视界模型强化学习策略（DHMBPO）。该方法将rollout过程分为两部分：长的“分布rollout”（DR）用于生成在策略状态样本，以减少分布偏移；短的“训练rollout”（TR）则利用可微分的转换提供准确且稳定的价值梯度估计，从而减少更新次数和缩短运行时间。

Result: 双视界方法有效平衡了分布偏移、模型偏差和梯度不稳定性。并且在连续控制基准测试中，DHMBPO在样本效率和运行时间方面均优于现有的MBRL方法。

Conclusion: DHMBPO通过引入双视界rollout机制，成功地解决了MBRL中rollout长度选择的困境，显著提升了算法性能。

Abstract: Model-based reinforcement learning (MBRL) reduces the cost of real-environment sampling by generating synthetic trajectories (called rollouts) from a learned dynamics model. However, choosing the length of the rollouts poses two dilemmas: (1) Longer rollouts better preserve on-policy training but amplify model bias, indicating the need for an intermediate horizon to mitigate distribution shift (i.e., the gap between on-policy and past off-policy samples). (2) Moreover, a longer model rollout may reduce value estimation bias but raise the variance of policy gradients due to backpropagation through multiple steps, implying another intermediate horizon for stable gradient estimates. However, these two optimal horizons may differ. To resolve this conflict, we propose Double Horizon Model-Based Policy Optimization (DHMBPO), which divides the rollout procedure into a long "distribution rollout" (DR) and a short "training rollout" (TR). The DR generates on-policy state samples for mitigating distribution shift. In contrast, the short TR leverages differentiable transitions to offer accurate value gradient estimation with stable gradient updates, thereby requiring fewer updates and reducing overall runtime. We demonstrate that the double-horizon approach effectively balances distribution shift, model bias, and gradient instability, and surpasses existing MBRL methods on continuous-control benchmarks in terms of both sample efficiency and runtime.

</details>


### [88] [Copyright Infringement Risk Reduction via Chain-of-Thought and Task Instruction Prompting](https://arxiv.org/abs/2512.15442)
*Neeraj Sarna,Yuanyuan Li,Michael von Gablenz*

Main category: cs.LG

TL;DR: 该文章探讨了如何通过组合思想链、任务指令提示、负面提示和提示重写等技术来减少大型文本到图像生成模型生成受版权保护内容的风险。


<details>
  <summary>Details</summary>
Motivation: 大型文本到图像生成模型可能会记忆并再现其训练数据，如果训练数据包含受版权保护的材料，则存在版权侵权风险。

Method: 本文提出了一种结合思想链、任务指令提示、负面提示和提示重写四种策略的公式，以减少受版权保护内容的生成。

Result: 通过数值实验研究了生成图像与版权图像的相似性以及与用户输入的关联性，并分析了这些技术在不同模型复杂性下的有效性。

Conclusion: 文章提供了关于所讨论技术在降低版权内容生成风险方面的有效性的见解。

Abstract: Large scale text-to-image generation models can memorize and reproduce their training dataset. Since the training dataset often contains copyrighted material, reproduction of training dataset poses a copyright infringement risk, which could result in legal liabilities and financial losses for both the AI user and the developer. The current works explores the potential of chain-of-thought and task instruction prompting in reducing copyrighted content generation. To this end, we present a formulation that combines these two techniques with two other copyright mitigation strategies: a) negative prompting, and b) prompt re-writing. We study the generated images in terms their similarity to a copyrighted image and their relevance of the user input. We present numerical experiments on a variety of models and provide insights on the effectiveness of the aforementioned techniques for varying model complexity.

</details>


### [89] [From Risk to Resilience: Towards Assessing and Mitigating the Risk of Data Reconstruction Attacks in Federated Learning](https://arxiv.org/abs/2512.15460)
*Xiangrui Xu,Zhize Li,Yufei Han,Bin Wang,Jiqiang Liu,Wei Wang*

Main category: cs.LG

TL;DR: 这篇文章介绍了一种名为Invertibility Loss (InvLoss) 的方法，用于量化联邦学习（FL）系统中数据重建攻击（DRA）的有效性，并提出了基于InvLoss的风险评估器和自适应噪声扰动防御措施。


<details>
  <summary>Details</summary>
Motivation: 尽管对联邦学习（FL）中的数据重建攻击（DRA）进行了广泛研究，但由于缺乏理论基础的风险量化框架，如何表征和评估DRA的风险仍然悬而未决。

Method: 本文引入了Invertibility Loss (InvLoss) 来量化给定数据实例和FL模型的DRA最大可实现有效性。作者推导了InvLoss的紧密且可计算的上限，并从三个角度探讨了其含义。首先，证明了DRA风险受交换模型更新或特征嵌入的Jacobian矩阵的频谱特性支配。其次，开发了InvRE，一种基于InvLoss的DRA风险估计器。第三，提出了两种自适应噪声扰动防御措施。

Result: 作者的框架在真实世界数据集上进行了广泛的实验验证，证明了其在FL系统中系统评估和缓解DRA风险的潜力。DRA风险由交换模型更新或特征嵌入的Jacobian矩阵的频谱特性决定；InvRE提供了与攻击方法无关的、全面的风险评估。

Conclusion: InvLoss为量化FL系统中数据重建攻击的有效性提供了一个理论框架。InvRE作为一种风险评估器，可以全面评估DRA风险。提出的自适应噪声扰动防御措施可以在不损害分类准确性的前提下增强FL隐私。

Abstract: Data Reconstruction Attacks (DRA) pose a significant threat to Federated Learning (FL) systems by enabling adversaries to infer sensitive training data from local clients. Despite extensive research, the question of how to characterize and assess the risk of DRAs in FL systems remains unresolved due to the lack of a theoretically-grounded risk quantification framework. In this work, we address this gap by introducing Invertibility Loss (InvLoss) to quantify the maximum achievable effectiveness of DRAs for a given data instance and FL model. We derive a tight and computable upper bound for InvLoss and explore its implications from three perspectives. First, we show that DRA risk is governed by the spectral properties of the Jacobian matrix of exchanged model updates or feature embeddings, providing a unified explanation for the effectiveness of defense methods. Second, we develop InvRE, an InvLoss-based DRA risk estimator that offers attack method-agnostic, comprehensive risk evaluation across data instances and model architectures. Third, we propose two adaptive noise perturbation defenses that enhance FL privacy without harming classification accuracy. Extensive experiments on real-world datasets validate our framework, demonstrating its potential for systematic DRA risk evaluation and mitigation in FL systems.

</details>


### [90] [Robustness and uncertainty: two complementary aspects of the reliability of the predictions of a classifier](https://arxiv.org/abs/2512.15492)
*Adrián Detavernier,Jasper De Bock*

Main category: cs.LG

TL;DR: 本文比较了分类器个体预测可靠性评估的两种方法：鲁棒性量化（RQ）和不确定性量化（UQ）。研究发现这两种方法没有绝对的优劣，而是互补的，并且可以通过结合形成一种混合方法，其性能优于单独的RQ或UQ。


<details>
  <summary>Details</summary>
Motivation: 探索并比较鲁棒性量化和不确定性量化在评估分类器个体预测可靠性方面的有效性，并寻求结合两者的优化方案。

Method: 本文在多个基准数据集上比较了鲁棒性量化（RQ）和不确定性量化（UQ）两种方法。然后将两种方法结合成混合方法进行评估。

Result: RQ和UQ之间没有明确的优胜者，但它们是互补的。结合RQ和UQ的混合方法优于单一方法。此外，研究还评估了不确定性和鲁棒性作为不可靠性来源的相对重要性。

Conclusion: 鲁棒性量化和不确定性量化是评估分类器个体预测可靠性的互补方法，它们的结合可以获得更好的性能。

Abstract: We consider two conceptually different approaches for assessing the reliability of the individual predictions of a classifier: Robustness Quantification (RQ) and Uncertainty Quantification (UQ). We compare both approaches on a number of benchmark datasets and show that there is no clear winner between the two, but that they are complementary and can be combined to obtain a hybrid approach that outperforms both RQ and UQ. As a byproduct of our approach, for each dataset, we also obtain an assessment of the relative importance of uncertainty and robustness as sources of unreliability.

</details>


### [91] [How Smoothing is N-simplicial Attention?](https://arxiv.org/abs/2512.15600)
*Alexandre Dussolle,Pietro Liò*

Main category: cs.LG

TL;DR: 该文章介绍了N-单纯注意力机制，它将N-单纯注意力从成对的token相似性推广到高阶交互，并使它适应旋转位置编码（RoPE），并提出了一种经济高效的单纯形选择，使模型能够将计算负荷集中到对任务更敏感的交互上。该研究还通过推导Lipschitz上界来研究N-单纯注意力的平滑性，并证明它本身也存在过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统GNN中消息传递机制的局限性，特别是在捕获高阶交互方面的不足。

Method: 1. 提出了N-单纯注意力机制，将成对的token相似性扩展到高阶交互。 2. 使N-单纯注意力机制适应旋转位置编码（RoPE）。 3. 提出成本效益高的单纯形选择方法，以管理计算复杂性，并使模型能够关注对任务更敏感的交互。 4. 通过推导Lipschitz上界来分析N-单纯注意力的平滑性。

Result: 1. N-单纯注意力机制能够实现高阶交互。 2. 存在需要管理计算复杂性的问题。 3. 即使引入高阶交互，N-单纯注意力仍然存在过平滑问题。

Conclusion: N-单纯注意力机制为处理高阶交互提供了一种有前景的方法，但需要在计算效率和过平滑问题上进一步优化。

Abstract: Going from pure Multilayer Perceptron (MLP) to a learnable graph message-passing mechanism at each layer has been foundational to state-of-the-art results, despite the computational trade-off (e.g. GATs or Transformers). To go a step further, in this work, we introduce N-simplicial attention, going from pairwise token similarity to higher-order interactions, and adapt it for Rotary Position Embeddings (RoPE). To help manage the increased complexity, we propose a cost-effective simplex selection enabling the model to focus its computation load onto the more task-sensitive interactions. Beyond these core mechanisms, we study how smoothing N-simplicial attention is by deriving a Lipschitz upper-bound and by demonstrating that by itself it also suffers from over-smoothing, despite opening the attention message-passing to higher-order interactions.

</details>


### [92] [Joint Learning of Unsupervised Multi-view Feature and Instance Co-selection with Cross-view Imputation](https://arxiv.org/abs/2512.15574)
*Yuxin Cai,Yanyong Huang,Jinyuan Chang,Dongjie Wang,Tianrui Li,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: JUICE是一种新的无监督不完全多视图特征和实例协同选择方法，它通过联合学习和跨视图邻域信息，解决了传统方法中协同选择与缺失数据插补相互独立以及多视图信息融合不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的特征和实例协同选择方法在处理未标记不完全多视图数据时，通常先独立插补缺失数据，再进行协同选择，忽视了两者间的潜在交互。此外，简单合并多视图数据未能充分利用视图间的互补信息，限制了协同选择的效果。

Method: JUICE方法首先在一个统一的框架内，利用现有观测值重建不完全多视图数据，将缺失数据恢复与特征和实例协同选择结合起来。其次，JUICE利用跨视图邻域信息学习样本间的关系，并在重建过程中进一步细化缺失值插补。

Result: JUICE在多个数据集上的广泛实验表明，它优于现有的最先进方法。

Conclusion: JUICE通过将缺失数据恢复和特征与实例协同选择相结合，并利用跨视图信息进行更准确的插补，有效提高了不完全多视图数据的协同选择性能。

Abstract: Feature and instance co-selection, which aims to reduce both feature dimensionality and sample size by identifying the most informative features and instances, has attracted considerable attention in recent years. However, when dealing with unlabeled incomplete multi-view data, where some samples are missing in certain views, existing methods typically first impute the missing data and then concatenate all views into a single dataset for subsequent co-selection. Such a strategy treats co-selection and missing data imputation as two independent processes, overlooking potential interactions between them. The inter-sample relationships gleaned from co-selection can aid imputation, which in turn enhances co-selection performance. Additionally, simply merging multi-view data fails to capture the complementary information among views, ultimately limiting co-selection effectiveness. To address these issues, we propose a novel co-selection method, termed Joint learning of Unsupervised multI-view feature and instance Co-selection with cross-viEw imputation (JUICE). JUICE first reconstructs incomplete multi-view data using available observations, bringing missing data recovery and feature and instance co-selection together in a unified framework. Then, JUICE leverages cross-view neighborhood information to learn inter-sample relationships and further refine the imputation of missing values during reconstruction. This enables the selection of more representative features and instances. Extensive experiments demonstrate that JUICE outperforms state-of-the-art methods.

</details>


### [93] [Corrective Diffusion Language Models](https://arxiv.org/abs/2512.15596)
*Shuibai Zhang,Fred Zhangzhi Peng,Yiheng Zhang,Jin Pan,Grigorios G. Chrysos*

Main category: cs.LG

TL;DR: 本文介绍了一种纠错导向的后训练原则，用于提高扩散语言模型的纠错能力，并通过新引入的Code Revision Benchmark（CRB）对其进行了评估。


<details>
  <summary>Details</summary>
Motivation: 探索扩散语言模型在迭代纠错方面的潜力，并解决标准掩码扩散语言模型（MDLM）训练未能有效诱导模型识别和纠正不可靠标记的问题。

Method: 提出了一种纠错导向的后训练原则，明确监督可见的错误标记，以实现错误感知的置信度和有针对性的改进。通过引入Code Revision Benchmark（CRB）来评估纠错行为。

Result: 与使用我们方法训练的模型相比，在纠错场景中，标准MDLMs的表现显著逊色，同时我们的方法也提高了纯代码补全的性能。

Conclusion: 所提出的纠错导向后训练原则能有效提升扩散语言模型的纠错能力，使其在代码修正等任务中表现优异，并优于传统方法。

Abstract: Diffusion language models are structurally well-suited for iterative error correction, as their non-causal denoising dynamics allow arbitrary positions in a sequence to be revised. However, standard masked diffusion language model (MDLM) training fails to reliably induce this behavior, as models often cannot identify unreliable tokens in a complete input, rendering confidence-guided refinement ineffective. We study corrective behavior in diffusion language models, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a correction-oriented post-training principle that explicitly supervises visible incorrect tokens, enabling error-aware confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark (CRB), a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and controlled settings demonstrate that models trained with our approach substantially outperform standard MDLMs in correction scenarios, while also improving pure completion performance. Our code is publicly available at https://github.com/zhangshuibai/CDLM.

</details>


### [94] [Behavior Tokens Speak Louder: Disentangled Explainable Recommendation with Behavior Vocabulary](https://arxiv.org/abs/2512.15614)
*Xinshun Feng,Mingzhe Liu,Yi Qiao,Tongyu Zhu,Leilei Sun,Shuai Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为BEAT的统一可迁移框架，通过将用户和物品行为标记化为离散、可解释的序列，以提升可解释推荐系统的性能，并在零样本推荐和解释生成方面取得了显著成效。


<details>
  <summary>Details</summary>
Motivation: 现有可解释推荐方法依赖于ID表示，语义不明确且对语言模型存在结构限制，难以应对开放场景和复杂的用户交互。实际应用中，用户意图多样，协同信号与语言语义不符，这些都加剧了挑战。

Method: BEAT框架通过向量量化的自编码过程构建行为词汇表，从图表示中解耦宏观兴趣和微观意图。引入多级语义监督，弥合行为信号与语言空间之间的鸿沟。设计语义对齐正则化机制，将行为token直接嵌入到冻结语言模型的输入空间。

Result: 在三个公共数据集上的实验表明，BEAT显著提升了零样本推荐性能，并能生成连贯且信息丰富的解释。

Conclusion: BEAT的行为token捕获了细粒度语义，为将复杂行为模式集成到大型语言模型提供了即插即用的接口。

Abstract: Recent advances in explainable recommendations have explored the integration of language models to analyze natural language rationales for user-item interactions. Despite their potential, existing methods often rely on ID-based representations that obscure semantic meaning and impose structural constraints on language models, thereby limiting their applicability in open-ended scenarios. These challenges are intensified by the complex nature of real-world interactions, where diverse user intents are entangled and collaborative signals rarely align with linguistic semantics. To overcome these limitations, we propose BEAT, a unified and transferable framework that tokenizes user and item behaviors into discrete, interpretable sequences. We construct a behavior vocabulary via a vector-quantized autoencoding process that disentangles macro-level interests and micro-level intentions from graph-based representations. We then introduce multi-level semantic supervision to bridge the gap between behavioral signals and language space. A semantic alignment regularization mechanism is designed to embed behavior tokens directly into the input space of frozen language models. Experiments on three public datasets show that BEAT improves zero-shot recommendation performance while generating coherent and informative explanations. Further analysis demonstrates that our behavior tokens capture fine-grained semantics and offer a plug-and-play interface for integrating complex behavior patterns into large language models.

</details>


### [95] [Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2512.15687)
*Zhenwen Liang,Sidi Lu,Wenhao Yu,Kishan Panaganti,Yujun Zhou,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: G2RL是一种梯度引导的强化学习框架。它可以通过模型自身的更新几何来驱动探索，并在数学和通用推理基准测试中持续改进性能。


<details>
  <summary>Details</summary>
Motivation: 作者认为，目前大型语言模型中的强化学习探索机制与模型实际学习方式不符，现有的探索机制无法保证采样轨迹在优化过程中形成不同的更新方向。

Method: G2RL通过测量模型最后一层敏感度对每个响应构建序列级特征，并通过比较这些特征来衡量每个轨迹将如何重塑策略。G2RL会给予引入新梯度方向的轨迹奖励，并弱化冗余或偏离流形的更新。

Result: 在Qwen3基础1.7B和4B模型上进行数学和通用推理基准测试时，G2RL持续改进了pass@1、maj@16和pass@k。

Conclusion: G2RL将探索扩展到更多正交和对立的梯度方向，同时保持语义连贯性，证明了策略自身的更新空间可以为大型语言模型强化学习中的探索提供更忠实和有效的指导。

Abstract: Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.

</details>


### [96] [SoFlow: Solution Flow Models for One-Step Generative Modeling](https://arxiv.org/abs/2512.15657)
*Tianze Luo,Haotian Yuan,Zhuang Liu*

Main category: cs.LG

TL;DR: 该论文提出了SoFlow，一个用于一步生成图像的模型，通过新的损失函数提高了生成效率和性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和流匹配模型的多步去噪过程效率低下，促使研究人员寻求少步甚至一步生成的方法。

Method: SoFlow模型通过分析速度函数和速度常微分方程（ODE）解函数之间的关系，提出了流匹配损失和解一致性损失。流匹配损失使得模型在训练期间为无分类器指导（CFG）提供估计的速度场，从而提高生成性能。解一致性损失无需计算雅可比向量积（JVP）。

Result: 在ImageNet 256x256数据集上，使用相同的Diffusion Transformer (DiT)架构和训练周期，SoFlow模型比MeanFlow模型取得了更好的FID-50K分数。

Conclusion: SoFlow模型通过结合流匹配损失和无需JVP计算的解一致性损失，实现了高效且高性能的一步图像生成，解决了现有扩散模型和流匹配模型效率低下的问题。

Abstract: The multi-step denoising process in diffusion and Flow Matching models causes major efficiency issues, which motivates research on few-step generation. We present Solution Flow Models (SoFlow), a framework for one-step generation from scratch. By analyzing the relationship between the velocity function and the solution function of the velocity ordinary differential equation (ODE), we propose a Flow Matching loss and a solution consistency loss to train our models. The Flow Matching loss allows our models to provide estimated velocity fields for Classifier-Free Guidance (CFG) during training, which improves generation performance. Notably, our consistency loss does not require the calculation of the Jacobian-vector product (JVP), a common requirement in recent works that is not well-optimized in deep learning frameworks like PyTorch. Experimental results indicate that, when trained from scratch using the same Diffusion Transformer (DiT) architecture and an equal number of training epochs, our models achieve better FID-50K scores than MeanFlow models on the ImageNet 256x256 dataset.

</details>


### [97] [FrontierCS: Evolving Challenges for Evolving Intelligence](https://arxiv.org/abs/2512.15699)
*Qiuyang Mang,Wenhao Chai,Zhifei Li,Huanzhi Mao,Shang Zhou,Alexander Du,Hanchen Li,Shu Liu,Edwin Chen,Yichuan Wang,Xieting Chu,Zerui Cheng,Yuan Xu,Tian Xia,Zirui Wang,Tianneng Shi,Jianzhu Yao,Yilong Zhao,Qizheng Zhang,Charlie Ruan,Zeyu Shen,Kaiyuan Liu,Runyuan He,Dong Xing,Zerui Li,Zirong Zeng,Yige Jiang,Lufeng Cheng,Ziyi Zhao,Youran Sun,Wesley Zheng,Meiyuwang Zhang,Ruyi Ji,Xuechang Tu,Zihan Zheng,Zexing Chen,Kangyang Zhou,Zhaozi Wang,Jingbang Chen,Aleksandra Korolova,Peter Henderson,Pramod Viswanath,Vijay Ganesh,Saining Xie,Zhuang Liu,Dawn Song,Sewon Min,Ion Stoica,Joseph E. Gonzalez,Jingbo Shang,Alvin Cheung*

Main category: cs.LG

TL;DR: FrontierCS是一项包含156个开放性问题的计算机科学基准测试，旨在解决现有基准测试中缺乏已知最优解的问题。它包含算法问题和研究问题，并提供专家参考解决方案和自动评估器。我们发现模型在此基准测试上远低于人类专家的表现，并且在只生成可用代码而非高质量算法和系统设计方面存在过度优化问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试通常侧重于已知最优解的任务，不能反映计算机科学前沿领域中许多问题的本质，这些问题的最优解是未知的，但解决方案的质量可以客观评估。

Method: 设计并开发了FrontierCS，一个包含156个开放性问题的计算机科学基准测试。这些问题由计算机科学博士和顶级竞争性编程参与者等专家设计和评审。基准测试中的问题分为算法问题和研究问题，其解决方案通过可执行程序实现。每个问题都提供专家参考解决方案和自动评估器。

Result: 模型在FrontierCS的算法和研究轨道上都远落后于人类专家。仅仅增加推理预算并不能弥补这一差距。模型经常过度优化于生成仅能工作但质量不高的代码，而不是发现高质量的算法和系统设计。

Conclusion: FrontierCS作为一个开放式设计、可衡量进展和专家策划的基准测试，代表了计算机科学难度的前沿。当前的推理模型在解决这类问题时仍表现出显著的局限性，需要进一步的研究来提高模型发现高质量算法和系统设计的能力。

Abstract: We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike existing benchmarks that focus on tasks with known optimal solutions, FrontierCS targets problems where the optimal solution is unknown, but the quality of a solution can be objectively evaluated. Models solve these tasks by implementing executable programs rather than outputting a direct answer. FrontierCS includes algorithmic problems, which are often NP-hard variants of competitive programming problems with objective partial scoring, and research problems with the same property. For each problem we provide an expert reference solution and an automatic evaluator. Combining open-ended design, measurable progress, and expert curation, FrontierCS provides a benchmark at the frontier of computer-science difficulty. Empirically, we find that frontier reasoning models still lag far behind human experts on both the algorithmic and research tracks, that increasing reasoning budgets alone does not close this gap, and that models often over-optimize for generating merely workable code instead of discovering high-quality algorithms and system designs.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [98] [Low-Complexity Channel Estimation for Internet of Vehicles AFDM Communications With Sparse Bayesian Learning](https://arxiv.org/abs/2512.14776)
*Xiangxiang Li,Haiyan Wang,Yao Ge,Xiaohong Shen,Miaowen Wen,Shun Zhang,Yong Liang Guan*

Main category: cs.IT

TL;DR: 本文提出了一种针对AFDM系统的稀疏贝叶斯学习（SBL）框架，用于解决双分散信道中的信道估计问题。


<details>
  <summary>Details</summary>
Motivation: 在车联网中，仿射频分复用（AFDM）被认为是一种非常有前景的波形，可以实现高可靠性的连接。然而，在双分散信道中，要达到AFDM系统预期的性能，精确的信道估计至关重要且具有挑战性。

Method: 本文提出了一种稀疏贝叶斯学习（SBL）框架，并开发了两种具有离网信道估计功能的动态网格更新策略：网格细化SBL（GR-SBL）和网格演化SBL（GE-SBL）估计器。GR-SBL采用局部网格细化方法和动态更新网格以实现高精度估计。GE-SBL通过一阶线性近似逼近离网分量，并逐步演化网格以提高估计精度。此外，本文还开发了一种分布式计算方案，将大维信道估计模型分解为多个可管理的小维子模型，以降低GR-SBL和GE-SBL的复杂度，分别表示为分布式GR-SBL（D-GR-SBL）和分布式GE-SBL（D-GE-SBL）估计器，这些方案也支持并行处理以减少计算延迟。

Result: 仿真结果表明，所提出的信道估计器优于现有的竞争方案。GR-SBL估计器以高复杂度为代价实现了高精度估计。GE-SBL估计器在性能和复杂度之间提供了更好的权衡。提议的D-GR-SBL和D-GE-SBL估计器有效地降低了复杂性，并保持了与GR-SBL和GE-SBL估计器相当的性能。

Conclusion: 本文提出的SBL框架及其GR-SBL、GE-SBL、D-GR-SBL和D-GE-SBL估计器为AFDM系统在双分散信道中的信道估计问题提供了有效的解决方案，并在性能、复杂度和计算效率之间取得了良好的平衡。

Abstract: Affine frequency division multiplexing (AFDM) has been considered as a promising waveform to enable high-reliable connectivity in the internet of vehicles. However, accurate channel estimation is critical and challenging to achieve the expected performance of the AFDM systems in doubly-dispersive channels. In this paper, we propose a sparse Bayesian learning (SBL) framework for AFDM systems and develop a dynamic grid update strategy with two off-grid channel estimation methods, i.e., grid-refinement SBL (GR-SBL) and grid-evolution SBL (GE-SBL) estimators. Specifically, the GR-SBL employs a localized grid refinement method and dynamically updates grid for a high-precision estimation. The GE-SBL estimator approximates the off-grid components via first-order linear approximation and enables gradual grid evolution for estimation accuracy enhancement. Furthermore, we develop a distributed computing scheme to decompose the large-dimensional channel estimation model into multiple manageable small-dimensional sub-models for complexity reduction of GR-SBL and GE-SBL, denoted as distributed GR-SBL (D-GR-SBL) and distributed GE-SBL (D-GE-SBL) estimators, which also support parallel processing to reduce the computational latency. Finally, simulation results demonstrate that the proposed channel estimators outperform existing competitive schemes. The GR-SBL estimator achieves high-precision estimation with fine step sizes at the cost of high complexity, while the GE-SBL estimator provides a better trade-off between performance and complexity. The proposed D-GR-SBL and D-GE-SBL estimators effectively reduce complexity and maintain comparable performance to GR-SBL and GE-SBL estimators, respectively.

</details>


### [99] [Rotatable IRS-Assisted 6DMA Communications: A Two-timescale Design](https://arxiv.org/abs/2512.15092)
*Chao Zhou,Changsheng You,Cong Zhou,Liujia Yao,Weijie Yuan,Beixiong Zheng,Nan Wu*

Main category: cs.IT

TL;DR: 本文提出了一种结合了可旋转智能反射面（R-IRS）和六维可移动天线（6DMA）的多功能天线/表面系统，以通过两时间尺度传输协议来最大化多用户的平均和速率。


<details>
  <summary>Details</summary>
Motivation: 智能反射面（IRS）和可移动天线（MA）在增强无线通信方面具有潜力，但受限于实际约束。本文旨在通过结合两者的优点，提出一种多功能天线/表面系统来克服这些限制，以提高无线通信性能。

Method: 本文提出了一种多功能天线/表面系统，该系统结合了可旋转智能反射面（R-IRS）和六维可移动天线（6DMA）。针对单用户情况，优化了6DMA和R-IRS的配置，使其能够进行多波束传输和多径对齐。对于多用户情况，提出了一种结合加权最小均方误差（WMMSE）和随机逐次凸逼近（SSCA）的高效算法。还提出了一种低复杂度的算法来降低计算复杂度。

Result: 在单用户情况下，6DMA基站应形成稀疏阵列，用于向IRS和用户进行多波束传输，有效协调直射和反射信道，同时IRS旋转实现了有效的多径对齐。在多用户情况下，通过WMMS和SSCA技术结合提出的高效算法，以及低复杂度的算法，取得了显著的性能增益。

Conclusion: 本文提出的结合6DMA基站和R-IRS的多功能天线/表面系统，在两时间尺度协议下，通过联合利用两者的空间自由度，显著提升了无线通信性能。

Abstract: Intelligent reflecting surface (IRS) and movable antenna (MA) are promising technologies to enhance wireless communication by reconfiguring channels at the environment and transceiver sides. However, their performance is constrained by practical limitations. To address this, we propose a multi-functional antenna/surface system that leverages their complementary advantages. A rotatable IRS (R-IRS) is deployed to enhance downlink communications from a six-dimensional MA (6DMA)-equipped base station (BS) to multiple single-antenna users. To reduce the complexity of real-time channel estimation and beamforming, we formulate an optimization problem to maximize the average sum-rate using a two-timescale (TTS) transmission protocol. Specifically, the BS antenna configuration (including position and rotation) and IRS rotation and reflection are optimized based on statistical channel state information (S-CSI), while BS transmit beamforming is designed using instantaneous CSI (I-CSI) in the short timescale. We first consider a single-user case and show that the 6DMA at the BS should form a sparse array for multi-beam transmission towards both the IRS and the user, allowing efficient coordination of direct and reflected channels, while the IRS rotation achieves effective multi-path alignment. For the general multi-user case, the optimization problem is non-convex and challenging to solve. To tackle this, we propose an efficient algorithm combining weighted minimum mean-square error (WMMSE) and stochastic successive convex approximation (SSCA) techniques. A low-complexity algorithm is also proposed to reduce computational complexity. Numerical results validate the proposed system, showing significant performance gains by jointly exploiting the spatial degrees of freedom of the 6DMA-BS and R-IRS under the TTS protocol.

</details>


### [100] [Sparse Principal Component Analysis with Energy Profile Dependent Sample Complexity](https://arxiv.org/abs/2512.15191)
*Mengchu Xu,Jian Wang,Yonina C. Eldar*

Main category: cs.IT

TL;DR: 该文章旨在解决高维、样本有限情况下的稀疏主成分分析问题。作者提出了一种名为"Spectral Energy Pursuit (SEP)"的迭代方案，通过重复筛选和重新选择坐标，以适应不同的能量分布。研究结果表明，SEP的样本复杂度与能量分布相适应，并且在实际应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管在稀疏主成分分析方面取得了广泛进展，但大多数方法和分析都针对平坦尖峰情况，当尖峰能量在其支持范围内分布不均匀时，缺乏指导。

Method: 本文提出了一种名为"Spectral Energy Pursuit (SEP)"的迭代方案。该方案通过重复筛选和重新选择坐标，并围绕一个结构函数 \(s(p)\) 展开，该函数量化了尖峰能量在其前 \(p\) 个条目上的累积方式。SEP可以适应能量分布，并且其样本复杂度也与能量分布相适应。此外，本文还提出了一种轻量级的后处理方法，即截断幂迭代，以确保最终估计器达到统一的统计误差范围。

Result: SEP 的样本量达到 \(\max_{1\le p\le k} p\,s^2(p)\,\log n\) 的数量级，这与平坦尖峰的经典 \(k^2\log n\) 样本复杂度相匹配，并且随着能量分布变得更加集中，样本量会向 \(k\log n\) 方案改进。经验模拟也验证了 SEP 在平坦、幂律和指数信号上都优于现有算法。

Conclusion: 本文提出了一种名为 SEP 的方法，该方法通过迭代筛选和重新选择坐标，成功解决了高维、样本有限情况下的稀疏主成分分析问题。SEP 的样本复杂度与能量分布相适应，并且在各种信号类型下均表现出优越的性能。

Abstract: We study sparse principal component analysis in the high-dimensional, sample-limited regime, aiming to recover a leading component supported on a few coordinates. Despite extensive progress, most methods and analyses are tailored to the flat-spike case, offering little guidance when spike energy is unevenly distributed across the support. Motivated by this, we propose Spectral Energy Pursuit (SEP), an effective iterative scheme that repeatedly screens and reselects coordinates, with a sample complexity that adapts to the energy profile. We develop our framework around a structure function \(s(p)\) that quantifies how spike energy accumulates over its top \(p\) entries. We establish that SEP succeeds with a sample size of order \(\max_{1\le p\le k} p\,s^2(p)\,\log n\), which matches the classical \(k^2\log n\) sample complexity for flat spikes and improves toward the \(k\log n\) regime as the profile becomes more concentrated. As a lightweight post-processing, a single truncated power iteration is proven to enable the final estimator to attain a uniform statistical error bound. Empirical simulations across flat, power-law, and exponential signals validate that SEP adapts to profile structure without tuning and outperforms existing algorithms.

</details>


### [101] [Variational Robust Kalman Filters: A Unified Framework](https://arxiv.org/abs/2512.15419)
*Shilei Li,Dawei Shi,Hao Yu,Ling Shi*

Main category: cs.IT

TL;DR: 本文提出了一种统一的变分鲁棒卡尔曼滤波器，将传统卡尔曼滤波器、鲁棒卡尔曼滤波器和自适应卡尔曼滤波器进行融合，通过调整参数使其在复杂噪声环境下表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有的卡尔曼滤波器在处理复杂噪声场景时存在局限性，因为鲁棒滤波器和自适应滤波器之间存在内在不兼容性，难以同时实现鲁棒性和自适应性。

Method: 本文提出了一种统一的变分鲁棒卡尔曼滤波器，该滤波器基于由学生t分布引起的损失函数和变分推理，并通过不动点迭代以计算效率高的方式求解。

Result: 本文提出的滤波器可以通过调整参数恢复传统的卡尔曼滤波器、鲁棒卡尔曼滤波器和自适应卡尔曼滤波器，并且可以抑制不完善的过程噪声和测量噪声。

Conclusion: 鲁棒性可以被理解为适应性的先决条件，这使得通过切换规则将上述两个竞争目标合并到一个框架中成为可能，从而在复杂噪声环境中表现出色。

Abstract: Robustness and adaptivity are two competing objectives in Kalman filters (KF). Robustness involves temporarily inflating prior estimates of noise covariances, while adaptivity updates prior beliefs using real-time information. In practical applications, both process and measurement noise can be influenced by outliers, be time-varying, or both. Existing works may not effectively address the above complex noise scenarios, as there is an intrinsic incompatibility between robust filters and adaptive filters. In this work, we propose a unified variational robust Kalman filter, built on a Student's t-distribution induced loss function and variational inference, and solved through fixed-point iteration in a computationally efficient manner. We demonstrate that robustness can be understood as a prerequisite for adaptivity, making it possible to merge the above two competing goals into a single framework through switching rules. Additionally, our proposed filter can recover conventional KF, robust KF, and adaptive KF by adjusting parameters, and can suppress both the imperfect process and measurement noise, enabling it to perform superiorly in complex noise environments. Simulations verify the effectiveness of the proposed method.

</details>


### [102] [An Anti-Interference AFDM System: Interference Impacts Analyses and Parameter Optimization](https://arxiv.org/abs/2512.15425)
*Peng Yuan,Zulin Wang,Tao Luo,Yuanhan Ni*

Main category: cs.IT

TL;DR: 本文提出了一种抗干扰AFDM系统，并在高机动性场景下，通过理论分析和实验验证，实现了高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 为了解决高机动性场景下，恶意高功率干扰对AFDM系统可靠性和资源效率的影响。

Method: 推导了离散仿射傅里叶变换（DAFT）域中的干扰闭式表达式，并将其分为平稳和非平稳两类。在此基础上，揭示了包吞吐量与扩频和纠错编码参数之间的解析关系，并设计了参数优化算法。在接收端，设计了一种线性复杂度的相关DAFT域检测器（CDD），该检测器利用扩频序列的自相关函数和AFDM输入输出关系的循环移位特性，实现了全分集增益，并通过相关均衡避免了矩阵求逆。

Result: 推导出的闭式表达式的准确性得到了验证，并且所提出的抗干扰AFDM系统在高机动性场景中，能在干扰下实现高包吞吐量。

Conclusion: 本文提出的抗干扰AFDM系统通过理论分析、参数优化和创新的接收机设计，有效提升了系统在高机动性干扰环境下的性能和可靠性。

Abstract: This paper proposes an anti-interference affine frequency division multiplexing (AFDM) system to ensure reliability and resource efficiency under malicious high-power interference originating from adversarial devices in high-mobility scenarios. Closed-form expressions of interferences in the discrete affine Fourier transform (DAFT) domain are derived by utilizing the stationary phase principle and the Affine Fourier transform convolution theorem, which indicates that interference impacts can be classified into stationary and non-stationary categories. On this basis, we reveal the analytical relationship between packet throughput and the paramerters of spread spectrum and error correction coding in our proposed anti-interference system, which enables the design of a parameter optimization algorithm that maximizes packet throughput. For reception, by jointly utilizing the autocorrelation function of spreading sequence and the cyclic-shift property of AFDM input-output relation, we design a linear-complexity correlation-based DAFT domain detector (CDD) capable of achieving full diversity gain, which performs correlation-based equalization to avoid matrix inversion. Numerical results validate the accuracy of the derived closed-form expressions and verify that the proposed anti-interference AFDM system could achieve high packet throughput under interference in high-mobility scenarios.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [103] [High-Dimensional Partial Least Squares: Spectral Analysis and Fundamental Limitations](https://arxiv.org/abs/2512.15684)
*Victor Léger,Florent Chatelain*

Main category: stat.ML

TL;DR: 本文对SVD中的PLS在数据集成中的高维行为进行了准确的理论分析。


<details>
  <summary>Details</summary>
Motivation: PLS已被广泛应用于数据集成，但其在高维区域的行为缺乏精确的理论理解。

Method: 我们通过随机矩阵理论中的工具分析了相关交叉协方差矩阵的奇异向量，推导了估计和真实潜在方向之间对齐的渐近特征。

Result: 这些结果对PLS-SVD的重建性能提供了定量的解释，并指出了该方法表现出反直觉或限制行为的区域。通过对比分析，我们证明了PLS-SVD在检测共同潜在子空间方面的渐近优越性。

Conclusion: 总的来说，我们的研究为高维PLS-SVD提供了全面的理论理解，阐明了其优点和基本局限性。

Abstract: Partial Least Squares (PLS) is a widely used method for data integration, designed to extract latent components shared across paired high-dimensional datasets. Despite decades of practical success, a precise theoretical understanding of its behavior in high-dimensional regimes remains limited. In this paper, we study a data integration model in which two high-dimensional data matrices share a low-rank common latent structure while also containing individual-specific components. We analyze the singular vectors of the associated cross-covariance matrix using tools from random matrix theory and derive asymptotic characterizations of the alignment between estimated and true latent directions. These results provide a quantitative explanation of the reconstruction performance of the PLS variant based on Singular Value Decomposition (PLS-SVD) and identify regimes where the method exhibits counter-intuitive or limiting behavior. Building on this analysis, we compare PLS-SVD with principal component analysis applied separately to each dataset and show its asymptotic superiority in detecting the common latent subspace. Overall, our results offer a comprehensive theoretical understanding of high-dimensional PLS-SVD, clarifying both its advantages and fundamental limitations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [104] [Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning](https://arxiv.org/abs/2512.14709)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 这篇论文探讨了Transformer模型如何通过近似向量符号架构（VSA）实现类推理行为，并提出了改进其符号操作稳定性的方法。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在推理方面表现出色，但在符号操作的稳定性上仍有不足。本文旨在通过VSA视角统一理解这些现象。

Method: 本文将Transformer的自注意力机制和残差连接解释为实现了近似的向量符号架构（VSA）。具体而言，查询和键定义了角色空间，值编码了填充物，注意力权重执行软解绑，残差连接实现了多个绑定结构的叠加。作者利用这种代数视角将Transformer内部机制与思维链、基于程序的推理和记忆增强工具使用联系起来，并解释了模型失效模式，如变量混淆和逻辑相关提示中的不一致性。基于此，作者提出了VSA启发式架构偏置（包括显式绑定/解绑头和超维记忆层）和训练目标，以促进角色-填充物分离和鲁棒的叠加。

Result: 通过将Transformer解释为近似VSA，本文揭示了Transformer的内部机制，解释了其推理行为和失败模式，并提出了VSA启发式改进方案。

Conclusion: 将注意力机制视为软向量符号计算，为实现更可解释和逻辑上更可靠的推理系统提供了一条M明确的途径。

Abstract: Transformer-based language models display impressive reasoning-like behavior, yet remain brittle on tasks that require stable symbolic manipulation. This paper develops a unified perspective on these phenomena by interpreting self-attention and residual streams as implementing an approximate Vector Symbolic Architecture (VSA). In this view, queries and keys define role spaces, values encode fillers, attention weights perform soft unbinding, and residual connections realize superposition of many bound structures. We use this algebraic lens to relate transformer internals to chain-of-thought traces, program-based reasoning, and memory-augmented tool use, and to explain characteristic failure modes such as variable confusion and inconsistency across logically related prompts. Building on this perspective, we propose VSA-inspired architectural biases, including explicit binding/unbinding heads and hyperdimensional memory layers, and training objectives that promote role-filler separation and robust superposition. Finally, we outline metrics for measuring "VSA-likeness" and logical compositionality, and pose theoretical and architectural open problems. Overall, the paper argues that viewing attention as soft vector-symbolic computation offers a principled route toward more interpretable and logically reliable reasoning systems.

</details>


### [105] [IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection](https://arxiv.org/abs/2512.14792)
*Roman Nekrasov,Stefano Fossati,Indika Kumara,Damian Andrew Tamburri,Willem-Jan van den Heuvel*

Main category: cs.AI

TL;DR: 该论文调查了通过系统地注入结构化配置知识来改进大型语言模型（LLMs）生成的Terraform基础设施即代码（IaC）的方法。


<details>
  <summary>Details</summary>
Motivation: 目前，大型语言模型在生成正确且符合意图的基础设施即代码（IaC）方面的成功率较低。

Method: 通过增强现有的IaC-Eval基准测试（增加云仿真和自动化错误分析），并开发了LLM辅助IaC代码生成的新错误分类法。还实施并评估了一系列知识注入技术，从简单的检索增强生成（RAG）到更复杂的图RAG方法，包括图组件的语义丰富和资源间依赖建模。

Result: 基线LLM的性能较差（27.1%的总体成功率），但注入结构化配置知识后，技术验证成功率提高到75.3%，总体成功率提高到62.6%。尽管技术正确性有所提高，但意图对齐趋于稳定，揭示了“正确性-一致性差距”。

Conclusion: 大型语言模型可以成为熟练的“程序员”，但在 O 满足细致的用户意图方面仍然是有限的“架构师”。

Abstract: Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark was significantly enhanced with cloud emulation and automated error analysis. Additionally, a novel error taxonomy for LLM-assisted IaC code generation was developed. A series of knowledge injection techniques was implemented and evaluated, progressing from Naive Retrieval-Augmented Generation (RAG) to more sophisticated Graph RAG approaches. These included semantic enrichment of graph components and modeling inter-resource dependencies. Experimental results demonstrated that while baseline LLM performance was poor (27.1% overall success), injecting structured configuration knowledge increased technical validation success to 75.3% and overall success to 62.6%. Despite these gains in technical correctness, intent alignment plateaued, revealing a "Correctness-Congruence Gap" where LLMs can become proficient "coders" but remain limited "architects" in fulfilling nuanced user intent.

</details>


### [106] [Agentic AI for Integrated Sensing and Communication: Analysis, Framework, and Case Study](https://arxiv.org/abs/2512.15044)
*Wenwen Xie,Geng Sun,Ruichen Zhang,Xuejie Liu,Yinqiu Liu,Jiacheng Wang,Dusit Niyato,Ping Zhang*

Main category: cs.AI

TL;DR: 本文探讨了智能AI在ISAC系统中的应用，旨在提高系统在动态复杂环境中的效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 随着无线环境日益动态和复杂，集成传感与通信（ISAC）系统需要更智能的处理和更自主的操作。智能AI通过实现连续的感知-推理-行动循环，为ISAC系统提供智能、自主和高效的运行。

Method: 首先，全面回顾了智能AI和ISAC系统的关键特性。其次，展示了几种常用的ISAC系统优化方法，并强调了基于生成式AI的智能AI的显著优势。第三，提出了一个新颖的智能ISAC框架，并通过案例研究验证了其在优化ISAC性能方面的优越性。

Result: 提出了一个新颖的智能ISAC框架，并通过案例研究验证了其在优化ISAC性能方面的优越性。

Conclusion: 本文澄清了基于智能AI的ISAC系统的未来研究方向，强调了智能AI在提升ISAC系统效率和适应性方面的巨大潜力。

Abstract: Integrated sensing and communication (ISAC) has emerged as a key development direction in the sixth-generation (6G) era, which provides essential support for the collaborative sensing and communication of future intelligent networks. However, as wireless environments become increasingly dynamic and complex, ISAC systems require more intelligent processing and more autonomous operation to maintain efficiency and adaptability. Meanwhile, agentic artificial intelligence (AI) offers a feasible solution to address these challenges by enabling continuous perception-reasoning-action loops in dynamic environments to support intelligent, autonomous, and efficient operation for ISAC systems. As such, we delve into the application value and prospects of agentic AI in ISAC systems in this work. Firstly, we provide a comprehensive review of agentic AI and ISAC systems to demonstrate their key characteristics. Secondly, we show several common optimization approaches for ISAC systems and highlight the significant advantages of generative artificial intelligence (GenAI)-based agentic AI. Thirdly, we propose a novel agentic ISAC framework and prensent a case study to verify its superiority in optimizing ISAC performance. Finally, we clarify future research directions for agentic AI-based ISAC systems.

</details>


### [107] [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://arxiv.org/abs/2512.15089)
*Jinwu Hu,Dongjin Yang,Langyu Bian,Zhiquan Wen,Yufeng Wang,Yaofo Chen,Bin Xiao,Yuanqing Li,Mingkui Tan*

Main category: cs.AI

TL;DR: CogER 是一个受人类分层推理启发的框架，它能自动为每个查询选择最合适的推理策略。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 推理策略难以平衡不同难度查询的推理效率和准确性。

Method: CogER 评估传入查询的复杂性，并将其分配给预定义的级别，每个级别对应一个量身定制的处理策略；通过将此过程建模为马尔可夫决策过程并使用强化学习训练 CogER-Agent 来实现自动策略选择；引入认知工具辅助推理，使 LLM 能够在思维链中自主调用外部工具。

Result: CogER 在 In-Domain 任务上的平均精确匹配率至少提高了 13%，在 Out-of-Domain 任务上平均相对提高了 8%。

Conclusion: CogER 显著优于 SOTA 测试时扩展方法。

Abstract: Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.

</details>


### [108] [A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem](https://arxiv.org/abs/2512.15198)
*Mohsen Nafar,Michael Römer,Lin Xie*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的基于聚类的变量排序框架，用于改进离散优化中松弛决策图的质量，通过将变量划分为簇来减少动态变量排序启发式算法的计算开销。


<details>
  <summary>Details</summary>
Motivation: 高效的离散优化算法严重依赖于强的原始和对偶边界。松弛决策图（DDs）提供了一种通用机制来导出来自节点合并的对偶边界。然而，松弛图的质量（即所得对偶边界的紧密性）严重依赖于变量排序和编译过程中执行的合并决策。动态变量排序启发式算法能有效收紧边界，但在全局评估时会产生计算开销。

Method: 本文引入了一种新的基于聚类的变量排序框架，以减轻上述权衡。该框架不将动态排序启发式应用于所有未固定变量，而是首先将变量划分为簇，然后利用这种结构分解来指导排序过程，从而显著减少启发式算法的搜索空间。具体包括两种策略：簇间策略（Cluster-to-Cluster）和选择排序策略（Pick-and-Sort）。此外，还提出了两种不同的策略来设置簇的数量。

Result: 在最大权重独立集问题（MWISP）基准实例上，该方法与标准动态变量排序基线算法相比，计算成本持续降低。

Conclusion: 所提出的基于聚类的变量排序框架通过结构分解和引导排序过程，显著减少了决策图的计算开销，提高了离散优化算法的效率和对偶边界的紧密性。

Abstract: Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these relaxed diagrams, i.e. the tightness of the resulting dual bounds, depends critically on the variable ordering and the merging decisions executed during compilation. While dynamic variable ordering heuristics effectively tighten bounds, they often incur computational overhead when evaluated globally across the entire variable set. To mitigate this trade-off, this work introduces a novel clustering-based framework for variable ordering. Instead of applying dynamic ordering heuristics to the full set of unfixed variables, we first partition variables into clusters. We then leverage this structural decomposition to guide the ordering process, significantly reducing the heuristic's search space. Within this framework, we investigate two distinct strategies: Cluster-to-Cluster, which processes clusters sequentially using problem-specific aggregate criteria (such as cumulative vertex weights in the Maximum Weighted Independent Set Problem (MWISP)), and Pick-and-Sort, which iteratively selects and sorts representative variables from each cluster to balance local diversity with heuristic guidance. Later on, developing some theoretical results on the growth of the size of DDs for MWISP we propose two different policies for setting the number of clusters within the proposed framework. We embed these strategies into a DD-based branch-and-bound algorithm and evaluate them on the MWISP. Across benchmark instances, the proposed methodology consistently reduces computational costs compared to standard dynamic variable ordering baseline.

</details>


### [109] [ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I](https://arxiv.org/abs/2512.15298)
*Seok-Hyun Ga,Chun-Yen Chang*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLM）在教育评估中的表现，强调了其在多模态科学推理方面的缺陷，并提出了“抗AI问题”以识别学生的真实能力。


<details>
  <summary>Details</summary>
Motivation: 随着学生在作业中使用AI的普及，人们对学术诚信和评估有效性的担忧日益增加。本研究旨在深入分析最先进的大型语言模型在多模态科学推理能力和认知局限性方面的表现，以应对教育领域中AI带来的挑战。

Method: 本研究以2025年韩国大学学术能力测试（CSAT）的地球科学I部分为例，设计了三种实验条件（整页输入、单个项目输入和优化的多模态输入），以评估模型在不同数据结构下的性能。研究对象包括GPT-4o、Gemini 2.5 Flash和Gemini 2.5 Pro。

Result: 定量结果表明，由于分段和光学字符识别（OCR）失败，非结构化输入导致性能显著下降。即使在优化条件下，模型也表现出基本的推理缺陷。定性分析揭示了“感知错误”是主要问题，突出了模型未能解释示意图中的符号含义的“感知-认知差距”。此外，模型还表现出“计算-概念化差异”，即能成功进行计算但未能应用潜在的科学概念，以及“过程幻觉”，即模型跳过视觉验证而倾向于合理但毫无根据的背景知识。

Conclusion: 本研究为设计“抗AI问题”提供了可操作的线索，这些问题专门针对AI的认知漏洞，例如感知与认知之间的差距。通过利用AI的弱点，教育工作者可以区分学生的真实能力与AI生成的回答，从而确保评估的公平性。

Abstract: The rapid development of Generative AI is bringing innovative changes to education and assessment. As the prevalence of students utilizing AI for assignments increases, concerns regarding academic integrity and the validity of assessments are growing. This study utilizes the Earth Science I section of the 2025 Korean College Scholastic Ability Test (CSAT) to deeply analyze the multimodal scientific reasoning capabilities and cognitive limitations of state-of-the-art Large Language Models (LLMs), including GPT-4o, Gemini 2.5 Flash, and Gemini 2.5 Pro. Three experimental conditions (full-page input, individual item input, and optimized multimodal input) were designed to evaluate model performance across different data structures. Quantitative results indicated that unstructured inputs led to significant performance degradation due to segmentation and Optical Character Recognition (OCR) failures. Even under optimized conditions, models exhibited fundamental reasoning flaws. Qualitative analysis revealed that "Perception Errors" were dominant, highlighting a "Perception-Cognition Gap" where models failed to interpret symbolic meanings in schematic diagrams despite recognizing visual data. Furthermore, models demonstrated a "Calculation-Conceptualization Discrepancy," successfully performing calculations while failing to apply the underlying scientific concepts, and "Process Hallucination," where models skipped visual verification in favor of plausible but unfounded background knowledge. Addressing the challenge of unauthorized AI use in coursework, this study provides actionable cues for designing "AI-resistant questions" that target these specific cognitive vulnerabilities. By exploiting AI's weaknesses, such as the gap between perception and cognition, educators can distinguish genuine student competency from AI-generated responses, thereby ensuring assessment fairness.

</details>


### [110] [Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations](https://arxiv.org/abs/2512.15388)
*Reinhard Moratz,Niklas Daute,James Ondieki,Markus Kattenbeck,Mario Krajina,Ioannis Giannopoulos*

Main category: cs.AI

TL;DR: 本文旨在增强大型语言模型为行人寻路者提供路线指令的能力，着重于定性空间关系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在为行人寻路者提供路线指令方面存在改进空间。

Method: 通过利用定性空间关系来提高大型语言模型提供路线指令的能力。

Result: 通过利用定性空间关系，LLM在为行人寻路者提供路线指令方面的能力得到了增强。

Conclusion: 定性空间关系可以有效提升大型语言模型在行人导航指令方面的表现。

Abstract: This paper deals with improving the capabilities of Large Language Models (LLM) to provide route instructions for pedestrian wayfinders by means of qualitative spatial relations.

</details>


### [111] [Outer-Learning Framework for Playing Multi-Player Trick-Taking Card Games: A Case Study in Skat](https://arxiv.org/abs/2512.15435)
*Stefan Edelkamp*

Main category: cs.AI

TL;DR: 本文提出了一种通用的自举式外学习框架，通过扩展人工和AI游戏的数据库来提高预测准确性，从而实现自我改进的纸牌游戏引擎。


<details>
  <summary>Details</summary>
Motivation: 在Skat或Bridge等多玩家纸牌游戏中，早期决策对游戏的成功至关重要，但目前的计算能力限制了对这些决策的优化。因此，研究旨在使用统计信息改进这些早期决策。

Method: 本文提出了一种通用的自举式外学习框架。该框架通过使用数百万个AI自玩游戏扩展人类专家游戏的数据库，并融合统计数据，从而提高预测准确性。文中实现了完善的特征哈希函数，以解决压缩表问题，从而生成一个自我改进的纸牌游戏引擎，在该引擎中，新推断的知识在自学习过程中不断得到改进。

Result: 在Skat中的案例研究表明，该自动化方法可用于支持游戏中的各种决策。

Conclusion: 通过自举外学习框架和AI自玩游戏的使用，可以显著提高多玩家纸牌游戏中早期决策的预测准确性。这种方法使得纸牌游戏引擎能够自我改进。

Abstract: In multi-player card games such as Skat or Bridge, the early stages of the game, such as bidding, game selection, and initial card selection, are often more critical to the success of the play than refined middle- and end-game play. At the current limits of computation, such early decision-making resorts to using statistical information derived from a large corpus of human expert games. In this paper, we derive and evaluate a general bootstrapping outer-learning framework that improves prediction accuracy by expanding the database of human games with millions of self-playing AI games to generate and merge statistics. We implement perfect feature hash functions to address compacted tables, producing a self-improving card game engine, where newly inferred knowledge is continuously improved during self-learning. The case study in Skat shows that the automated approach can be used to support various decisions in the game.

</details>


### [112] [Intent-Driven UAM Rescheduling](https://arxiv.org/abs/2512.15462)
*Jeongseok Kim,Kangjin Kim*

Main category: cs.AI

TL;DR: 该文提出了一个新的集成系统，结合了ASP和MILP，以有效地解决城市空中交通（UAM）中由于资源受限而导致的垂直机场调度问题。


<details>
  <summary>Details</summary>
Motivation: 在城市空中交通（UAM）领域，由于资源有限，垂直机场的有效调度受到了越来越多的关注。现有的调度问题通常采用资源受限项目调度问题（RCPSP）的混合整数线性规划（MILP）方法。

Method: 我们开发了一个新的集成系统，将Answer Set Programming（ASP）和混合整数线性规划（MILP）相结合。该系统利用三值逻辑解释模糊的用户意图，并通过决策树处理动态操作要求和人类模糊的重新调度请求。

Result: 这个集成框架能够优化调度问题，并透明地支持人类输入。为可解释、自适应的城市空中交通调度提供了强大的结构。

Conclusion: 该文提出的集成系统通过结合ASP和MILP，成功解决了城市空中交通（UAM）中垂直机场的资源受限调度问题，并能有效处理动态操作和人类模糊请求。

Abstract: Due to the restricted resources, efficient scheduling in vertiports has received much more attention in the field of Urban Air Mobility (UAM). For the scheduling problem, we utilize a Mixed Integer Linear Programming (MILP), which is often formulated in a resource-restricted project scheduling problem (RCPSP). In this paper, we show our approach to handle both dynamic operation requirements and vague rescheduling requests from humans. Particularly, we utilize a three-valued logic for interpreting ambiguous user intents and a decision tree, proposing a newly integrated system that combines Answer Set Programming (ASP) and MILP. This integrated framework optimizes schedules and supports human inputs transparently. With this system, we provide a robust structure for explainable, adaptive UAM scheduling.

</details>


### [113] [Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision](https://arxiv.org/abs/2512.15489)
*Wei Du,Shubham Toshniwal,Branislav Kisacanin,Sadegh Mahdavi,Ivan Moshkov,George Armstrong,Stephen Ge,Edgar Minasyan,Feng Chen,Igor Gitman*

Main category: cs.AI

TL;DR: Nemotron-Math是一个包含750万个数学问题解决方案轨迹的大型数据集，它整合了AoPS和StackExchange-Math问题，旨在通过多模式和工具集成来提高数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的数学推理监督数据集在推理风格多样性、长篇轨迹和有效工具集成方面存在局限性。

Method: Nemotron-Math利用gpt-oss-120b的多模式生成能力，通过整合8.5万个AoPS问题和26.2万个StackExchange-Math问题，构建了一个包含高、中、低三种推理模式的750万个解决方案轨迹数据集，并提供了Python工具集成推理（TIR）和非TIR两种版本。为了支持高效的长上下文训练，开发了一种顺序桶化策略，将128K上下文长度的微调速度提高了2-3倍，而没有显著的准确性损失。

Result: Nemotron-Math在匹配的AoPS问题上始终优于原始的OpenMathReasoning。整合StackExchange-Math显著提高了鲁棒性和泛化能力，尤其是在HLE-Math上，同时在数学竞赛基准测试中保持了准确性。Nemotron-Math实现了最先进的性能，包括在AIME 2024和2025上使用Python TIR达到了100%的maj@16准确率。

Conclusion: Nemotron-Math数据集通过其多样化的推理模式和有效的工具集成，显著提升了数学推理任务的性能，并在多个基准测试中展现出卓越的准确性和泛化能力。

Abstract: High-quality mathematical reasoning supervision requires diverse reasoning styles, long-form traces, and effective tool integration, capabilities that existing datasets provide only in limited form. Leveraging the multi-mode generation ability of gpt-oss-120b, we introduce Nemotron-Math, a large-scale mathematical reasoning dataset containing 7.5M solution traces across high, medium, and low reasoning modes, each available both with and without Python tool-integrated reasoning (TIR).
  The dataset integrates 85K curated AoPS problems with 262K community-sourced StackExchange-Math problems, combining structured competition tasks with diverse real-world mathematical queries. We conduct controlled evaluations to assess the dataset quality.
  Nemotron-Math consistently outperforms the original OpenMathReasoning on matched AoPS problems. Incorporating StackExchange-Math substantially improves robustness and generalization, especially on HLE-Math, while preserving accuracy on math competition benchmarks.
  To support efficient long-context training, we develop a sequential bucketed strategy that accelerates 128K context-length fine-tuning by 2--3$\times$ without significant accuracy loss. Overall, Nemotron-Math enables state-of-the-art performance, including 100\% maj@16 accuracy on AIME 2024 and 2025 with Python TIR.

</details>


### [114] [Evaluating Large Language Models in Scientific Discovery](https://arxiv.org/abs/2512.15567)
*Zhangde Song,Jieyu Lu,Yuanqi Du,Botao Yu,Thomas M. Pruyn,Yue Huang,Kehan Guo,Xiuzhe Luo,Yuanhao Qu,Yi Qu,Yinkai Wang,Haorui Wang,Jeff Guo,Jingru Gan,Parshin Shojaee,Di Luo,Andres M Bran,Gen Li,Qiyuan Zhao,Shao-Xiong Lennon Luo,Yuxuan Zhang,Xiang Zou,Wanru Zhao,Yifan F. Zhang,Wucheng Zhang,Shunan Zheng,Saiyang Zhang,Sartaaj Takrim Khan,Mahyar Rajabi-Kochi,Samantha Paradi-Maropakis,Tony Baltoiu,Fengyu Xie,Tianyang Chen,Kexin Huang,Weiliang Luo,Meijing Fang,Xin Yang,Lixue Cheng,Jiajun He,Soha Hassoun,Xiangliang Zhang,Wei Wang,Chandan K. Reddy,Chao Zhang,Zhiling Zheng,Mengdi Wang,Le Cong,Carla P. Gomes,Chang-Yu Hsieh,Aditya Nandy,Philippe Schwaller,Heather J. Kulik,Haojun Jia,Huan Sun,Seyed Mohamad Moosavi,Chenru Duan*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个新的基准，通过在生物学、化学、材料学和物理学等领域设置真实的研究项目场景来评估大型语言模型（LLMs）的科学发现能力。


<details>
  <summary>Details</summary>
Motivation: 当前衡量LLMs科学能力的基准未能充分反映科学发现过程中迭代推理、假设生成和观察解释等关键环节。

Method: 通过领域专家定义研究项目和模块化研究场景，并从中抽取问题来评估LLMs。评估分为两个层面：(i) 问题层面：测量在与场景相关问题上的准确性；(ii) 项目层面：评估模型提出可测试假设、设计模拟或实验以及解释结果的能力。

Result: 研究发现，与通用科学基准相比，LLMs在科学发现评估（SDE）框架下表现出一致的性能差距；模型规模和推理能力的提升带来了收益递减；顶级模型普遍存在系统性弱点。不同研究场景中模型的表现差异很大，没有一个模型能持续领先，这表明当前的LLMs距离实现通用科学“超智能”还有很长的路要走。尽管如此，LLMs在多种科学发现项目中已展现出潜力，即便在某些构成性场景得分较低的情况下也是如此，这突出了在发现过程中引导性探索和偶然性的作用。

Conclusion: SDE框架为评估LLMs的科学发现能力提供了一个可重复的基准，并为推动其在科学发现方面的发展指明了实际路径。

Abstract: Large language models (LLMs) are increasingly applied to scientific research, yet prevailing science benchmarks probe decontextualized knowledge and overlook the iterative reasoning, hypothesis generation, and observation interpretation that drive scientific discovery. We introduce a scenario-grounded benchmark that evaluates LLMs across biology, chemistry, materials, and physics, where domain experts define research projects of genuine interest and decompose them into modular research scenarios from which vetted questions are sampled. The framework assesses models at two levels: (i) question-level accuracy on scenario-tied items and (ii) project-level performance, where models must propose testable hypotheses, design simulations or experiments, and interpret results. Applying this two-phase scientific discovery evaluation (SDE) framework to state-of-the-art LLMs reveals a consistent performance gap relative to general science benchmarks, diminishing return of scaling up model sizes and reasoning, and systematic weaknesses shared across top-tier models from different providers. Large performance variation in research scenarios leads to changing choices of the best performing model on scientific discovery projects evaluated, suggesting all current LLMs are distant to general scientific "superintelligence". Nevertheless, LLMs already demonstrate promise in a great variety of scientific discovery projects, including cases where constituent scenario scores are low, highlighting the role of guided exploration and serendipity in discovery. This SDE framework offers a reproducible benchmark for discovery-relevant evaluation of LLMs and charts practical paths to advance their development toward scientific discovery.

</details>


### [115] [Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning](https://arxiv.org/abs/2512.15662)
*Jiaqi Xu,Cuiling Lan,Xuejin Chen,Yan LU*

Main category: cs.AI

TL;DR: 该论文提出了一个名为STC的统一框架，它在大型语言模型（LLMs）中，通过在每一步中交 S推理和自我 crítica 来模拟人类的批判性思维，从而提高了问题解决能力和推理过程的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs在推理时缺乏明确的自我检查，或者依赖外部验证器进行事后纠错，这增加了系统复杂性并阻碍了同步学习。为了解决这些问题，受到人类批判性思维的启发，本文提出了STC框架。

Method: STC框架在单一模型中交替进行推理和自我批判。它通过结合推理奖励和批判一致性奖励的混合强化学习目标进行训练，以共同优化推理质量和自我评估能力。

Result: 在数学推理基准测试中，STC展现出强大的批判性思维能力，并生成了更具解释性的推理轨迹。

Conclusion: STC代表了LLMs在内置批判性思维方面迈出了重要一步，能够解决复杂问题并产生更具解释性的推理过程。

Abstract: Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking or rely on external verifiers to detect errors post hoc. The former lacks immediate feedback, while the latter increases system complexity and hinders synchronized learning. Motivated by human critical thinking, we propose Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single model. STC is trained with a hybrid reinforcement learning objective combining reasoning rewards and critique-consistency rewards to jointly optimize reasoning quality and self-evaluation. Experiments on mathematical reasoning benchmarks show that STC demonstrates strong critic-thinking capabilities and produces more interpretable reasoning traces, representing a step toward LLMs with built-in critical thinking.

</details>


### [116] [Explaining the Reasoning of Large Language Models Using Attribution Graphs](https://arxiv.org/abs/2512.15663)
*Chase Walker,Rickard Ewetz*

Main category: cs.AI

TL;DR: CAGE框架通过引入归因图，解决了现有上下文归因方法在解释大型语言模型时忽略代际影响的问题，从而提高了归因的忠实度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的推理过程不透明，引发了人们对安全性和信任的担忧。现有的上下文归因方法在解释LLMs的决策时，忽略了生成token之间的相互影响，导致解释不完整。

Method: CAGE框架引入了一个归因图，该图是一个有向图，量化了每个生成如何受到提示和所有先前生成的影响。该图的构建保留了因果关系和行随机性这两个属性。归因图通过边缘化图中路径上的中间贡献来计算上下文归因。

Result: CAGE框架在多个模型、数据集、指标和方法上提高了上下文归因的忠实度，平均增益高达40%。

Conclusion: CAGE框架通过引入归因图，有效地解决了大型语言模型解释中上下文归因的不足，显著提高了归因的忠实度，从而增强了LLMs的可解释性和可信度。

Abstract: Large language models (LLMs) exhibit remarkable capabilities, yet their reasoning remains opaque, raising safety and trust concerns. Attribution methods, which assign credit to input features, have proven effective for explaining the decision making of computer vision models. From these, context attributions have emerged as a promising approach for explaining the behavior of autoregressive LLMs. However, current context attributions produce incomplete explanations by directly relating generated tokens to the prompt, discarding inter-generational influence in the process. To overcome these shortcomings, we introduce the Context Attribution via Graph Explanations (CAGE) framework. CAGE introduces an attribution graph: a directed graph that quantifies how each generation is influenced by both the prompt and all prior generations. The graph is constructed to preserve two properties-causality and row stochasticity. The attribution graph allows context attributions to be computed by marginalizing intermediate contributions along paths in the graph. Across multiple models, datasets, metrics, and methods, CAGE improves context attribution faithfulness, achieving average gains of up to 40%.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [117] [Mapis: A Knowledge-Graph Grounded Multi-Agent Framework for Evidence-Based PCOS Diagnosis](https://arxiv.org/abs/2512.15398)
*Zanxiang He,Meng Li,Liyun Shi,Weiye Daia,Liming Nie*

Main category: cs.MA

TL;DR: 该文章提出了一种名为Mapis的新型多智能体框架，用于PCOS的诊断，该框架基于2023年国际指南，并结合了领域知识图谱，解决了传统方法对大规模标记数据的依赖和可解释性差的问题，在多项实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PCOS影响了10%的育龄女性，急需有效的诊断工具。现有的机器学习和深度学习诊断工具受限于对大规模标记数据的依赖和缺乏可解释性。多智能体系统在PCOS检测中的潜力尚未被充分探索，且现有医学多智能体框架缺乏领域整合和特定领域知识。

Method: Mapis是一种知识驱动的多智能体框架，专门用于基于指南的PCOS诊断。它将2023年国际指南融入结构化协作工作流，模拟临床诊断过程。系统将复杂的诊断任务分解给专业智能体：妇科内分泌智能体和放射学智能体协作验证纳入标准，排除智能体严格排除其他原因。此外，构建了全面的PCOS知识图谱，以确保可验证的、基于证据的决策。

Result: 在公共基准和专业临床数据集上进行的大量实验表明，Mapis显著优于九种不同的基线方法。在临床数据集上，Mapis在准确性方面超越了传统机器学习模型13.56%，超越单智能体模型6.55%，超越之前的医学多智能体系统7.05%。

Conclusion: Mapis通过结合2023年国际PCOS诊断指南和全面的PCOS知识图谱，提供了一个可解释、高效的多智能体诊断框架，克服了现有方法的局限性，显著提高了PCOS诊断的准确性。

Abstract: Polycystic Ovary Syndrome (PCOS) constitutes a significant public health issue affecting 10% of reproductive-aged women, highlighting the critical importance of developing effective diagnostic tools. Previous machine learning and deep learning detection tools are constrained by their reliance on large-scale labeled data and an lack of interpretability. Although multi-agent systems have demonstrated robust capabilities, the potential of such systems for PCOS detection remains largely unexplored. Existing medical multi-agent frameworks are predominantly designed for general medical tasks, suffering from insufficient domain integration and a lack of specific domain knowledge. To address these challenges, we propose Mapis, the first knowledge-grounded multi-agent framework explicitly designed for guideline-based PCOS diagnosis. Specifically, it built upon the 2023 International Guideline into a structured collaborative workflow that simulates the clinical diagnostic process. It decouples complex diagnostic tasks across specialized agents: a gynecological endocrine agent and a radiology agent collaborative to verify inclusion criteria, while an exclusion agent strictly rules out other causes. Furthermore, we construct a comprehensive PCOS knowledge graph to ensure verifiable, evidence-based decision-making. Extensive experiments on public benchmarks and specialized clinical datasets, benchmarking against nine diverse baselines, demonstrate that Mapis significantly outperforms competitive methods. On the clinical dataset, it surpasses traditional machine learning models by 13.56%, single-agent by 6.55%, and previous medical multi-agent systems by 7.05% in Accuracy.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [118] [A Joint Auction Framework with Externalities and Adaptation](https://arxiv.org/abs/2512.15043)
*Chun Fang,Luowen Liu,Kun Huang,Tao Ruan,Sheng Yan,Zhen Wang,Huan Li,Qiang Liu,Xingxing Wang*

Main category: cs.GT

TL;DR: 该论文提出了一个联合拍卖框架（JEANet），旨在克服现有联合广告方法的局限性，特别是在考虑全局外部性和多方广告商参与情况下的出价可变性。


<details>
  <summary>Details</summary>
Motivation: 传统的广告分配方法难以同时适应联合广告和传统广告模式，限制了收入潜力。现有方法未能考虑全局外部性和多方广告商参与导致的出价可变性，给联合拍卖机制的设计带来了挑战。

Method: 提出了一种结合外部性和自适应机制的联合拍卖框架（JEANet）。利用自动化机制设计（AMD）方法，通过JEANet计算满足个体理性（IR）和近似主导策略激励兼容性（DSIC）条件的联合拍卖机制。JEANet是首个将全局外部性整合到联合拍卖中的AMD方法，并且能够动态适应多方广告商的出价特征。

Result: JEANet在多槽联合拍卖中表现优于现有基线方法。

Conclusion: JEANet框架通过整合全局外部性和适应多方广告商的出价特性，实现了统一的联合广告和传统广告拍卖，显著提升了广告分配的效率和收益。

Abstract: Recently, joint advertising has gained significant attention as an effective approach to enhancing the efficiency and revenue of advertising slot allocation. Unlike traditional advertising, which allocates advertising slots exclusively to a single advertiser, joint advertising displays advertisements from brands and stores that have established a joint selling relationship within the same advertising slot. However, existing approaches often struggle to accommodate both joint and traditional advertising frameworks, thereby limiting the revenue potential and generalizability of joint advertising. Furthermore, these methods are constrained by two critical limitations: they generally neglect the influence of global externalities, and they fail to address the bidding variability stemming from multi-party advertiser participation. Collectively, these limitations present substantial challenges to the design of joint auction mechanisms. To address these challenges, we propose a Joint Auction Framework incorporating Externalities and Adaptation, and leverage the automated mechanism design (AMD) method through our proposed JEANet to compute joint auction mechanisms that satisfy the conditions of individual rationality (IR) and approximate dominant strategy incentive compatibility (DSIC). As the first AMD method to integrate global externalities into joint auctions, JEANet dynamically adapts to the bidding characteristics of multi-party advertiser and enables unified auctions that integrate both joint and traditional advertising. Extensive experimental results demonstrate that JEANet outperforms state-of-the-art baselines in multi-slot joint auctions.

</details>
